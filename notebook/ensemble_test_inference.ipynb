{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceramic-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "from network2 import *\n",
    "from dataset import *\n",
    "from utils2 import *\n",
    "from loss import *\n",
    "from load import *\n",
    "\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM']='false'\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from collections import defaultdict, OrderedDict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertModel, GPT2LMHeadModel, ElectraModel, BertModel, AlbertModel, FunnelModel\n",
    "from transformers import PreTrainedTokenizerFast, AutoTokenizer, BertTokenizerFast, ElectraTokenizerFast, FunnelTokenizerFast\n",
    "from asian_bart import AsianBartTokenizer, AsianBartForConditionalGeneration\n",
    "import gluonnlp as nlp\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "device='cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-belly",
   "metadata": {},
   "source": [
    "# Base Models' Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-gates",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_paths = [\n",
    "    '/home/jupyter/FINAL/albert',\n",
    "    '/home/jupyter/FINAL/asbart',\n",
    "    '/home/jupyter/FINAL/asbart_2',\n",
    "    '/home/jupyter/FINAL/electra',\n",
    "    '/home/jupyter/FINAL/funnel',\n",
    "    '/home/jupyter/FINAL/funnel_2',\n",
    "    '/home/jupyter/FINAL/kobart',\n",
    "    '/home/jupyter/FINAL/kobart_2',\n",
    "    '/home/jupyter/FINAL/kobert',\n",
    "    '/home/jupyter/FINAL/kogpt2',\n",
    "    '/home/jupyter/FINAL/kogpt3',\n",
    "    '/home/jupyter/FINAL/kogpt3_2',\n",
    "    '/home/jupyter/FINAL/mlbert',\n",
    "    '/home/jupyter/FINAL/mlbert_2'\n",
    "]\n",
    "model_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-election",
   "metadata": {},
   "source": [
    "# Load Backbones & Tokenizers & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "russian-tooth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>고객을 대상으로 세차장에서 자동차세차업</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>사업장에서 고객의요청에따라 자동차세차업</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>자동차부분정비 서비스 인젝터수리</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>카센타 자동차의 특정부분만을 전문적 수리 경정비,타이어,내장수리,도장 등의 서비스</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정비사업소 고객의 요청으로 자동차 특정부분수리</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>시설을 갖추고 사업장에서 종교라디오방송</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>라디오영어 FM방송을 제작하여 방송국에서 라디오영어 방송 제공</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>플라스틱, 잉크 자재입고, 사출 교육용 CD</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>통신및방송장비, 영상및음향기기</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>잎담배, 판상엽 가공, 궐련 차세대상품, 차세대제조담배</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49952 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text  label\n",
       "0                           고객을 대상으로 세차장에서 자동차세차업    221\n",
       "1                           사업장에서 고객의요청에따라 자동차세차업    221\n",
       "2                               자동차부분정비 서비스 인젝터수리    221\n",
       "3   카센타 자동차의 특정부분만을 전문적 수리 경정비,타이어,내장수리,도장 등의 서비스    221\n",
       "4                       정비사업소 고객의 요청으로 자동차 특정부분수리    221\n",
       "..                                            ...    ...\n",
       "0                           시설을 갖추고 사업장에서 종교라디오방송    153\n",
       "1              라디오영어 FM방송을 제작하여 방송국에서 라디오영어 방송 제공    153\n",
       "0                        플라스틱, 잉크 자재입고, 사출 교육용 CD     69\n",
       "1                              통신및방송장비, 영상및음향기기       69\n",
       "0                  잎담배, 판상엽 가공, 궐련 차세대상품, 차세대제조담배     22\n",
       "\n",
       "[49952 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "root = '/home/jupyter/FINAL/data/1. 실습용자료_final.txt'\n",
    "data = pd.read_csv(root, sep='|', encoding='cp949')\n",
    "train, test, cat2id, id2cat = preprocess(data, num_test=50000, upsample='', minimum=500, clean_fn=None, target='S', seed=5986)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "included-spirituality",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/jupyter/FINAL/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/jupyter/FINAL/.cache/kobart_base_cased_ff4bda5738.zip\n",
      "using cached model. /home/jupyter/FINAL/.cache/kobert_v1.zip\n",
      "using cached model. /home/jupyter/FINAL/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/jupyter/FINAL/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load backbones and tokenizers\n",
    "backbones = {}\n",
    "tokenizers = {}\n",
    "estimators=len(model_paths)\n",
    "for path in model_paths:\n",
    "    model_path = os.path.join(path, f'weights/best_loss.pth.tar')\n",
    "    config_path = os.path.join(path, 'config.json')\n",
    "    with open(config_path, 'r', encoding='utf-8-sig') as f:\n",
    "        model_args = json.load(f)\n",
    "    if model_args['model'] + '_tokenizer' not in tokenizers.keys():\n",
    "        backbone, tokenizer = load_backbone_tokenizer(model_args['model'], max_len=50)\n",
    "        backbones[model_args[\"model\"]] = backbone\n",
    "        tokenizers[f'{model_args[\"model\"]}_tokenizer'] = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "after-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['albert', 'asbart', 'electra', 'funnel', 'kobart', 'kobert', 'kogpt2', 'kogpt3', 'mlbert'])\n",
      "dict_keys(['albert_tokenizer', 'asbart_tokenizer', 'electra_tokenizer', 'funnel_tokenizer', 'kobart_tokenizer', 'kobert_tokenizer', 'kogpt2_tokenizer', 'kogpt3_tokenizer', 'mlbert_tokenizer'])\n"
     ]
    }
   ],
   "source": [
    "print(backbones.keys())\n",
    "print(tokenizers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "apparent-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataloader\n",
    "test_set = EnsembleDataset(test['text'].tolist(), test['label'].tolist(), **tokenizers, max_len=50)\n",
    "test_loader = DataLoader(test_set, batch_size=768, num_workers=4, shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-apparatus",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "independent-grade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0/13 albert: 100%|██████████████████████████████████████████████████| 66/66 [00:29<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.893217\tpc: 0.773534\trc: 0.737759\tf1: 0.745843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/13 asbart: 100%|██████████████████████████████████████████████████| 66/66 [01:24<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.894479\tpc: 0.776831\trc: 0.732162\tf1: 0.74218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2/13 asbart_2: 100%|████████████████████████████████████████████████| 66/66 [01:25<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.89594\tpc: 0.787935\trc: 0.741071\tf1: 0.753943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3/13 electra: 100%|█████████████████████████████████████████████████| 66/66 [00:23<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.900024\tpc: 0.775634\trc: 0.739965\tf1: 0.748075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4/13 funnel: 100%|██████████████████████████████████████████████████| 66/66 [00:34<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.903447\tpc: 0.778733\trc: 0.763929\tf1: 0.765086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5/13 funnel_2: 100%|████████████████████████████████████████████████| 66/66 [00:34<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.901746\tpc: 0.778926\trc: 0.748958\tf1: 0.755827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6/13 kobart: 100%|██████████████████████████████████████████████████| 66/66 [00:29<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.896661\tpc: 0.780303\trc: 0.751514\tf1: 0.757613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7/13 kobart_2: 100%|████████████████████████████████████████████████| 66/66 [00:29<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.896541\tpc: 0.761119\trc: 0.738662\tf1: 0.742271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8/13 kobert: 100%|██████████████████████████████████████████████████| 66/66 [00:23<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.898723\tpc: 0.771965\trc: 0.743887\tf1: 0.7515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9/13 kogpt2: 100%|██████████████████████████████████████████████████| 66/66 [00:30<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.891196\tpc: 0.792242\trc: 0.716439\tf1: 0.737997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/13 kogpt3: 100%|█████████████████████████████████████████████████| 66/66 [00:29<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.904248\tpc: 0.782837\trc: 0.775835\tf1: 0.773007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/13 kogpt3_2: 100%|███████████████████████████████████████████████| 66/66 [00:30<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.903988\tpc: 0.798322\trc: 0.754658\tf1: 0.767265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/13 mlbert: 100%|█████████████████████████████████████████████████| 66/66 [00:23<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.89614\tpc: 0.768502\trc: 0.749519\tf1: 0.750923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13/13 mlbert_2: 100%|███████████████████████████████████████████████| 66/66 [00:23<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tacc: 0.890475\tpc: 0.777429\trc: 0.733732\tf1: 0.744785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_classes=225\n",
    "estimators=len(model_paths)\n",
    "\n",
    "base_predictions = defaultdict(lambda: None) # Test data에 대한 base model의 예측(소프트맥스 확률값)을 저장\n",
    "labels = None # Test data label 저장\n",
    "\n",
    "# 성능 평가 도구 : Evaluator\n",
    "eval_base_models = defaultdict(lambda: Evaluator(num_classes)) # 개별 base model 성능 평가\n",
    "eval_mean = Evaluator(num_classes) # mean aggregation 결과 평가\n",
    "eval_vote = Evaluator(num_classes) # vote aggregation 결과 평가\n",
    "\n",
    "# Test\n",
    "for e, path in enumerate(model_paths):\n",
    "    # paths\n",
    "    model_path = os.path.join(path, f'weights/best_loss.pth.tar')\n",
    "    config_path = os.path.join(path, 'config.json')\n",
    "    \n",
    "    # info from config.json\n",
    "    with open(config_path, 'r', encoding='utf-8-sig') as f:\n",
    "        model_args = json.load(f)\n",
    "    loss_type = model_args['loss']\n",
    "    model_type = model_args['model']\n",
    "#     model_name = model_args['model']\n",
    "    model_name = path.split(os.sep)[-1]\n",
    "#     model_name = '_'.join([str(e), model_type, path.split(os.sep)[-1]])\n",
    "    \n",
    "    # build a base model\n",
    "    backbone = backbones[model_type] # load backbone\n",
    "    model = load_model(model_type=model_type,\n",
    "                       backbone=copy(backbone),\n",
    "                       num_classes=num_classes,\n",
    "                       num_layers=model_args['n_layers'], \n",
    "                       dr_rate=model_args['dr_rate'],\n",
    "                       bias=True,\n",
    "                       batchnorm=model_args['batchnorm'],\n",
    "                       layernorm=model_args['layernorm'])\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu')['state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Base Model Test\n",
    "    with torch.no_grad():\n",
    "        for inputs, label in tqdm(test_loader, total=len(test_loader), ncols=100,\n",
    "                                  desc=f'{e}/{len(model_paths)-1} {model_name}'):\n",
    "            # pick base model input from inputs\n",
    "            _inputs = {}\n",
    "            _inputs['input_ids'] = inputs[model_type][:, 0].to(device, non_blocking=True)\n",
    "            _inputs['attention_mask'] = inputs[model_type][:, 1].to(device, non_blocking=True)\n",
    "            if 'bart' not in model_type:\n",
    "                _inputs['token_type_ids'] = inputs[model_type][:, 2].to(device, non_blocking=True)\n",
    "            \n",
    "            # forward\n",
    "            output = model(**_inputs)\n",
    "            pred = F.softmax(output, dim=1)\n",
    "            \n",
    "            # store base predictions\n",
    "            if base_predictions[model_name] is None:\n",
    "                base_predictions[model_name] = pred.clone().cpu()\n",
    "            else:\n",
    "                base_predictions[model_name] = torch.cat([base_predictions[model_name], pred.clone().cpu()], dim=0)\n",
    "            # store labels\n",
    "            if e==0:\n",
    "                if labels is None:\n",
    "                    labels = label.cpu()\n",
    "                else:\n",
    "                    labels = torch.cat([labels, label.cpu()], dim=0)\n",
    "            \n",
    "            # update batch predictions\n",
    "            eval_base_models[model_name].update(pred.clone().argmax(1).cpu(), label)\n",
    "    # log a base model performance\n",
    "    eval_base_models[model_name].compute()\n",
    "    print(f'\\tacc: {round(eval_base_models[model_name].acc, 6)}\\tpc: {round(eval_base_models[model_name].macro_pc, 6)}\\trc: {round(eval_base_models[model_name].macro_rc, 6)}\\tf1: {round(eval_base_models[model_name].macro_f1, 6)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "domestic-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Result\n",
      "mean agg|\tacc: 0.912136\tpc: 0.816902\trc: 0.78041\tf1: 0.791835\n",
      "vote agg|\tacc: 0.912156\tpc: 0.817654\trc: 0.781789\tf1: 0.792392\n",
      "0 albert | \tacc: 0.893217\tpc: 0.773534\trc: 0.737759\tf1: 0.745843\n",
      "1 asbart | \tacc: 0.894479\tpc: 0.776831\trc: 0.732162\tf1: 0.74218\n",
      "2 asbart_2 | \tacc: 0.89594\tpc: 0.787935\trc: 0.741071\tf1: 0.753943\n",
      "3 electra | \tacc: 0.900024\tpc: 0.775634\trc: 0.739965\tf1: 0.748075\n",
      "4 funnel | \tacc: 0.903447\tpc: 0.778733\trc: 0.763929\tf1: 0.765086\n",
      "5 funnel_2 | \tacc: 0.901746\tpc: 0.778926\trc: 0.748958\tf1: 0.755827\n",
      "6 kobart | \tacc: 0.896661\tpc: 0.780303\trc: 0.751514\tf1: 0.757613\n",
      "7 kobart_2 | \tacc: 0.896541\tpc: 0.761119\trc: 0.738662\tf1: 0.742271\n",
      "8 kobert | \tacc: 0.898723\tpc: 0.771965\trc: 0.743887\tf1: 0.7515\n",
      "9 kogpt2 | \tacc: 0.891196\tpc: 0.792242\trc: 0.716439\tf1: 0.737997\n",
      "10 kogpt3 | \tacc: 0.904248\tpc: 0.782837\trc: 0.775835\tf1: 0.773007\n",
      "11 kogpt3_2 | \tacc: 0.903988\tpc: 0.798322\trc: 0.754658\tf1: 0.767265\n",
      "12 mlbert | \tacc: 0.89614\tpc: 0.768502\trc: 0.749519\tf1: 0.750923\n",
      "13 mlbert_2 | \tacc: 0.890475\tpc: 0.777429\trc: 0.733732\tf1: 0.744785\n"
     ]
    }
   ],
   "source": [
    "# mean aggregation\n",
    "base_model_outputs = torch.stack(list(base_predictions.values()))\n",
    "ensemble_output_mean = torch.mean(base_model_outputs, dim=0)\n",
    "pred_mean = ensemble_output_mean.argmax(1).cpu()\n",
    "eval_mean.update(pred_mean.tolist(), labels.tolist())\n",
    "eval_mean.compute()\n",
    "# vote aggregation\n",
    "ensemble_output_vote = vote(base_model_outputs, dim=2)\n",
    "pred_vote = ensemble_output_vote.sum(0).argmax(1).cpu()\n",
    "eval_vote.update(pred_vote.tolist(), labels.tolist())\n",
    "eval_vote.compute()\n",
    "\n",
    "# log aggregation result\n",
    "print('\\n\\nResult')\n",
    "print(f'mean agg|\\tacc: {round(eval_mean.acc, 6)}\\tpc: {round(eval_mean.macro_pc, 6)}\\trc: {round(eval_mean.macro_rc, 6)}\\tf1: {round(eval_mean.macro_f1, 6)}')\n",
    "print(f'vote agg|\\tacc: {round(eval_vote.acc, 6)}\\tpc: {round(eval_vote.macro_pc, 6)}\\trc: {round(eval_vote.macro_rc, 6)}\\tf1: {round(eval_vote.macro_f1, 6)}')\n",
    "# log base models' result again\n",
    "for e, (model_name, eval_base_model) in enumerate(eval_base_models.items()):\n",
    "    print(f'{e} {model_name} | \\tacc: {round(eval_base_model.acc, 6)}\\tpc: {round(eval_base_model.macro_pc, 6)}\\trc: {round(eval_base_model.macro_rc, 6)}\\tf1: {round(eval_base_model.macro_f1, 6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-trustee",
   "metadata": {},
   "source": [
    "# Best 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "linear-directive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9121356502242153 0.8169016274378694 0.7804104475723467 0.7918351755669315\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import time\n",
    "\n",
    "n = 1\n",
    "model_predictions = defaultdict(list)\n",
    "for model_name, predictions in base_predictions.items():\n",
    "    model_type = model_name.split('_')[0]\n",
    "    model_predictions[model_type].append((model_name, predictions))\n",
    "    \n",
    "model_coef={}\n",
    "eval_test = Evaluator(num_classes)\n",
    "predictions = []\n",
    "model_names = []\n",
    "for model_type, model_preds in model_predictions.items():\n",
    "    combs = list(combinations(model_preds, n))\n",
    "    for comb in combs:\n",
    "        model_name, preds = zip(*comb)\n",
    "        predictions += preds\n",
    "        model_names.append(model_name)\n",
    "agg_pred = torch.stack(predictions)\n",
    "ensemble_output_mean = torch.mean(agg_pred, dim=0)\n",
    "pred_mean = ensemble_output_mean.argmax(1).cpu()\n",
    "eval_test.update(pred_mean.tolist(), labels.tolist())\n",
    "eval_test.compute()\n",
    "print(eval_test.acc, eval_test.macro_pc, eval_test.macro_rc, eval_test.macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "wrapped-purse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1개 조합: 100%|█████████████████████████████████████████████████████| 14/14 [00:00<00:00, 19.06it/s]\n",
      "2개 조합: 100%|█████████████████████████████████████████████████████| 91/91 [00:05<00:00, 18.02it/s]\n",
      "3개 조합: 100%|███████████████████████████████████████████████████| 364/364 [00:22<00:00, 16.34it/s]\n",
      "4개 조합: 100%|█████████████████████████████████████████████████| 1001/1001 [01:07<00:00, 14.91it/s]\n",
      "5개 조합: 100%|█████████████████████████████████████████████████| 2002/2002 [02:25<00:00, 13.76it/s]\n",
      "6개 조합: 100%|█████████████████████████████████████████████████| 3003/3003 [03:54<00:00, 12.79it/s]\n",
      "7개 조합: 100%|█████████████████████████████████████████████████| 3432/3432 [04:49<00:00, 11.86it/s]\n",
      "8개 조합: 100%|█████████████████████████████████████████████████| 3003/3003 [04:30<00:00, 11.10it/s]\n",
      "9개 조합: 100%|█████████████████████████████████████████████████| 2002/2002 [03:12<00:00, 10.39it/s]\n",
      "10개 조합: 100%|████████████████████████████████████████████████| 1001/1001 [01:43<00:00,  9.65it/s]\n",
      "11개 조합: 100%|██████████████████████████████████████████████████| 364/364 [00:39<00:00,  9.12it/s]\n",
      "12개 조합: 100%|████████████████████████████████████████████████████| 91/91 [00:11<00:00,  7.83it/s]\n",
      "13개 조합: 100%|████████████████████████████████████████████████████| 14/14 [00:01<00:00,  7.30it/s]\n",
      "14개 조합: 100%|██████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "model_coef={}\n",
    "for n in range(1, len(base_predictions)+1):\n",
    "    combs = list(combinations(sorted(base_predictions.items()), n))\n",
    "    for comb in tqdm(combs, total=len(combs), desc=f'{n}개 조합', ncols=100):\n",
    "        models, predictions = zip(*comb)\n",
    "        eval_test = Evaluator(num_classes)\n",
    "        agg_pred = torch.stack(predictions)\n",
    "        ensemble_output_mean = torch.mean(agg_pred, dim=0)\n",
    "        pred_mean = ensemble_output_mean.argmax(1).cpu()\n",
    "        eval_test.update(pred_mean.tolist(), labels.tolist())\n",
    "        eval_test.compute()\n",
    "        model_coef['|'.join(models)] = (eval_test.acc, eval_test.macro_f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cross-whole",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.912636,\n",
       "  'asbart_2|funnel|funnel_2|kobart_2|kobert|kogpt2|kogpt3|kogpt3_2|mlbert|mlbert_2'),\n",
       " (0.912616,\n",
       "  'asbart_2|funnel|funnel_2|kobart|kobart_2|kobert|kogpt2|kogpt3|kogpt3_2|mlbert|mlbert_2'),\n",
       " (0.912616,\n",
       "  'asbart_2|electra|funnel_2|kobert|kogpt2|kogpt3|kogpt3_2|mlbert|mlbert_2'),\n",
       " (0.912576,\n",
       "  'asbart|asbart_2|funnel|funnel_2|kobart_2|kobert|kogpt2|kogpt3_2|mlbert|mlbert_2'),\n",
       " (0.912576,\n",
       "  'albert|asbart|asbart_2|funnel_2|kobart_2|kobert|kogpt2|kogpt3|kogpt3_2|mlbert|mlbert_2')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc 기준 조합 랭킹\n",
    "rank = 5\n",
    "model_acc = {mt: acc for mt, (acc, f1) in model_coef.items()}\n",
    "sorted(zip(map(lambda x: round(x, 6), model_acc.values()), model_acc.keys()), reverse=True)[:rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "twelve-singing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.799122,\n",
       "  'albert|asbart|asbart_2|funnel|kobert|kogpt2|kogpt3|mlbert|mlbert_2'),\n",
       " (0.798517,\n",
       "  'albert|asbart|asbart_2|electra|funnel|funnel_2|kobart|kobert|kogpt2|kogpt3|mlbert_2'),\n",
       " (0.798496,\n",
       "  'albert|asbart|asbart_2|electra|funnel|kobart|kobert|kogpt2|kogpt3|mlbert_2'),\n",
       " (0.798383, 'asbart|asbart_2|funnel|kobert|kogpt3|kogpt3_2|mlbert_2'),\n",
       " (0.798105, 'albert|asbart|asbart_2|funnel|kobert|kogpt2|kogpt3|mlbert')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 기준 조합 랭킹\n",
    "model_f1 = {mt: f1 for mt, (acc, f1) in model_coef.items()}\n",
    "sorted(zip(map(lambda x: round(x, 6), model_f1.values()), model_f1.keys()), reverse=True)[:rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fluid-begin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.867038,\n",
       "  'albert|asbart|asbart_2|funnel|kobert|kogpt2|kogpt3|mlbert|mlbert_2'),\n",
       " (0.866478, 'asbart|asbart_2|funnel|kobert|kogpt3|kogpt3_2|mlbert_2'),\n",
       " (0.866469,\n",
       "  'asbart|asbart_2|electra|funnel|funnel_2|kobart|kobert|kogpt2|kogpt3|kogpt3_2|mlbert_2'),\n",
       " (0.866447,\n",
       "  'albert|asbart|asbart_2|electra|funnel|funnel_2|kobert|kogpt2|kogpt3|mlbert|mlbert_2'),\n",
       " (0.866438, 'asbart|asbart_2|funnel_2|kobert|kogpt2|kogpt3|kogpt3_2|mlbert')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc, f1 가중합 기준 조합 랭킹\n",
    "w_acc = 0.6\n",
    "w_f1 = 1-w_acc\n",
    "model_coef2 = {mt: acc*w_acc + f1*w_f1 for mt, (acc, f1) in model_coef.items()}\n",
    "sorted(zip(map(lambda x: round(x, 6), model_coef2.values()), model_coef2.keys()), reverse=True)[:rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-staff",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "based-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.root='/home/jupyter/FINAL/data/2. 모델개발용자료_final.txt'\n",
    "        self.batch_size=728\n",
    "        self.device='cuda'\n",
    "    \n",
    "args = arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cosmetic-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/FINAL/albert',\n",
       " '/home/jupyter/FINAL/asbart',\n",
       " '/home/jupyter/FINAL/asbart_2',\n",
       " '/home/jupyter/FINAL/funnel',\n",
       " '/home/jupyter/FINAL/kobert',\n",
       " '/home/jupyter/FINAL/kogpt2',\n",
       " '/home/jupyter/FINAL/kogpt3',\n",
       " '/home/jupyter/FINAL/mlbert',\n",
       " '/home/jupyter/FINAL/mlbert_2']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths = [\n",
    "    '/home/jupyter/FINAL/albert',\n",
    "    '/home/jupyter/FINAL/asbart',\n",
    "    '/home/jupyter/FINAL/asbart_2',\n",
    "    '/home/jupyter/FINAL/funnel',\n",
    "    '/home/jupyter/FINAL/kobert',\n",
    "    '/home/jupyter/FINAL/kogpt2',\n",
    "    '/home/jupyter/FINAL/kogpt3',\n",
    "    '/home/jupyter/FINAL/mlbert',\n",
    "    '/home/jupyter/FINAL/mlbert_2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "artistic-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/home/jupyter/FINAL/mlbert_2/id2cat.json'), 'r') as f:\n",
    "    id2cat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "superb-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(args.root, sep='|', encoding='cp949')\n",
    "doc_id, doc = data.index.tolist(), data[['text_obj', 'text_mthd', 'text_deal']].fillna('')\n",
    "doc = doc.apply(lambda x: ' '.join(x), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "electrical-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Data Loader\n",
    "test_set = EnsembleDataset(doc, doc_id, **tokenizers,\n",
    "                           max_len=50)\n",
    "test_loader = DataLoader(test_set, batch_size=512, num_workers=4,\n",
    "                         shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "social-lucas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0/9 albert_FCE: 100%|█████████████████████████████████████████████| 196/196 [00:59<00:00,  3.30it/s]\n",
      "1/9 asbart_FCE: 100%|█████████████████████████████████████████████| 196/196 [02:50<00:00,  1.15it/s]\n",
      "2/9 asbart_FCE: 100%|█████████████████████████████████████████████| 196/196 [02:52<00:00,  1.13it/s]\n",
      "3/9 funnel_CE: 100%|██████████████████████████████████████████████| 196/196 [01:08<00:00,  2.85it/s]\n",
      "4/9 kobert_FCE: 100%|█████████████████████████████████████████████| 196/196 [00:47<00:00,  4.17it/s]\n",
      "5/9 kogpt2_FCE: 100%|█████████████████████████████████████████████| 196/196 [00:59<00:00,  3.29it/s]\n",
      "6/9 kogpt3_CE: 100%|██████████████████████████████████████████████| 196/196 [00:59<00:00,  3.29it/s]\n",
      "7/9 mlbert_CE: 100%|██████████████████████████████████████████████| 196/196 [00:47<00:00,  4.15it/s]\n",
      "8/9 mlbert_FCE: 100%|█████████████████████████████████████████████| 196/196 [00:47<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "num_classes=225\n",
    "\n",
    "estimators=len(model_paths)\n",
    "\n",
    "base_model_outputs = []\n",
    "\n",
    "doc_ids = None\n",
    "\n",
    "for e, path in enumerate(model_paths):\n",
    "    model_path = os.path.join(path, f'weights/best_loss.pth.tar')\n",
    "    config_path = os.path.join(path, 'config.json')\n",
    "    with open(config_path, 'r', encoding='utf-8-sig') as f:\n",
    "        model_args = json.load(f)\n",
    "    loss_type = model_args['loss']\n",
    "    model_type = model_args['model']\n",
    "    if 'sample_dist' in model_args.keys():\n",
    "        dist = model_args['sample_dist']\n",
    "        model_name = '_'.join([model_type, loss_type, dist])\n",
    "    else:\n",
    "        model_name = '_'.join([model_type, loss_type])\n",
    "    backbone = backbones[model_args['model']]\n",
    "    model = load_model(model_type=model_args['model'],\n",
    "                       backbone=copy(backbone),\n",
    "                       num_classes=num_classes,\n",
    "                       num_layers=model_args['n_layers'], \n",
    "                       dr_rate=model_args['dr_rate'],\n",
    "                       bias=True,\n",
    "                       batchnorm=model_args['batchnorm'],\n",
    "                       layernorm=model_args['layernorm'])\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu')['state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    base_model_output = None\n",
    "    with torch.no_grad():\n",
    "        for inputs, doc_id in tqdm(test_loader, total=len(test_loader), ncols=100, desc=f'{e}/{len(model_paths)-1} {model_name}'):\n",
    "            _inputs = {}\n",
    "            _inputs['input_ids'] = inputs[model_type][:, 0].to(device, non_blocking=True)\n",
    "            _inputs['attention_mask'] = inputs[model_type][:, 1].to(device, non_blocking=True)\n",
    "            if 'bart' not in model_type:\n",
    "                _inputs['token_type_ids'] = inputs[model_type][:, 2].to(device, non_blocking=True)\n",
    "            output = model(**_inputs)\n",
    "            pred = F.softmax(output, dim=1)\n",
    "            if base_model_output is None:\n",
    "                base_model_output = pred.clone().cpu()\n",
    "            else:\n",
    "                base_model_output = torch.cat([base_model_output, pred.clone().cpu()], dim=0)\n",
    "            if e==0:\n",
    "                if doc_ids is None:\n",
    "                    doc_ids = doc_id\n",
    "                else:\n",
    "                    doc_ids = torch.cat([doc_ids, doc_id])\n",
    "    base_model_outputs.append(base_model_output)\n",
    "base_model_outputs = torch.stack(base_model_outputs)\n",
    "\n",
    "\n",
    "ensemble_output_mean = torch.mean(base_model_outputs, dim=0)\n",
    "output_cat = list(map(lambda x: id2cat[str(x)], ensemble_output_mean.argmax(1).cpu().tolist()))\n",
    "data[['digit_1', 'digit_2', 'digit_3']] = pd.DataFrame(list(zip(*[map(lambda x: x[0], output_cat),\n",
    "                                                                  map(lambda x: x[1:3], output_cat),\n",
    "                                                                  map(lambda x: x[3:], output_cat)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "baking-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "random-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./submit_0413_final.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "frequent-trauma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000001</td>\n",
       "      <td>I</td>\n",
       "      <td>56</td>\n",
       "      <td>561</td>\n",
       "      <td>치킨전문점에서</td>\n",
       "      <td>고객의주문에의해</td>\n",
       "      <td>치킨판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000002</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>466</td>\n",
       "      <td>산업공구</td>\n",
       "      <td>다른 소매업자에게</td>\n",
       "      <td>철물 수공구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000003</td>\n",
       "      <td>S</td>\n",
       "      <td>94</td>\n",
       "      <td>949</td>\n",
       "      <td>절에서</td>\n",
       "      <td>신도을 대상으로</td>\n",
       "      <td>불교단체운영</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_000004</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>영업장에서</td>\n",
       "      <td>고객요구로</td>\n",
       "      <td>자동차튜닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_000005</td>\n",
       "      <td>I</td>\n",
       "      <td>56</td>\n",
       "      <td>562</td>\n",
       "      <td>실내포장마차에서</td>\n",
       "      <td>접객시설을 갖추고</td>\n",
       "      <td>소주,맥주제공</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id_000006</td>\n",
       "      <td>C</td>\n",
       "      <td>18</td>\n",
       "      <td>181</td>\n",
       "      <td>철,아크릴,포맥스</td>\n",
       "      <td>스크린인쇄</td>\n",
       "      <td>명판</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id_000007</td>\n",
       "      <td>I</td>\n",
       "      <td>56</td>\n",
       "      <td>561</td>\n",
       "      <td>음식점</td>\n",
       "      <td>접객시설가지고</td>\n",
       "      <td>조개구이판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id_000008</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>259</td>\n",
       "      <td>스테인레스를</td>\n",
       "      <td>프레스가공하여제조</td>\n",
       "      <td>주방용품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id_000009</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>수리</td>\n",
       "      <td>서비스센터에서</td>\n",
       "      <td>전문수리 수입차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id_000010</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>259</td>\n",
       "      <td>약품(화공), 미싱</td>\n",
       "      <td>완성품입고, 수선</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id_000011</td>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>107</td>\n",
       "      <td>밀가루, 쇼트닝</td>\n",
       "      <td>원재료입고, 반죽</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id_000012</td>\n",
       "      <td>S</td>\n",
       "      <td>96</td>\n",
       "      <td>961</td>\n",
       "      <td>이발소에서</td>\n",
       "      <td>일반인 대상으로</td>\n",
       "      <td>고객의 두발을 손질함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id_000013</td>\n",
       "      <td>C</td>\n",
       "      <td>16</td>\n",
       "      <td>162</td>\n",
       "      <td>목재</td>\n",
       "      <td>고객의 요구에 따라</td>\n",
       "      <td>무대장치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id_000014</td>\n",
       "      <td>Q</td>\n",
       "      <td>86</td>\n",
       "      <td>862</td>\n",
       "      <td>의원에서</td>\n",
       "      <td>소아,청소년을대상으로</td>\n",
       "      <td>진료서비스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id_000015</td>\n",
       "      <td>M</td>\n",
       "      <td>72</td>\n",
       "      <td>729</td>\n",
       "      <td>산업공단조성시 의뢰받아</td>\n",
       "      <td>사무실에서</td>\n",
       "      <td>측량，토목설계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id_000016</td>\n",
       "      <td>S</td>\n",
       "      <td>96</td>\n",
       "      <td>961</td>\n",
       "      <td>태국전통마사지숍</td>\n",
       "      <td>일반고객대상</td>\n",
       "      <td>마사지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id_000017</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>465</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>관련사용자에게</td>\n",
       "      <td>선박엔진부품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id_000018</td>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>107</td>\n",
       "      <td>상가에서</td>\n",
       "      <td>주문에 의해</td>\n",
       "      <td>반찬,도시락</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id_000019</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>476</td>\n",
       "      <td>문구용품에서</td>\n",
       "      <td>일반인대상</td>\n",
       "      <td>문구류,사무용품 소매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id_000020</td>\n",
       "      <td>M</td>\n",
       "      <td>72</td>\n",
       "      <td>721</td>\n",
       "      <td>엔지니어링및 건축관련</td>\n",
       "      <td>고객 요청에 의해</td>\n",
       "      <td>도면설계</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AI_id digit_1 digit_2 digit_3      text_obj    text_mthd    text_deal\n",
       "0   id_000001       I      56     561       치킨전문점에서     고객의주문에의해         치킨판매\n",
       "1   id_000002       G      46     466          산업공구    다른 소매업자에게       철물 수공구\n",
       "2   id_000003       S      94     949           절에서     신도을 대상으로       불교단체운영\n",
       "3   id_000004       S      95     952         영업장에서        고객요구로        자동차튜닝\n",
       "4   id_000005       I      56     562      실내포장마차에서    접객시설을 갖추고      소주,맥주제공\n",
       "5   id_000006       C      18     181     철,아크릴,포맥스        스크린인쇄           명판\n",
       "6   id_000007       I      56     561           음식점      접객시설가지고       조개구이판매\n",
       "7   id_000008       C      25     259        스테인레스를    프레스가공하여제조         주방용품\n",
       "8   id_000009       S      95     952            수리      서비스센터에서     전문수리 수입차\n",
       "9   id_000010       C      25     259    약품(화공), 미싱    완성품입고, 수선          NaN\n",
       "10  id_000011       C      10     107      밀가루, 쇼트닝    원재료입고, 반죽          NaN\n",
       "11  id_000012       S      96     961         이발소에서     일반인 대상으로  고객의 두발을 손질함\n",
       "12  id_000013       C      16     162            목재   고객의 요구에 따라         무대장치\n",
       "13  id_000014       Q      86     862          의원에서  소아,청소년을대상으로        진료서비스\n",
       "14  id_000015       M      72     729  산업공단조성시 의뢰받아        사무실에서      측량，토목설계\n",
       "15  id_000016       S      96     961      태국전통마사지숍       일반고객대상          마사지\n",
       "16  id_000017       G      46     465         사업장에서      관련사용자에게       선박엔진부품\n",
       "17  id_000018       C      10     107          상가에서       주문에 의해       반찬,도시락\n",
       "18  id_000019       G      47     476        문구용품에서        일반인대상  문구류,사무용품 소매\n",
       "19  id_000020       M      72     721   엔지니어링및 건축관련    고객 요청에 의해         도면설계"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
