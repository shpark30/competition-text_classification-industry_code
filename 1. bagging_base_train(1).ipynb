{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82d44bb",
   "metadata": {},
   "source": [
    "# Import & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b9df2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_path: /home/jupyter/parksh/src/runs/train/exp25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import statistics\n",
    "import csv\n",
    "from typing import Optional, Union, List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertModel, GPTJForCausalLM, GPT2LMHeadModel\n",
    "from transformers import PreTrainedTokenizerFast, AutoTokenizer\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "import gluonnlp as nlp\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from loss import CrossEntropy, FocalCrossEntropy, label2target\n",
    "from utils import create_logger, create_directory, increment_path, save_performance_graph\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # https://github.com/pytorch/pytorch/issues/57273\n",
    "\n",
    "ROOT = Path(os.getcwd())\n",
    "DATA = ROOT.parents[1]\n",
    "save_dir = increment_path(Path(ROOT) / 'runs'/ 'train' / 'exp')\n",
    "\n",
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.root = DATA / 'data' / '1. 실습용자료_hsp2.txt'\n",
    "        self.project = save_dir\n",
    "        self.num_test = 50000\n",
    "        self.upsample='shuffle'\n",
    "        self.minimum=100\n",
    "\n",
    "        self.workers = 4\n",
    "        self.batch_size = 512\n",
    "        \n",
    "        self.model='ensemble'\n",
    "        self.estimators=10\n",
    "        self.num_samples=150000\n",
    "        self.sub_valid_ratio=0.1\n",
    "        self.epochs=50\n",
    "        self.patience=5\n",
    "        self.loss='FCE'\n",
    "        self.learning_rate=0.1e-4\n",
    "        self.lr_scheduler='constant_with_warmup'\n",
    "        self.warmup_step=1000\n",
    "        self.optimizer='AdamW'\n",
    "        self.beta1=0.9\n",
    "        self.beta2=0.99\n",
    "        self.weight_decay=0.001\n",
    "        self.eps=1e-8\n",
    "        self.seed=42\n",
    "        self.max_len=50\n",
    "        \n",
    "        self.device='cuda'\n",
    "    \n",
    "args=arguments()\n",
    "    \n",
    "gpu_num = '0' if args.device=='cuda' else '1'\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = gpu_num\n",
    "\n",
    "# save config\n",
    "create_directory(args.project)\n",
    "print('output_path:', args.project)\n",
    "with open(args.project / 'config.json', 'w', encoding='utf-8-sig') as f:\n",
    "    arg_dict = {k: (str(v) if type(v)==pathlib.PosixPath else v) for k, v in args.__dict__.items()}\n",
    "    json.dump(arg_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51b483",
   "metadata": {},
   "source": [
    "# Data Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b84348",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d70125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0000001</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 부분정비</td>\n",
       "      <td>타이어 오일 교환</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0000002</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>472</td>\n",
       "      <td>상점 내에서</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>채소 과일 판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0000003</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>467</td>\n",
       "      <td>절단하여 사업체에도 매</td>\n",
       "      <td>공업용 고무를 가지고</td>\n",
       "      <td>합성고무도 매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0000004</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>475</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>열쇠 잠금장치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0000005</td>\n",
       "      <td>Q</td>\n",
       "      <td>87</td>\n",
       "      <td>872</td>\n",
       "      <td>어린이집</td>\n",
       "      <td>보호자의 위탁을 받아</td>\n",
       "      <td>취학 전 아동보육</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AI_id digit_1  digit_2  digit_3      text_obj    text_mthd  text_deal\n",
       "0  id_0000001       S       95      952         카센터에서     자동차 부분정비  타이어 오일 교환\n",
       "1  id_0000002       G       47      472        상점 내에서    일반인을 대상으로   채소 과일 판매\n",
       "2  id_0000003       G       46      467  절단하여 사업체에도 매  공업용 고무를 가지고    합성고무도 매\n",
       "3  id_0000004       G       47      475         영업점에서     일반 소비자에게    열쇠 잠금장치\n",
       "4  id_0000005       Q       87      872          어린이집  보호자의 위탁을 받아  취학 전 아동보육"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   AI_id      1000000 non-null  object\n",
      " 1   digit_1    1000000 non-null  object\n",
      " 2   digit_2    1000000 non-null  int64 \n",
      " 3   digit_3    1000000 non-null  int64 \n",
      " 4   text_obj   983323 non-null   object\n",
      " 5   text_mthd  956381 non-null   object\n",
      " 6   text_deal  932345 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 53.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(args.root, sep='|', encoding='utf-8')\n",
    "display(data.head())\n",
    "display(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37884b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0000001</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 부분정비</td>\n",
       "      <td>타이어 오일 교환</td>\n",
       "      <td>S95952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0000002</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>472</td>\n",
       "      <td>상점 내에서</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>채소 과일 판매</td>\n",
       "      <td>G47472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0000003</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>467</td>\n",
       "      <td>절단하여 사업체에도 매</td>\n",
       "      <td>공업용 고무를 가지고</td>\n",
       "      <td>합성고무도 매</td>\n",
       "      <td>G46467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0000004</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>475</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>열쇠 잠금장치</td>\n",
       "      <td>G47475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0000005</td>\n",
       "      <td>Q</td>\n",
       "      <td>87</td>\n",
       "      <td>872</td>\n",
       "      <td>어린이집</td>\n",
       "      <td>보호자의 위탁을 받아</td>\n",
       "      <td>취학 전 아동보육</td>\n",
       "      <td>Q87872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AI_id digit_1 digit_2 digit_3      text_obj    text_mthd  text_deal  \\\n",
       "0  id_0000001       S      95     952         카센터에서     자동차 부분정비  타이어 오일 교환   \n",
       "1  id_0000002       G      47     472        상점 내에서    일반인을 대상으로   채소 과일 판매   \n",
       "2  id_0000003       G      46     467  절단하여 사업체에도 매  공업용 고무를 가지고    합성고무도 매   \n",
       "3  id_0000004       G      47     475         영업점에서     일반 소비자에게    열쇠 잠금장치   \n",
       "4  id_0000005       Q      87     872          어린이집  보호자의 위탁을 받아  취학 전 아동보육   \n",
       "\n",
       "    digit  \n",
       "0  S95952  \n",
       "1  G47472  \n",
       "2  G46467  \n",
       "3  G47475  \n",
       "4  Q87872  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대-중-소 이어붙이기\n",
    "def num2code(num, digits=0):\n",
    "    \"\"\" int타입의 데이터를 일정한 자릿수(digits)의 코드값으로 변환 \"\"\"\n",
    "    num = str(num)\n",
    "    code = '0'*(digits-len(num)) + num\n",
    "    return code\n",
    "\n",
    "data['digit_2'] = data['digit_2'].apply(lambda x:  num2code(x, 2))\n",
    "data['digit_3'] = data['digit_3'].apply(lambda x:  num2code(x, 3))\n",
    "data['digit'] = data['digit_1'] + data['digit_2'] + data['digit_3']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218cdbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0000001</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 부분정비</td>\n",
       "      <td>타이어 오일 교환</td>\n",
       "      <td>S95952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0000002</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>472</td>\n",
       "      <td>상점 내에서</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>채소 과일 판매</td>\n",
       "      <td>G47472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0000003</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>467</td>\n",
       "      <td>절단하여 사업체에도 매</td>\n",
       "      <td>공업용 고무를 가지고</td>\n",
       "      <td>합성고무도 매</td>\n",
       "      <td>G46467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0000004</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>475</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>열쇠 잠금장치</td>\n",
       "      <td>G47475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0000005</td>\n",
       "      <td>Q</td>\n",
       "      <td>87</td>\n",
       "      <td>872</td>\n",
       "      <td>어린이집</td>\n",
       "      <td>보호자의 위탁을 받아</td>\n",
       "      <td>취학 전 아동보육</td>\n",
       "      <td>Q87872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999993</th>\n",
       "      <td>id_0999994</td>\n",
       "      <td>C</td>\n",
       "      <td>32</td>\n",
       "      <td>320</td>\n",
       "      <td>카본 열선 퀼팅 구조체</td>\n",
       "      <td>조립 배열 봉제하여</td>\n",
       "      <td>의료용 매트리스</td>\n",
       "      <td>C32320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999994</th>\n",
       "      <td>id_0999995</td>\n",
       "      <td>L</td>\n",
       "      <td>68</td>\n",
       "      <td>681</td>\n",
       "      <td>사무실에서</td>\n",
       "      <td>NaN</td>\n",
       "      <td>비주거용 임대</td>\n",
       "      <td>L68681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>id_0999996</td>\n",
       "      <td>C</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>제품 입고</td>\n",
       "      <td>워싱</td>\n",
       "      <td>청바지 워싱</td>\n",
       "      <td>C13134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>id_0999998</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>474</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>여성의류 판매</td>\n",
       "      <td>G47474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>id_1000000</td>\n",
       "      <td>I</td>\n",
       "      <td>56</td>\n",
       "      <td>561</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>접객시설을 갖추고</td>\n",
       "      <td>한식 미역국 판매</td>\n",
       "      <td>I56561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>641457 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AI_id digit_1 digit_2 digit_3      text_obj    text_mthd  \\\n",
       "0       id_0000001       S      95     952         카센터에서     자동차 부분정비   \n",
       "1       id_0000002       G      47     472        상점 내에서    일반인을 대상으로   \n",
       "2       id_0000003       G      46     467  절단하여 사업체에도 매  공업용 고무를 가지고   \n",
       "3       id_0000004       G      47     475         영업점에서     일반 소비자에게   \n",
       "4       id_0000005       Q      87     872          어린이집  보호자의 위탁을 받아   \n",
       "...            ...     ...     ...     ...           ...          ...   \n",
       "999993  id_0999994       C      32     320  카본 열선 퀼팅 구조체   조립 배열 봉제하여   \n",
       "999994  id_0999995       L      68     681         사무실에서          NaN   \n",
       "999995  id_0999996       C      13     134         제품 입고           워싱   \n",
       "999997  id_0999998       G      47     474         영업점에서     일반 소비자에게   \n",
       "999999  id_1000000       I      56     561         사업장에서    접객시설을 갖추고   \n",
       "\n",
       "        text_deal   digit  \n",
       "0       타이어 오일 교환  S95952  \n",
       "1        채소 과일 판매  G47472  \n",
       "2         합성고무도 매  G46467  \n",
       "3         열쇠 잠금장치  G47475  \n",
       "4       취학 전 아동보육  Q87872  \n",
       "...           ...     ...  \n",
       "999993   의료용 매트리스  C32320  \n",
       "999994    비주거용 임대  L68681  \n",
       "999995     청바지 워싱  C13134  \n",
       "999997    여성의류 판매  G47474  \n",
       "999999  한식 미역국 판매  I56561  \n",
       "\n",
       "[641457 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 행 제거\n",
    "data = data.drop_duplicates(subset=['text_obj', 'text_mthd', 'text_deal', 'digit'], keep='first')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f9796",
   "metadata": {},
   "source": [
    "## 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce803c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   AI_id      100000 non-null  object \n",
      " 1   digit_1    0 non-null       float64\n",
      " 2   digit_2    0 non-null       float64\n",
      " 3   digit_3    0 non-null       float64\n",
      " 4   text_obj   98189 non-null   object \n",
      " 5   text_mthd  97032 non-null   object \n",
      " 6   text_deal  93839 non-null   object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# 제출용 데이터의 결측치 분포 확인하기\n",
    "submit = pd.read_csv(DATA / 'data/2. 모델개발용자료.txt', sep='|', encoding='cp949')\n",
    "submit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be59f02a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_obj  text_mthd  text_deal\n",
       "False     False      False        92985\n",
       "                     True          2317\n",
       "          True       True          2294\n",
       "True      False      True          1550\n",
       "False     True       False          593\n",
       "True      False      False          180\n",
       "          True       False           81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_obj = submit['text_obj'].isna()\n",
    "na_mthd = submit['text_mthd'].isna()\n",
    "na_deal = submit['text_deal'].isna()\n",
    "na_text = pd.concat([na_obj, na_mthd, na_deal], axis=1)\n",
    "na_text.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4ebe3",
   "metadata": {},
   "source": [
    "nan이 없는 데이터 : 92985개\n",
    "\n",
    "1개만 nan\n",
    " - obj만 nan : 180\n",
    " - mthd만 nan : 593\n",
    " - deal만 nan : 2317\n",
    " \n",
    "2개 nan\n",
    " - obj mthd : 81\n",
    " - obj deal : 1550\n",
    " - mthd deal : 2294\n",
    " \n",
    "nan이 발생하는 모든 경우의 수가 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5299d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0000001</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 부분정비</td>\n",
       "      <td>타이어 오일 교환</td>\n",
       "      <td>S95952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0000002</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>472</td>\n",
       "      <td>상점 내에서</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>채소 과일 판매</td>\n",
       "      <td>G47472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0000003</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>467</td>\n",
       "      <td>절단하여 사업체에도 매</td>\n",
       "      <td>공업용 고무를 가지고</td>\n",
       "      <td>합성고무도 매</td>\n",
       "      <td>G46467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0000004</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>475</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>열쇠 잠금장치</td>\n",
       "      <td>G47475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0000005</td>\n",
       "      <td>Q</td>\n",
       "      <td>87</td>\n",
       "      <td>872</td>\n",
       "      <td>어린이집</td>\n",
       "      <td>보호자의 위탁을 받아</td>\n",
       "      <td>취학 전 아동보육</td>\n",
       "      <td>Q87872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999993</th>\n",
       "      <td>id_0999994</td>\n",
       "      <td>C</td>\n",
       "      <td>32</td>\n",
       "      <td>320</td>\n",
       "      <td>카본 열선 퀼팅 구조체</td>\n",
       "      <td>조립 배열 봉제하여</td>\n",
       "      <td>의료용 매트리스</td>\n",
       "      <td>C32320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999994</th>\n",
       "      <td>id_0999995</td>\n",
       "      <td>L</td>\n",
       "      <td>68</td>\n",
       "      <td>681</td>\n",
       "      <td>사무실에서</td>\n",
       "      <td></td>\n",
       "      <td>비주거용 임대</td>\n",
       "      <td>L68681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>id_0999996</td>\n",
       "      <td>C</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>제품 입고</td>\n",
       "      <td>워싱</td>\n",
       "      <td>청바지 워싱</td>\n",
       "      <td>C13134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>id_0999998</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>474</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>여성의류 판매</td>\n",
       "      <td>G47474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>id_1000000</td>\n",
       "      <td>I</td>\n",
       "      <td>56</td>\n",
       "      <td>561</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>접객시설을 갖추고</td>\n",
       "      <td>한식 미역국 판매</td>\n",
       "      <td>I56561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>641457 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AI_id digit_1 digit_2 digit_3      text_obj    text_mthd  \\\n",
       "0       id_0000001       S      95     952         카센터에서     자동차 부분정비   \n",
       "1       id_0000002       G      47     472        상점 내에서    일반인을 대상으로   \n",
       "2       id_0000003       G      46     467  절단하여 사업체에도 매  공업용 고무를 가지고   \n",
       "3       id_0000004       G      47     475         영업점에서     일반 소비자에게   \n",
       "4       id_0000005       Q      87     872          어린이집  보호자의 위탁을 받아   \n",
       "...            ...     ...     ...     ...           ...          ...   \n",
       "999993  id_0999994       C      32     320  카본 열선 퀼팅 구조체   조립 배열 봉제하여   \n",
       "999994  id_0999995       L      68     681         사무실에서                \n",
       "999995  id_0999996       C      13     134         제품 입고           워싱   \n",
       "999997  id_0999998       G      47     474         영업점에서     일반 소비자에게   \n",
       "999999  id_1000000       I      56     561         사업장에서    접객시설을 갖추고   \n",
       "\n",
       "        text_deal   digit  \n",
       "0       타이어 오일 교환  S95952  \n",
       "1        채소 과일 판매  G47472  \n",
       "2         합성고무도 매  G46467  \n",
       "3         열쇠 잠금장치  G47475  \n",
       "4       취학 전 아동보육  Q87872  \n",
       "...           ...     ...  \n",
       "999993   의료용 매트리스  C32320  \n",
       "999994    비주거용 임대  L68681  \n",
       "999995     청바지 워싱  C13134  \n",
       "999997    여성의류 판매  G47474  \n",
       "999999  한식 미역국 판매  I56561  \n",
       "\n",
       "[641457 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 채우기\n",
    "data = data.fillna('')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe7cfb",
   "metadata": {},
   "source": [
    "## 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26628d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카테고리 개수: 225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>digit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0000001</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 부분정비</td>\n",
       "      <td>타이어 오일 교환</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0000002</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>472</td>\n",
       "      <td>상점 내에서</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>채소 과일 판매</td>\n",
       "      <td>G47472</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0000003</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>467</td>\n",
       "      <td>절단하여 사업체에도 매</td>\n",
       "      <td>공업용 고무를 가지고</td>\n",
       "      <td>합성고무도 매</td>\n",
       "      <td>G46467</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0000004</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>475</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>열쇠 잠금장치</td>\n",
       "      <td>G47475</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0000005</td>\n",
       "      <td>Q</td>\n",
       "      <td>87</td>\n",
       "      <td>872</td>\n",
       "      <td>어린이집</td>\n",
       "      <td>보호자의 위탁을 받아</td>\n",
       "      <td>취학 전 아동보육</td>\n",
       "      <td>Q87872</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999993</th>\n",
       "      <td>id_0999994</td>\n",
       "      <td>C</td>\n",
       "      <td>32</td>\n",
       "      <td>320</td>\n",
       "      <td>카본 열선 퀼팅 구조체</td>\n",
       "      <td>조립 배열 봉제하여</td>\n",
       "      <td>의료용 매트리스</td>\n",
       "      <td>C32320</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999994</th>\n",
       "      <td>id_0999995</td>\n",
       "      <td>L</td>\n",
       "      <td>68</td>\n",
       "      <td>681</td>\n",
       "      <td>사무실에서</td>\n",
       "      <td></td>\n",
       "      <td>비주거용 임대</td>\n",
       "      <td>L68681</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>id_0999996</td>\n",
       "      <td>C</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>제품 입고</td>\n",
       "      <td>워싱</td>\n",
       "      <td>청바지 워싱</td>\n",
       "      <td>C13134</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>id_0999998</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>474</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>여성의류 판매</td>\n",
       "      <td>G47474</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>id_1000000</td>\n",
       "      <td>I</td>\n",
       "      <td>56</td>\n",
       "      <td>561</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>접객시설을 갖추고</td>\n",
       "      <td>한식 미역국 판매</td>\n",
       "      <td>I56561</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>641457 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AI_id digit_1 digit_2 digit_3      text_obj    text_mthd  \\\n",
       "0       id_0000001       S      95     952         카센터에서     자동차 부분정비   \n",
       "1       id_0000002       G      47     472        상점 내에서    일반인을 대상으로   \n",
       "2       id_0000003       G      46     467  절단하여 사업체에도 매  공업용 고무를 가지고   \n",
       "3       id_0000004       G      47     475         영업점에서     일반 소비자에게   \n",
       "4       id_0000005       Q      87     872          어린이집  보호자의 위탁을 받아   \n",
       "...            ...     ...     ...     ...           ...          ...   \n",
       "999993  id_0999994       C      32     320  카본 열선 퀼팅 구조체   조립 배열 봉제하여   \n",
       "999994  id_0999995       L      68     681         사무실에서                \n",
       "999995  id_0999996       C      13     134         제품 입고           워싱   \n",
       "999997  id_0999998       G      47     474         영업점에서     일반 소비자에게   \n",
       "999999  id_1000000       I      56     561         사업장에서    접객시설을 갖추고   \n",
       "\n",
       "        text_deal   digit  label  \n",
       "0       타이어 오일 교환  S95952    221  \n",
       "1        채소 과일 판매  G47472    126  \n",
       "2         합성고무도 매  G46467    123  \n",
       "3         열쇠 잠금장치  G47475    129  \n",
       "4       취학 전 아동보육  Q87872    212  \n",
       "...           ...     ...    ...  \n",
       "999993   의료용 매트리스  C32320     90  \n",
       "999994    비주거용 임대  L68681    168  \n",
       "999995     청바지 워싱  C13134     26  \n",
       "999997    여성의류 판매  G47474    128  \n",
       "999999  한식 미역국 판매  I56561    147  \n",
       "\n",
       "[641457 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 인코딩\n",
    "unique_digit = data['digit'].sort_values().drop_duplicates().tolist()\n",
    "print('카테고리 개수:', len(unique_digit))\n",
    "cat2id, id2cat = {}, {}\n",
    "for i, cat in enumerate(unique_digit):\n",
    "    cat2id[cat] = i\n",
    "    id2cat[i] = cat\n",
    "data['label'] = data['digit'].apply(lambda x: cat2id[x])\n",
    "data\n",
    "        \n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# unique_digit = data['digit'].sort_values().drop_duplicates().tolist()\n",
    "# print('카테고리 개수:', len(unique_digit))\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# le.fit(unique_digit)\n",
    "# print('첫 5개 카테고리:', list(le.classes_)[:5])\n",
    "# print('인코딩 id:', le.transform(list(le.classes_)[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d52ed",
   "metadata": {},
   "source": [
    "## 학습 데이터 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fea6bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>62654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223</td>\n",
       "      <td>23020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>22092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>21972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148</td>\n",
       "      <td>20685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label    cnt\n",
       "0      147  62654\n",
       "1      223  23020\n",
       "2      128  22092\n",
       "3      132  21972\n",
       "4      148  20685\n",
       "..     ...    ...\n",
       "220     11      3\n",
       "221    138      3\n",
       "222    164      2\n",
       "223      6      1\n",
       "224      7      1\n",
       "\n",
       "[225 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist = data['label'].value_counts().reset_index()\n",
    "train_dist.columns = ['label', 'cnt']\n",
    "train_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d586bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균: 2850.92\n",
      "1분위 수: 1.0\n",
      "2분위 수: 218.0\n",
      "3분위 수(중앙값): 793.0\n",
      "4분위 수: 2681.0\n",
      "5분위 수: 62654.0\n",
      "\n",
      "box plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('평균:', train_dist['cnt'].mean())\n",
    "print('1분위 수:', train_dist['cnt'].quantile(0))\n",
    "print('2분위 수:', train_dist['cnt'].quantile(0.25))\n",
    "print('3분위 수(중앙값):', train_dist['cnt'].quantile(0.5))\n",
    "print('4분위 수:', train_dist['cnt'].quantile(0.75))\n",
    "print('5분위 수:', train_dist['cnt'].quantile(1))\n",
    "\n",
    "print('\\nbox plot')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "train_dist['cnt'].plot(kind='box')\n",
    "plt.title(\"Data Distribution\")\n",
    "# plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"# Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78713bf6",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7b3674",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 수: 591511\n",
      "test data 수: 49946\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(frame, test_ratio=0.1, seed=42):\n",
    "    \"\"\"\n",
    "    temp_df \n",
    "    \"\"\"\n",
    "    train, test = pd.DataFrame(), pd.DataFrame()\n",
    "    for lb in frame['label'].unique():\n",
    "        # (lb) 카테고리의 데이터 순서 섞기\n",
    "        temp_df_l = frame[frame['label']==lb].sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "        \n",
    "        # 데이터 나누기\n",
    "        if len(temp_df_l) < 3:\n",
    "            # 데이터 수가 3개 미만인 카테고리는 모두 훈련 데이터로 활용한다. \n",
    "            train = pd.concat([train, temp_df_l])\n",
    "        else:\n",
    "            # train과 test를 slice할 index 구하기\n",
    "            if len(temp_df_l) <= 5:\n",
    "                slice_idx = 1\n",
    "            elif len(temp_df_l) <= 10:\n",
    "                slice_idx = 2\n",
    "            elif len(temp_df_l) < 100:\n",
    "                a, b = 8/90, 10/9\n",
    "                slice_idx = int(a*len(temp_df_l) + b)\n",
    "            else: # len(ttemp) >= 100\n",
    "                slice_idx = int(len(temp_df_l)*test_ratio)\n",
    "                \n",
    "            # train, test 나누기\n",
    "            train = pd.concat([train, temp_df_l.iloc[slice_idx:, :]])\n",
    "            test = pd.concat([test, temp_df_l.iloc[:slice_idx, :]])\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    test.reset_index(drop=True, inplace=True)       \n",
    "    return train, test\n",
    "test_ratio = args.num_test/len(data)\n",
    "train, test = train_test_split(data, test_ratio=test_ratio, seed=args.seed)\n",
    "\n",
    "print('train data 수:', len(train))\n",
    "print('test data 수:', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fdfcf",
   "metadata": {},
   "source": [
    "## Sub Sampling with BootStrap : 복원추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73441524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>57771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223</td>\n",
       "      <td>21226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>20370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>20260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148</td>\n",
       "      <td>19073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label    cnt\n",
       "0      147  57771\n",
       "1      223  21226\n",
       "2      128  20370\n",
       "3      132  20260\n",
       "4      148  19073\n",
       "..     ...    ...\n",
       "220    164      2\n",
       "221     11      2\n",
       "222    138      2\n",
       "223      6      1\n",
       "224      7      1\n",
       "\n",
       "[225 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 카테고리별 데이터 수\n",
    "dist = train['label'].value_counts().to_frame().reset_index()\n",
    "dist.columns = ['label', 'cnt']\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0481e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:25<00:00,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub data 수: 10\n",
      "sub data 카테고리 수: [(0, 225), (1, 225), (2, 225), (3, 225), (4, 225), (5, 225), (6, 225), (7, 225), (8, 225), (9, 225)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train 데이터셋에서 랜덤샘플링해 (args.estimators)개 서브데이터셋을 구성한다..\n",
    "서브데이터셋은 모든 카테고리를 포함해야 하며, 데이터의 수는 (Train 데이터 수/args.estimators)로 한다.\n",
    "완전히 random하게 데이터를 샘플하면 데이터가 적은 카테고리를 포함하지 않는 서브데이터셋이 생긴다.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "1. Sub sampling을 먼저 한 다음\n",
    "2. Sub train-valid split\n",
    "3. Sub train set에 대해서 upsampling 진행(다양한 Upsample 적용)\n",
    "\"\"\"\n",
    "\n",
    "def bootstrap(data, estimators, num_samples=100000, min_cat_data=2, seed=42):\n",
    "    def _sub_sampling(data, seed, min_cat_data, t_sampled):\n",
    "        n = min_cat_data\n",
    "        e = t_sampled/len(data)\n",
    "        random.seed(seed)\n",
    "        sub_data = pd.DataFrame()\n",
    "        for lb in data['label'].unique().tolist():\n",
    "            data_lb = data[data['label']==lb].copy()\n",
    "            seed_lb = random.randint(0, 1000)\n",
    "            if len(data_lb) <= n:\n",
    "                n_sampled = len(data_lb)\n",
    "            else:\n",
    "                a, b = (100*e-n)/(100-n), 100*n*(1-e)/(100-n)\n",
    "                n_sampled = int(a*len(data_lb) + b)\n",
    "\n",
    "    #         if len(data_lb) <= 2:\n",
    "    #             n_sampled = len(data_lb)\n",
    "    #         elif len(data_lb) == 3:\n",
    "    #             n_sampled = 2 # 2개 샘플\n",
    "    #         elif len(data_lb) <= 5:\n",
    "    #             n_sampled = len(data_lb)-2 # 2개 빼고 샘플\n",
    "    #         elif len(data_lb) <= 10:\n",
    "    #             n_sampled = 5 # 5개 샘플\n",
    "    #         elif len(data_lb) <= 100:\n",
    "    #             a, b = (100*e-5)/90, (40-100*e)/9\n",
    "    #             n_sampled = int(a*len(data_lb) + b)\n",
    "    #         else: # len(ttemp) >= 100\n",
    "    #             n_sampled = int(len(data_lb)*e)\n",
    "            sub_data = pd.concat([sub_data, data_lb.sample(n=n_sampled, random_state=seed_lb)])\n",
    "            sub_data = sub_data.reset_index(drop=True)\n",
    "        return sub_data\n",
    "\n",
    "    sub_data_list = [] # 생성된 서브데이터를 담을 리스트\n",
    "    for estimator in tqdm(range(estimators), total=estimators): # args.estimators 만큼 서브데이터 생성\n",
    "        random.seed(seed*estimator)\n",
    "        seed_i = random.randint(0, 1000)\n",
    "        sub_data = _sub_sampling(data, seed_i, min_cat_data, num_samples)\n",
    "        sub_data_list.append(sub_data)\n",
    "    print('sub data 수:', len(sub_data_list))\n",
    "    print('sub data 카테고리 수:',\n",
    "          [(i, len(sub_data['label'].unique())) for i, sub_data in enumerate(sub_data_list)])\n",
    "    return sub_data_list\n",
    "sub_data_list = bootstrap(train, args.estimators, num_samples=args.num_samples, min_cat_data=2, seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf7651c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>digit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0573838</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>매장에서</td>\n",
       "      <td>고객 의뢰받아</td>\n",
       "      <td>자동차 래핑</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0204165</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>현대 카센터에서</td>\n",
       "      <td>고객 요구에 의해</td>\n",
       "      <td>자동차 내장 수리 타이어 교체</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0590218</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>일반 소비자에게</td>\n",
       "      <td>차 오토바이 배터리 전문수리</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0957467</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>자동차</td>\n",
       "      <td>자동차 종합수리</td>\n",
       "      <td>자동차 수리</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0277033</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 특정 부분을 전문수리</td>\n",
       "      <td>타이어</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38775</th>\n",
       "      <td>id_0761016</td>\n",
       "      <td>C</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>모피</td>\n",
       "      <td>재단</td>\n",
       "      <td>옷 제조</td>\n",
       "      <td>C14142</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38776</th>\n",
       "      <td>id_0551658</td>\n",
       "      <td>C</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>밍크 스킨</td>\n",
       "      <td>선별 및 흠집 제거 형태 고정 절단</td>\n",
       "      <td></td>\n",
       "      <td>C14142</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38777</th>\n",
       "      <td>id_0760691</td>\n",
       "      <td>C</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>모피</td>\n",
       "      <td>재단 봉제 가공하여</td>\n",
       "      <td>모피의류 제조</td>\n",
       "      <td>C14142</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38778</th>\n",
       "      <td>id_0754942</td>\n",
       "      <td>C</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>인조모피</td>\n",
       "      <td>가공</td>\n",
       "      <td>인조 무스탕 가공</td>\n",
       "      <td>C14142</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38779</th>\n",
       "      <td>id_0411686</td>\n",
       "      <td>J</td>\n",
       "      <td>60</td>\n",
       "      <td>601</td>\n",
       "      <td>라디오방송</td>\n",
       "      <td>지상파방송</td>\n",
       "      <td>불교 방송</td>\n",
       "      <td>J60601</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38780 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AI_id digit_1 digit_2 digit_3  text_obj            text_mthd  \\\n",
       "0      id_0573838       S      95     952      매장에서              고객 의뢰받아   \n",
       "1      id_0204165       S      95     952  현대 카센터에서            고객 요구에 의해   \n",
       "2      id_0590218       S      95     952     사업장에서             일반 소비자에게   \n",
       "3      id_0957467       S      95     952       자동차             자동차 종합수리   \n",
       "4      id_0277033       S      95     952     카센터에서      자동차 특정 부분을 전문수리   \n",
       "...           ...     ...     ...     ...       ...                  ...   \n",
       "38775  id_0761016       C      14     142        모피                   재단   \n",
       "38776  id_0551658       C      14     142     밍크 스킨  선별 및 흠집 제거 형태 고정 절단   \n",
       "38777  id_0760691       C      14     142        모피           재단 봉제 가공하여   \n",
       "38778  id_0754942       C      14     142      인조모피                   가공   \n",
       "38779  id_0411686       J      60     601     라디오방송                지상파방송   \n",
       "\n",
       "              text_deal   digit  label  \n",
       "0                자동차 래핑  S95952    221  \n",
       "1      자동차 내장 수리 타이어 교체  S95952    221  \n",
       "2       차 오토바이 배터리 전문수리  S95952    221  \n",
       "3                자동차 수리  S95952    221  \n",
       "4                   타이어  S95952    221  \n",
       "...                 ...     ...    ...  \n",
       "38775              옷 제조  C14142     29  \n",
       "38776                    C14142     29  \n",
       "38777           모피의류 제조  C14142     29  \n",
       "38778         인조 무스탕 가공  C14142     29  \n",
       "38779             불교 방송  J60601    153  \n",
       "\n",
       "[38780 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of Bag(OOB) : random sampling으로 추출되지 않은 데이터는 테스트 데이터에 포함시킨다.\n",
    "def out_of_bag(main_data, sub_data_list):\n",
    "    sub_data_ids = set(pd.concat([sub_data['AI_id'] for sub_data in sub_data_list]).unique())\n",
    "    main_data_ids = set(main_data['AI_id'].tolist())\n",
    "    oob_ids = main_data_ids - sub_data_ids\n",
    "    oob_data = train[train['AI_id'].apply(lambda x: x in oob_ids)]\n",
    "    oob_data = oob_data.reset_index(drop=True)\n",
    "    return oob_data\n",
    "oob_data = out_of_bag(train, sub_data_list)\n",
    "oob_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89e3cd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>digit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0195359</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>세차장에서</td>\n",
       "      <td>고객 요청에 의해</td>\n",
       "      <td>자동차 세차</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0503002</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 내장 설치 전문수리</td>\n",
       "      <td>자동차 수리</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0222579</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>금동 종합 정비 공업사</td>\n",
       "      <td>건설기계장비 및 승용차를 전문적으로</td>\n",
       "      <td>정비 종합 서비스 제공</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0344355</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>세차장에서</td>\n",
       "      <td>서비스</td>\n",
       "      <td>자동차 세차 광택</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0805317</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>가게에서</td>\n",
       "      <td>오토바이 자전거 수리</td>\n",
       "      <td>S95952</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88721</th>\n",
       "      <td>id_0761016</td>\n",
       "      <td>C</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>모피</td>\n",
       "      <td>재단</td>\n",
       "      <td>옷 제조</td>\n",
       "      <td>C14142</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88722</th>\n",
       "      <td>id_0551658</td>\n",
       "      <td>C</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>밍크 스킨</td>\n",
       "      <td>선별 및 흠집 제거 형태 고정 절단</td>\n",
       "      <td></td>\n",
       "      <td>C14142</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88723</th>\n",
       "      <td>id_0760691</td>\n",
       "      <td>C</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>모피</td>\n",
       "      <td>재단 봉제 가공하여</td>\n",
       "      <td>모피의류 제조</td>\n",
       "      <td>C14142</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88724</th>\n",
       "      <td>id_0754942</td>\n",
       "      <td>C</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>인조모피</td>\n",
       "      <td>가공</td>\n",
       "      <td>인조 무스탕 가공</td>\n",
       "      <td>C14142</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88725</th>\n",
       "      <td>id_0411686</td>\n",
       "      <td>J</td>\n",
       "      <td>60</td>\n",
       "      <td>601</td>\n",
       "      <td>라디오방송</td>\n",
       "      <td>지상파방송</td>\n",
       "      <td>불교 방송</td>\n",
       "      <td>J60601</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88726 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AI_id digit_1 digit_2 digit_3      text_obj            text_mthd  \\\n",
       "0      id_0195359       S      95     952         세차장에서            고객 요청에 의해   \n",
       "1      id_0503002       S      95     952         카센터에서       자동차 내장 설치 전문수리   \n",
       "2      id_0222579       S      95     952  금동 종합 정비 공업사  건설기계장비 및 승용차를 전문적으로   \n",
       "3      id_0344355       S      95     952         세차장에서                  서비스   \n",
       "4      id_0805317       S      95     952     일반인을 대상으로                 가게에서   \n",
       "...           ...     ...     ...     ...           ...                  ...   \n",
       "88721  id_0761016       C      14     142            모피                   재단   \n",
       "88722  id_0551658       C      14     142         밍크 스킨  선별 및 흠집 제거 형태 고정 절단   \n",
       "88723  id_0760691       C      14     142            모피           재단 봉제 가공하여   \n",
       "88724  id_0754942       C      14     142          인조모피                   가공   \n",
       "88725  id_0411686       J      60     601         라디오방송                지상파방송   \n",
       "\n",
       "          text_deal   digit  label  \n",
       "0            자동차 세차  S95952    221  \n",
       "1            자동차 수리  S95952    221  \n",
       "2      정비 종합 서비스 제공  S95952    221  \n",
       "3         자동차 세차 광택  S95952    221  \n",
       "4       오토바이 자전거 수리  S95952    221  \n",
       "...             ...     ...    ...  \n",
       "88721          옷 제조  C14142     29  \n",
       "88722                C14142     29  \n",
       "88723       모피의류 제조  C14142     29  \n",
       "88724     인조 무스탕 가공  C14142     29  \n",
       "88725         불교 방송  J60601    153  \n",
       "\n",
       "[88726 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data에 추가\n",
    "test = pd.concat([test, oob_data])\n",
    "test = test.reset_index(drop=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee02cd",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e73d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sub datasets\n",
    "for i, sub_data in enumerate(sub_data_list):\n",
    "    sub_data.to_csv(args.project / f'sub_data{i}.csv', index=False, encoding='utf-8-sig')\n",
    "# Save test dataset\n",
    "test.to_csv(args.project / 'test_data.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b16dca8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>영업소에서</td>\n",
       "      <td>고객 대상</td>\n",
       "      <td>자동차 세차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터</td>\n",
       "      <td>자동차의 특정 부위 수리</td>\n",
       "      <td>자동차 경정비</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>중고 자동차를</td>\n",
       "      <td>자동차 종합 정비 자동차 성능검사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>우리들 카에서</td>\n",
       "      <td>고객으로부터 의뢰받아</td>\n",
       "      <td>자동차 경정비</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>일반인 대상</td>\n",
       "      <td>자동차 선팅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141212</th>\n",
       "      <td>69</td>\n",
       "      <td>플라스틱 잉크</td>\n",
       "      <td>자재 입고 사출</td>\n",
       "      <td>교육용 CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141213</th>\n",
       "      <td>69</td>\n",
       "      <td>통신 및 방송장비 영상 및 음향기기</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141214</th>\n",
       "      <td>6</td>\n",
       "      <td>무연탄</td>\n",
       "      <td>발파 생산</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141215</th>\n",
       "      <td>22</td>\n",
       "      <td>향료</td>\n",
       "      <td>재료 투입 정제 혼합 출하</td>\n",
       "      <td>전자담배 액상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141216</th>\n",
       "      <td>22</td>\n",
       "      <td>담뱃잎 담보 잎줄기</td>\n",
       "      <td>원료 투입 슬러리 제조</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141217 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label             text_obj       text_mthd           text_deal\n",
       "0         221                영업소에서           고객 대상              자동차 세차\n",
       "1         221                  카센터   자동차의 특정 부위 수리             자동차 경정비\n",
       "2         221                사업장에서         중고 자동차를  자동차 종합 정비 자동차 성능검사\n",
       "3         221              우리들 카에서     고객으로부터 의뢰받아             자동차 경정비\n",
       "4         221                사업장에서          일반인 대상              자동차 선팅\n",
       "...       ...                  ...             ...                 ...\n",
       "141212     69              플라스틱 잉크        자재 입고 사출              교육용 CD\n",
       "141213     69  통신 및 방송장비 영상 및 음향기기                                    \n",
       "141214      6                  무연탄           발파 생산                    \n",
       "141215     22                   향료  재료 투입 정제 혼합 출하             전자담배 액상\n",
       "141216     22           담뱃잎 담보 잎줄기    원료 투입 슬러리 제조                    \n",
       "\n",
       "[141217 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d1ad1",
   "metadata": {},
   "source": [
    "## Column Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7713d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>일반 고객에게</td>\n",
       "      <td>자동차 도색 및 흠집 제거</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>세차장에서</td>\n",
       "      <td>고객을 대상으로</td>\n",
       "      <td>차량 세차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>고객에 의뢰를 받아</td>\n",
       "      <td>자동차 선팅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차의 특정 부분만을 전문적 수리</td>\n",
       "      <td>자동차 수리업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>자동차의 특정 부분만을 전문적으로 수리</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>차량 내부 도장 세차 등의 서비스 제공</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141212</th>\n",
       "      <td>69</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>LED 광원과 식물재배기술</td>\n",
       "      <td>온실환경제어시스템</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141213</th>\n",
       "      <td>69</td>\n",
       "      <td>플라스틱 잉크</td>\n",
       "      <td>자재 입고 사출</td>\n",
       "      <td>교육용 CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141214</th>\n",
       "      <td>6</td>\n",
       "      <td>무연탄</td>\n",
       "      <td>발파 생산</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141215</th>\n",
       "      <td>22</td>\n",
       "      <td>담뱃잎 담보 잎줄기</td>\n",
       "      <td>원료 투입 슬러리 제조</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141216</th>\n",
       "      <td>22</td>\n",
       "      <td>향료</td>\n",
       "      <td>재료 투입 정제 혼합 출하</td>\n",
       "      <td>전자담배 액상</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141217 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label               text_obj            text_mthd  \\\n",
       "0         221                  사업장에서              일반 고객에게   \n",
       "1         221                  세차장에서             고객을 대상으로   \n",
       "2         221                  사업장에서           고객에 의뢰를 받아   \n",
       "3         221                  카센터에서  자동차의 특정 부분만을 전문적 수리   \n",
       "4         221  자동차의 특정 부분만을 전문적으로 수리                카센터에서   \n",
       "...       ...                    ...                  ...   \n",
       "141212     69                  사업장에서       LED 광원과 식물재배기술   \n",
       "141213     69                플라스틱 잉크             자재 입고 사출   \n",
       "141214      6                    무연탄                발파 생산   \n",
       "141215     22             담뱃잎 담보 잎줄기         원료 투입 슬러리 제조   \n",
       "141216     22                     향료       재료 투입 정제 혼합 출하   \n",
       "\n",
       "                    text_deal  \n",
       "0              자동차 도색 및 흠집 제거  \n",
       "1                       차량 세차  \n",
       "2                      자동차 선팅  \n",
       "3                     자동차 수리업  \n",
       "4       차량 내부 도장 세차 등의 서비스 제공  \n",
       "...                       ...  \n",
       "141212              온실환경제어시스템  \n",
       "141213                 교육용 CD  \n",
       "141214                         \n",
       "141215                         \n",
       "141216                전자담배 액상  \n",
       "\n",
       "[141217 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>세차장에서</td>\n",
       "      <td>고객 요청에 의해</td>\n",
       "      <td>자동차 세차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 내장 설치 전문수리</td>\n",
       "      <td>자동차 수리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>금동 종합 정비 공업사</td>\n",
       "      <td>건설기계장비 및 승용차를 전문적으로</td>\n",
       "      <td>정비 종합 서비스 제공</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>세차장에서</td>\n",
       "      <td>서비스</td>\n",
       "      <td>자동차 세차 광택</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>가게에서</td>\n",
       "      <td>오토바이 자전거 수리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88721</th>\n",
       "      <td>29</td>\n",
       "      <td>모피</td>\n",
       "      <td>재단</td>\n",
       "      <td>옷 제조</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88722</th>\n",
       "      <td>29</td>\n",
       "      <td>밍크 스킨</td>\n",
       "      <td>선별 및 흠집 제거 형태 고정 절단</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88723</th>\n",
       "      <td>29</td>\n",
       "      <td>모피</td>\n",
       "      <td>재단 봉제 가공하여</td>\n",
       "      <td>모피의류 제조</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88724</th>\n",
       "      <td>29</td>\n",
       "      <td>인조모피</td>\n",
       "      <td>가공</td>\n",
       "      <td>인조 무스탕 가공</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88725</th>\n",
       "      <td>153</td>\n",
       "      <td>라디오방송</td>\n",
       "      <td>지상파방송</td>\n",
       "      <td>불교 방송</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88726 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label      text_obj            text_mthd     text_deal\n",
       "0        221         세차장에서            고객 요청에 의해        자동차 세차\n",
       "1        221         카센터에서       자동차 내장 설치 전문수리        자동차 수리\n",
       "2        221  금동 종합 정비 공업사  건설기계장비 및 승용차를 전문적으로  정비 종합 서비스 제공\n",
       "3        221         세차장에서                  서비스     자동차 세차 광택\n",
       "4        221     일반인을 대상으로                 가게에서   오토바이 자전거 수리\n",
       "...      ...           ...                  ...           ...\n",
       "88721     29            모피                   재단          옷 제조\n",
       "88722     29         밍크 스킨  선별 및 흠집 제거 형태 고정 절단              \n",
       "88723     29            모피           재단 봉제 가공하여       모피의류 제조\n",
       "88724     29          인조모피                   가공     인조 무스탕 가공\n",
       "88725    153         라디오방송                지상파방송         불교 방송\n",
       "\n",
       "[88726 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_data_list = [sub_data[['label', 'text_obj', 'text_mthd', 'text_deal']]\n",
    "                  for sub_data in sub_data_list]\n",
    "test = test[['label', 'text_obj', 'text_mthd', 'text_deal']]\n",
    "display(sub_data_list[0])\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de2b91",
   "metadata": {},
   "source": [
    "## Sub train-valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39c33858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127139 entries, 0 to 127138\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   label      127139 non-null  int64 \n",
      " 1   text_obj   127139 non-null  object\n",
      " 2   text_mthd  127139 non-null  object\n",
      " 3   text_deal  127139 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14078 entries, 0 to 14077\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   label      14078 non-null  int64 \n",
      " 1   text_obj   14078 non-null  object\n",
      " 2   text_mthd  14078 non-null  object\n",
      " 3   text_deal  14078 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 440.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_train_list, sub_valid_list = zip(*map(lambda sub_data: train_test_split(\n",
    "    sub_data, test_ratio=args.sub_valid_ratio, seed=args.seed), sub_data_list))\n",
    "display(sub_train_list[0].info()) # 첫번째 sub train set\n",
    "display(sub_valid_list[1].info()) # 두번째 sub valid set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b5af4",
   "metadata": {},
   "source": [
    "## Upsample sub trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b67dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub train 수(before upsample):\n",
      " [127139, 127139, 127139, 127139, 127139, 127139, 127139, 127139, 127139, 127139]\n",
      "sub train 수(after upsample):\n",
      " [132867, 132867, 132867, 132867, 132867, 132867, 132867, 132867, 132867, 132867]\n"
     ]
    }
   ],
   "source": [
    "def upsample_corpus(df, minimum=500, method='uniform', seed=42):\n",
    "    random.seed(seed)\n",
    "    labels = df['label'].unique().tolist()\n",
    "    upsampled = pd.DataFrame()\n",
    "    for lb in labels:\n",
    "        temp_df = df[df['label']==lb].copy()\n",
    "        n = 0\n",
    "        while True:\n",
    "            n+=1\n",
    "            if n==50:\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            if len(temp_df)>=minimum:\n",
    "                break\n",
    "                \n",
    "            if method=='random':\n",
    "                n_sample = minimum-len(temp_df)\n",
    "                sample = temp_df.sample(n=n_sample, replace=True, random_state=seed)\n",
    "                not_empty_cond = sample[['text_obj','text_mthd','text_deal']].applymap(\n",
    "                    lambda x: len(x)!=0).apply(any, axis=1)\n",
    "                if not not_empty_cond.all():\n",
    "                    sample = sample[not_empty_cond].reset_index(drop=True)\n",
    "                temp_df = pd.concat([temp_df, sample])\n",
    "            elif method=='uniform':\n",
    "                n_rep = minimum//len(temp_df)\n",
    "                n_sample = minimum%len(temp_df)\n",
    "                sample = temp_df.sample(n=n_sample, random_state=seed)\n",
    "                not_empty_cond = sample[['text_obj','text_mthd','text_deal']].applymap(\n",
    "                    lambda x: len(x)!=0).apply(any, axis=1)\n",
    "                if not not_empty_cond.all():\n",
    "                    sample = sample[not_empty_cond].reset_index(drop=True)\n",
    "                temp_df = pd.concat([temp_df for _ in range(n_rep)]+[sample])\n",
    "            elif method=='shuffle':\n",
    "                s1=random.randrange(0, 1000) # seed 1\n",
    "                s2=random.randrange(0, 1000) # seed 2\n",
    "                s3=random.randrange(0, 1000) # seed 3\n",
    "                n_sample = minimum-len(temp_df)\n",
    "                sample = pd.concat([\n",
    "                    temp_df['text_obj'].sample(n=n_sample, replace=True, \n",
    "                                               random_state=s1).reset_index(drop=True),\n",
    "                    temp_df['text_mthd'].sample(n=n_sample, replace=True, \n",
    "                                                random_state=s2).reset_index(drop=True),\n",
    "                    temp_df['text_deal'].sample(n=n_sample, replace=True, \n",
    "                                                random_state=s3).reset_index(drop=True)\n",
    "                ], axis=1)\n",
    "                sample['label'] = lb\n",
    "                sample=sample[['label', 'text_obj','text_mthd','text_deal']]\n",
    "                not_empty_cond = sample[['text_obj','text_mthd','text_deal']].applymap(\n",
    "                    lambda x: len(x)!=0).apply(any, axis=1)\n",
    "                if not not_empty_cond.all():\n",
    "                    sample = sample[not_empty_cond].reset_index(drop=True)\n",
    "                temp_df=pd.concat([temp_df, sample])\n",
    "        upsampled = pd.concat([upsampled, temp_df])\n",
    "    upsampled = upsampled.reset_index(drop=True)\n",
    "    return upsampled\n",
    "\n",
    "print('sub train 수(before upsample):\\n', \n",
    "      [len(sub_train) for sub_train in sub_train_list])\n",
    "sub_train_list = list(map(\n",
    "    lambda sub_train: upsample_corpus(sub_train, minimum=args.minimum, method=args.upsample, seed=args.seed),\n",
    "    sub_train_list\n",
    "))\n",
    "print('sub train 수(after upsample):\\n', \n",
    "      [len(sub_train) for sub_train in sub_train_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf62e397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차의 특정 부분을 전문적으로 수리</td>\n",
       "      <td>경정비</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>정비소에서</td>\n",
       "      <td>고객을 대상으로</td>\n",
       "      <td>자동차 타이어 수리 서비스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>일반 고객 대상으로</td>\n",
       "      <td>오토바이 수리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>고객을 대상</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 수리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터</td>\n",
       "      <td>일반 고객을 대상으로</td>\n",
       "      <td>자동차 전문수리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132862</th>\n",
       "      <td>22</td>\n",
       "      <td>향료</td>\n",
       "      <td>재료 투입 정제 혼합 출하</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132863</th>\n",
       "      <td>22</td>\n",
       "      <td>향료</td>\n",
       "      <td>재료 투입 정제 혼합 출하</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132864</th>\n",
       "      <td>22</td>\n",
       "      <td>향료</td>\n",
       "      <td>원료 투입 슬러리 제조</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132865</th>\n",
       "      <td>22</td>\n",
       "      <td>향료</td>\n",
       "      <td>원료 투입 슬러리 제조</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132866</th>\n",
       "      <td>22</td>\n",
       "      <td>담뱃잎 담보 잎줄기</td>\n",
       "      <td>재료 투입 정제 혼합 출하</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132867 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label    text_obj             text_mthd       text_deal\n",
       "0         221       카센터에서  자동차의 특정 부분을 전문적으로 수리             경정비\n",
       "1         221       정비소에서              고객을 대상으로  자동차 타이어 수리 서비스\n",
       "2         221       사업장에서            일반 고객 대상으로         오토바이 수리\n",
       "3         221      고객을 대상                 카센터에서          자동차 수리\n",
       "4         221         카센터           일반 고객을 대상으로        자동차 전문수리\n",
       "...       ...         ...                   ...             ...\n",
       "132862     22          향료        재료 투입 정제 혼합 출하                \n",
       "132863     22          향료        재료 투입 정제 혼합 출하                \n",
       "132864     22          향료          원료 투입 슬러리 제조                \n",
       "132865     22          향료          원료 투입 슬러리 제조                \n",
       "132866     22  담뱃잎 담보 잎줄기        재료 투입 정제 혼합 출하                \n",
       "\n",
       "[132867 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e7815",
   "metadata": {},
   "source": [
    "## Concatenate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e036936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차의 특정 부분을 전문적으로 수리</td>\n",
       "      <td>경정비</td>\n",
       "      <td>카센터에서 자동차의 특정 부분을 전문적으로 수리 경정비</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>정비소에서</td>\n",
       "      <td>고객을 대상으로</td>\n",
       "      <td>자동차 타이어 수리 서비스</td>\n",
       "      <td>정비소에서 고객을 대상으로 자동차 타이어 수리 서비스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>일반 고객 대상으로</td>\n",
       "      <td>오토바이 수리</td>\n",
       "      <td>사업장에서 일반 고객 대상으로 오토바이 수리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>고객을 대상</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 수리</td>\n",
       "      <td>고객을 대상 카센터에서 자동차 수리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터</td>\n",
       "      <td>일반 고객을 대상으로</td>\n",
       "      <td>자동차 전문수리</td>\n",
       "      <td>카센터 일반 고객을 대상으로 자동차 전문수리</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label text_obj             text_mthd       text_deal  \\\n",
       "0    221    카센터에서  자동차의 특정 부분을 전문적으로 수리             경정비   \n",
       "1    221    정비소에서              고객을 대상으로  자동차 타이어 수리 서비스   \n",
       "2    221    사업장에서            일반 고객 대상으로         오토바이 수리   \n",
       "3    221   고객을 대상                 카센터에서          자동차 수리   \n",
       "4    221      카센터           일반 고객을 대상으로        자동차 전문수리   \n",
       "\n",
       "                             text  \n",
       "0  카센터에서 자동차의 특정 부분을 전문적으로 수리 경정비  \n",
       "1   정비소에서 고객을 대상으로 자동차 타이어 수리 서비스  \n",
       "2        사업장에서 일반 고객 대상으로 오토바이 수리  \n",
       "3             고객을 대상 카센터에서 자동차 수리  \n",
       "4        카센터 일반 고객을 대상으로 자동차 전문수리  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 부분 수리</td>\n",
       "      <td>내장 및 도장</td>\n",
       "      <td>카센터에서 자동차 부분 수리 내장 및 도장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터</td>\n",
       "      <td>자동차 수리 및 검사시설 갖추고</td>\n",
       "      <td>자동차 경정 서비스</td>\n",
       "      <td>카센터 자동차 수리 및 검사시설 갖추고 자동차 경정 서비스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>사업장</td>\n",
       "      <td>자동차</td>\n",
       "      <td>스팀세차</td>\n",
       "      <td>사업장 자동차 스팀세차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>사업장에서</td>\n",
       "      <td>일반 고객 대상으로</td>\n",
       "      <td>차량 세차</td>\n",
       "      <td>사업장에서 일반 고객 대상으로 차량 세차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>특정 부분을 전문적으로 수리</td>\n",
       "      <td>정이 수리 서비스</td>\n",
       "      <td>카센터에서 특정 부분을 전문적으로 수리 정이 수리 서비스</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label text_obj          text_mthd   text_deal  \\\n",
       "0    221    카센터에서          자동차 부분 수리     내장 및 도장   \n",
       "1    221      카센터  자동차 수리 및 검사시설 갖추고  자동차 경정 서비스   \n",
       "2    221      사업장                자동차        스팀세차   \n",
       "3    221    사업장에서         일반 고객 대상으로       차량 세차   \n",
       "4    221    카센터에서    특정 부분을 전문적으로 수리   정이 수리 서비스   \n",
       "\n",
       "                               text  \n",
       "0           카센터에서 자동차 부분 수리 내장 및 도장  \n",
       "1  카센터 자동차 수리 및 검사시설 갖추고 자동차 경정 서비스  \n",
       "2                      사업장 자동차 스팀세차  \n",
       "3            사업장에서 일반 고객 대상으로 차량 세차  \n",
       "4   카센터에서 특정 부분을 전문적으로 수리 정이 수리 서비스  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>세차장에서</td>\n",
       "      <td>고객 요청에 의해</td>\n",
       "      <td>자동차 세차</td>\n",
       "      <td>세차장에서 고객 요청에 의해 자동차 세차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차 내장 설치 전문수리</td>\n",
       "      <td>자동차 수리</td>\n",
       "      <td>카센터에서 자동차 내장 설치 전문수리 자동차 수리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>금동 종합 정비 공업사</td>\n",
       "      <td>건설기계장비 및 승용차를 전문적으로</td>\n",
       "      <td>정비 종합 서비스 제공</td>\n",
       "      <td>금동 종합 정비 공업사 건설기계장비 및 승용차를 전문적으로 정비 종합 서비스 제공</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>세차장에서</td>\n",
       "      <td>서비스</td>\n",
       "      <td>자동차 세차 광택</td>\n",
       "      <td>세차장에서 서비스 자동차 세차 광택</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>가게에서</td>\n",
       "      <td>오토바이 자전거 수리</td>\n",
       "      <td>일반인을 대상으로 가게에서 오토바이 자전거 수리</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label      text_obj            text_mthd     text_deal  \\\n",
       "0    221         세차장에서            고객 요청에 의해        자동차 세차   \n",
       "1    221         카센터에서       자동차 내장 설치 전문수리        자동차 수리   \n",
       "2    221  금동 종합 정비 공업사  건설기계장비 및 승용차를 전문적으로  정비 종합 서비스 제공   \n",
       "3    221         세차장에서                  서비스     자동차 세차 광택   \n",
       "4    221     일반인을 대상으로                 가게에서   오토바이 자전거 수리   \n",
       "\n",
       "                                            text  \n",
       "0                         세차장에서 고객 요청에 의해 자동차 세차  \n",
       "1                    카센터에서 자동차 내장 설치 전문수리 자동차 수리  \n",
       "2  금동 종합 정비 공업사 건설기계장비 및 승용차를 전문적으로 정비 종합 서비스 제공  \n",
       "3                            세차장에서 서비스 자동차 세차 광택  \n",
       "4                     일반인을 대상으로 가게에서 오토바이 자전거 수리  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def concat_text(data):\n",
    "    data['text'] = data[['text_obj', 'text_mthd', 'text_deal']].apply(\n",
    "            lambda text_tuple: ' '.join(text_tuple), axis=1)\n",
    "    return data\n",
    "\n",
    "sub_train_list = [concat_text(sub_train) for sub_train in sub_train_list]\n",
    "sub_valid_list = [concat_text(sub_valid) for sub_valid in sub_valid_list]\n",
    "test = concat_text(test)\n",
    "\n",
    "display(sub_train_list[0].head())\n",
    "display(sub_valid_list[0].head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f341a51",
   "metadata": {},
   "source": [
    "## Save Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c318e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['label', 'text']].to_csv(args.project / 'test_data', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da2bd9",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n",
    "sub dataset의 반은 kobert, 반은 kogpt로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb740f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert base model 5개\n",
      "gpt base model 5개\n"
     ]
    }
   ],
   "source": [
    "train_loaders = []\n",
    "valid_loaders = []\n",
    "if args.model == 'ensemble':\n",
    "    n_bert = int(args.estimators/2)\n",
    "    n_gpt = args.estimators - n_bert\n",
    "elif args.model == 'ensemble-kobert':\n",
    "    n_bert = args.estimators\n",
    "    n_gpt = 0\n",
    "elif args.model == 'ensemble-kogpt2':\n",
    "    n_bert = 0\n",
    "    n_gpt = args.estimators\n",
    "    \n",
    "print(f'bert base model {n_bert}개')\n",
    "print(f'gpt base model {n_gpt}개')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5afda",
   "metadata": {},
   "source": [
    "## Kobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8e814d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/jupyter/parksh/src/.cache/kobert_v1.zip\n",
      "using cached model. /home/jupyter/parksh/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                       | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/jupyter/parksh/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:24<00:00,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "class KOBERTClassifyDataset(Dataset):\n",
    "    def __init__(self, doc, label, tokenizer):\n",
    "        super(KOBERTClassifyDataset, self).__init__()\n",
    "        self.doc = doc\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenized = [self.tokenizer([d]) for d in doc] # numpy.array\n",
    "        self.label = label\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = np.zeros_like(token_ids)\n",
    "        attention_mask[:valid_length] = 1\n",
    "        return attention_mask\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        token_ids = self.tokenized[i][0]\n",
    "        valid_length = self.tokenized[i][1]\n",
    "        token_type_ids = self.tokenized[i][2]\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        return (token_ids, # numpy.array\n",
    "                attention_mask, # numpy.array\n",
    "                token_type_ids, # numpy.array\n",
    "                self.label[i]) # int scalar\n",
    "        # numpy array will be changed to torch.tensor via DataLoader\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.label))\n",
    "    \n",
    "bert, bert_vocab = get_pytorch_kobert_model()\n",
    "bert_tokenizer_path = get_tokenizer()\n",
    "bert_tokenizer = nlp.data.BERTSPTokenizer(bert_tokenizer_path, bert_vocab, lower=False)\n",
    "bert_transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=args.max_len, pad=True, pair=False) \n",
    "\n",
    "for sub_train, sub_valid in tqdm(zip(sub_train_list[:n_bert], sub_valid_list[:n_bert]),\n",
    "                                total=n_bert):\n",
    "    train_set = KOBERTClassifyDataset(sub_train['text'].tolist(),\n",
    "                                     sub_train['label'].tolist(),\n",
    "                                     bert_transform)\n",
    "    valid_set = KOBERTClassifyDataset(sub_valid['text'].tolist(),\n",
    "                                     sub_valid['label'].tolist(),\n",
    "                                     bert_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, num_workers=args.workers,\n",
    "                              shuffle=True, pin_memory=False)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=args.batch_size, num_workers=args.workers,\n",
    "                             shuffle=False, pin_memory=False)\n",
    "    train_loaders.append(train_loader)\n",
    "    valid_loaders.append(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55913cc",
   "metadata": {},
   "source": [
    "## KoGPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e17fc61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:29<00:00,  5.91s/it]\n"
     ]
    }
   ],
   "source": [
    "class KOGPT2ClassifyDataset(Dataset):\n",
    "    def __init__(self, doc, label, tokenizer, max_len):\n",
    "        super(KOGPT2ClassifyDataset, self).__init__()\n",
    "        self.doc = doc\n",
    "        self.label = label\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.tokenized = self.tokenizer(doc, padding='max_length', max_length=max_len, truncation=True, return_tensors='pt')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.tokenized.input_ids[idx],\n",
    "                self.tokenized.attention_mask[idx],\n",
    "                self.tokenized.token_type_ids[idx],\n",
    "                self.label[idx])\n",
    "\n",
    "gpt_tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "        'skt/kogpt2-base-v2',\n",
    "        bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "        pad_token='<pad>', mask_token='<mask>')\n",
    "for sub_train, sub_valid in tqdm(zip(sub_train_list[-n_gpt:], sub_valid_list[-n_gpt:]),\n",
    "                                total=n_gpt):\n",
    "    train_set = KOGPT2ClassifyDataset(sub_train['text'].tolist(),\n",
    "                                     sub_train['label'].tolist(),\n",
    "                                     gpt_tokenizer, args.max_len)\n",
    "    valid_set = KOGPT2ClassifyDataset(sub_valid['text'].tolist(),\n",
    "                                     sub_valid['label'].tolist(),\n",
    "                                     gpt_tokenizer, args.max_len)\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, num_workers=args.workers,\n",
    "                              shuffle=True, pin_memory=False)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=args.batch_size, num_workers=args.workers,\n",
    "                             shuffle=False, pin_memory=False)\n",
    "    train_loaders.append(train_loader)\n",
    "    valid_loaders.append(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f4eec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loaders))\n",
    "print(len(valid_loaders))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78238f33",
   "metadata": {},
   "source": [
    "# Training Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002d983",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2394577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KOBERTClassifier(nn.Module):\n",
    "    def __init__(self, bert, num_classes, hidden_size = 4096, dr_rate=None, params=None):\n",
    "        super(KOBERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.num_classes = num_classes\n",
    "        self.dr_rate = dr_rate\n",
    "         \n",
    "#         self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        self.classifier = nn.Sequential(nn.Linear(768, hidden_size, bias=True),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(hidden_size, num_classes, bias=True))\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def forward(self, token_ids, attention_mask, token_type_ids):\n",
    "        _, pooler = self.bert(input_ids=token_ids.long(),\n",
    "                              token_type_ids=token_type_ids.long(),\n",
    "                              attention_mask=attention_mask.float())\n",
    "        if self.dr_rate:\n",
    "            pooler = self.dropout(pooler)\n",
    "        return self.classifier(pooler)\n",
    "    \n",
    "class KOGPT2Classifier(nn.Module):\n",
    "    def __init__(self, gpt, num_classes, hidden_size=4026, freeze_gpt=True, dr_rate=None):\n",
    "        super(KOGPT2Classifier, self).__init__()\n",
    "        self.gpt = gpt\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.freeze_gpt = freeze_gpt\n",
    "        self.dr_rate = dr_rate\n",
    "        \n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(nn.Linear(768, hidden_size, bias=True, dtype=torch.float32),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(hidden_size, num_classes, bias=True, dtype=torch.float32))\n",
    "        \n",
    "        if self.dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def forward(self, token_ids, attention_mask, token_type_ids):\n",
    "        # transformer decoder output\n",
    "        # size : (b, n_dec_seq, n_hidden)\n",
    "        dec_output = self.gpt.transformer(input_ids=token_ids,\n",
    "                                  token_type_ids=token_type_ids,\n",
    "                                  attention_mask = attention_mask)\n",
    "        \n",
    "        # language model output\n",
    "        # size : (b, n_dec_seq, n_dec_vocab)\n",
    "        logits_lm = self.gpt.lm_head(dec_output.last_hidden_state)\n",
    "        \n",
    "        # classifier output\n",
    "        # size : (b, n_hidden)\n",
    "        dec_outputs = dec_output.last_hidden_state[:, -1].contiguous() # 마지막 예측 토큰을 분류값으로 사용\n",
    "        # size : (b, num_classes)\n",
    "        logits_cls = self.classifier(dec_outputs)\n",
    "        \n",
    "#         return logits_lm[:, :-1, :].contiguous(), logits_cls, dec_output.attentions\n",
    "        return logits_cls\n",
    "\n",
    "gpt = GPT2LMHeadModel.from_pretrained(\n",
    "    pretrained_model_name_or_path='skt/kogpt2-base-v2',\n",
    "    pad_token_id=gpt_tokenizer.eos_token_id, torch_dtype='auto',\n",
    "    low_cpu_mem_usage=True)\n",
    "\n",
    "for child in gpt.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83de858",
   "metadata": {},
   "source": [
    "## Optimizer, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "844e9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer_type, model, lr, betas, weight_decay, eps=1e-08, amsgrad=False):\n",
    "    if optimizer_type == 'AdamW':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "    elif optimizer_type == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "    elif optimizer_type == 'RAdam':\n",
    "        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "    else:\n",
    "        raise\n",
    "    return optimizer\n",
    "\n",
    "def get_loss(loss_type, **kwargs):\n",
    "    if loss_type == 'CE':\n",
    "        criterion = CrossEntropy(**kwargs)\n",
    "    elif loss_type == 'FCE':\n",
    "        criterion = FocalCrossEntropy(**kwargs)\n",
    "    else:\n",
    "        raise\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fba5b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71184d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 03:57:58,746 | # train data: 132867\n",
      "2022-04-03 03:57:58,747 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:39<00:00,  1.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.18it/s]\n",
      "2022-04-03 04:00:47,165 | Epoch 0 Result\n",
      "2022-04-03 04:00:47,165 | \ttrain loss: 5.230920863133426\tvalid_loss: 4.864519410283072\n",
      "2022-04-03 04:00:47,165 | \tacc: 0.120614\tpc: 0.00224\trc: 0.008011\tf1: 0.003209\n",
      "2022-04-03 04:00:48,374 | Validation accuracy got better None --> 0.12061372354027561.  Saving model ...\n",
      "2022-04-03 04:00:48,756 | Validation loss got better None --> 4.864519410283072.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:41<00:00,  1.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.15it/s]\n",
      "2022-04-03 04:03:37,720 | Epoch 1 Result\n",
      "2022-04-03 04:03:37,721 | \ttrain loss: 4.2663917338286375\tvalid_loss: 3.480588388842672\n",
      "2022-04-03 04:03:37,721 | \tacc: 0.184472\tpc: 0.004502\trc: 0.017256\tf1: 0.006456\n",
      "2022-04-03 04:03:39,335 | Validation accuracy got better 0.12061372354027561 --> 0.18447222616848985.  Saving model ...\n",
      "2022-04-03 04:03:39,946 | Validation loss got better 4.864519410283072 --> 3.480588388842672.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.14it/s]\n",
      "2022-04-03 04:06:30,154 | Epoch 2 Result\n",
      "2022-04-03 04:06:30,154 | \ttrain loss: 3.066872626644654\tvalid_loss: 2.3303271017387552\n",
      "2022-04-03 04:06:30,155 | \tacc: 0.385921\tpc: 0.045639\trc: 0.063691\tf1: 0.043493\n",
      "2022-04-03 04:06:31,660 | Validation accuracy got better 0.18447222616848985 --> 0.385921295638585.  Saving model ...\n",
      "2022-04-03 04:06:32,396 | Validation loss got better 3.480588388842672 --> 2.3303271017387552.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 04:09:22,902 | Epoch 3 Result\n",
      "2022-04-03 04:09:22,903 | \ttrain loss: 2.081206082117004\tvalid_loss: 1.5276047715681456\n",
      "2022-04-03 04:09:22,903 | \tacc: 0.572809\tpc: 0.096775\trc: 0.132326\tf1: 0.103581\n",
      "2022-04-03 04:09:24,469 | Validation accuracy got better 0.385921295638585 --> 0.5728086375905669.  Saving model ...\n",
      "2022-04-03 04:09:25,092 | Validation loss got better 2.3303271017387552 --> 1.5276047715681456.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.14it/s]\n",
      "2022-04-03 04:12:15,303 | Epoch 4 Result\n",
      "2022-04-03 04:12:15,304 | \ttrain loss: 1.4830097661800772\tvalid_loss: 1.0916873136185197\n",
      "2022-04-03 04:12:15,304 | \tacc: 0.686532\tpc: 0.199542\trc: 0.208205\tf1: 0.185445\n",
      "2022-04-03 04:12:16,766 | Validation accuracy got better 0.5728086375905669 --> 0.6865321778661742.  Saving model ...\n",
      "2022-04-03 04:12:17,378 | Validation loss got better 1.5276047715681456 --> 1.0916873136185197.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 04:15:07,604 | Epoch 5 Result\n",
      "2022-04-03 04:15:07,605 | \ttrain loss: 1.1121668812983974\tvalid_loss: 0.8494080861093375\n",
      "2022-04-03 04:15:07,605 | \tacc: 0.748615\tpc: 0.259923\trc: 0.281191\tf1: 0.257594\n",
      "2022-04-03 04:15:09,539 | Validation accuracy got better 0.6865321778661742 --> 0.7486148600653502.  Saving model ...\n",
      "2022-04-03 04:15:10,233 | Validation loss got better 1.0916873136185197 --> 0.8494080861093375.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.14it/s]\n",
      "2022-04-03 04:18:00,559 | Epoch 6 Result\n",
      "2022-04-03 04:18:00,560 | \ttrain loss: 0.8729938719642927\tvalid_loss: 0.7132268509483418\n",
      "2022-04-03 04:18:00,560 | \tacc: 0.785907\tpc: 0.370848\trc: 0.373049\tf1: 0.354746\n",
      "2022-04-03 04:18:02,012 | Validation accuracy got better 0.7486148600653502 --> 0.7859070890751527.  Saving model ...\n",
      "2022-04-03 04:18:02,678 | Validation loss got better 0.8494080861093375 --> 0.7132268509483418.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.14it/s]\n",
      "2022-04-03 04:20:52,927 | Epoch 7 Result\n",
      "2022-04-03 04:20:52,928 | \ttrain loss: 0.7100546663554677\tvalid_loss: 0.6242731615704118\n",
      "2022-04-03 04:20:52,928 | \tacc: 0.807643\tpc: 0.443468\trc: 0.437937\tf1: 0.423426\n",
      "2022-04-03 04:20:54,375 | Validation accuracy got better 0.7859070890751527 --> 0.8076431311265805.  Saving model ...\n",
      "2022-04-03 04:20:54,982 | Validation loss got better 0.7132268509483418 --> 0.6242731615704118.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 04:23:45,181 | Epoch 8 Result\n",
      "2022-04-03 04:23:45,182 | \ttrain loss: 0.5957284378850395\tvalid_loss: 0.5711612020945884\n",
      "2022-04-03 04:23:45,182 | \tacc: 0.81638\tpc: 0.483428\trc: 0.476016\tf1: 0.46362\n",
      "2022-04-03 04:23:46,673 | Validation accuracy got better 0.8076431311265805 --> 0.8163801676374485.  Saving model ...\n",
      "2022-04-03 04:23:47,286 | Validation loss got better 0.6242731615704118 --> 0.5711612020945884.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.14it/s]\n",
      "2022-04-03 04:26:37,471 | Epoch 9 Result\n",
      "2022-04-03 04:26:37,471 | \ttrain loss: 0.5145345756564504\tvalid_loss: 0.5344820486955606\n",
      "2022-04-03 04:26:37,471 | \tacc: 0.82739\tpc: 0.55632\trc: 0.526402\tf1: 0.519134\n",
      "2022-04-03 04:26:39,090 | Validation accuracy got better 0.8163801676374485 --> 0.8273902542974855.  Saving model ...\n",
      "2022-04-03 04:26:39,755 | Validation loss got better 0.5711612020945884 --> 0.5344820486955606.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 04:29:30,021 | Epoch 10 Result\n",
      "2022-04-03 04:29:30,022 | \ttrain loss: 0.4507991757568521\tvalid_loss: 0.5065743212741213\n",
      "2022-04-03 04:29:30,022 | \tacc: 0.833783\tpc: 0.59272\trc: 0.565022\tf1: 0.557377\n",
      "2022-04-03 04:29:31,477 | Validation accuracy got better 0.8273902542974855 --> 0.833783207842023.  Saving model ...\n",
      "2022-04-03 04:29:32,088 | Validation loss got better 0.5344820486955606 --> 0.5065743212741213.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 04:32:22,354 | Epoch 11 Result\n",
      "2022-04-03 04:32:22,355 | \ttrain loss: 0.40069266154744065\tvalid_loss: 0.4892718912712094\n",
      "2022-04-03 04:32:22,355 | \tacc: 0.840389\tpc: 0.623822\trc: 0.598436\tf1: 0.588388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 04:32:23,666 | Validation accuracy got better 0.833783207842023 --> 0.8403892598380451.  Saving model ...\n",
      "2022-04-03 04:32:24,282 | Validation loss got better 0.5065743212741213 --> 0.4892718912712094.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.15it/s]\n",
      "2022-04-03 04:35:14,584 | Epoch 12 Result\n",
      "2022-04-03 04:35:14,585 | \ttrain loss: 0.36153801271772007\tvalid_loss: 0.47802042270150435\n",
      "2022-04-03 04:35:14,585 | \tacc: 0.844864\tpc: 0.639774\trc: 0.632323\tf1: 0.620514\n",
      "2022-04-03 04:35:15,950 | Validation accuracy got better 0.8403892598380451 --> 0.8448643273192215.  Saving model ...\n",
      "2022-04-03 04:35:16,561 | Validation loss got better 0.4892718912712094 --> 0.47802042270150435.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 04:38:06,918 | Epoch 13 Result\n",
      "2022-04-03 04:38:06,918 | \ttrain loss: 0.32788998839111716\tvalid_loss: 0.4678035300129228\n",
      "2022-04-03 04:38:06,919 | \tacc: 0.848629\tpc: 0.674916\trc: 0.634528\tf1: 0.633619\n",
      "2022-04-03 04:38:08,356 | Validation accuracy got better 0.8448643273192215 --> 0.8486290666287825.  Saving model ...\n",
      "2022-04-03 04:38:08,966 | Validation loss got better 0.47802042270150435 --> 0.4678035300129228.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 04:40:59,572 | Epoch 14 Result\n",
      "2022-04-03 04:40:59,572 | \ttrain loss: 0.2997777405972754\tvalid_loss: 0.4585835297925006\n",
      "2022-04-03 04:40:59,573 | \tacc: 0.851826\tpc: 0.682649\trc: 0.65095\tf1: 0.65101\n",
      "2022-04-03 04:41:01,049 | Validation accuracy got better 0.8486290666287825 --> 0.8518255434010513.  Saving model ...\n",
      "2022-04-03 04:41:01,616 | Validation loss got better 0.4678035300129228 --> 0.4585835297925006.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 04:43:51,952 | Epoch 15 Result\n",
      "2022-04-03 04:43:51,952 | \ttrain loss: 0.27583546069259857\tvalid_loss: 0.45772462449031115\n",
      "2022-04-03 04:43:51,953 | \tacc: 0.85076\tpc: 0.682528\trc: 0.659545\tf1: 0.654293\n",
      "2022-04-03 04:43:53,403 | Validation loss got better 0.4585835297925006 --> 0.45772462449031115.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 04:46:43,777 | Epoch 16 Result\n",
      "2022-04-03 04:46:43,777 | \ttrain loss: 0.25624944949819045\tvalid_loss: 0.45226117119665155\n",
      "2022-04-03 04:46:43,778 | \tacc: 0.855022\tpc: 0.691986\trc: 0.666721\tf1: 0.660928\n",
      "2022-04-03 04:46:45,237 | Validation accuracy got better 0.8518255434010513 --> 0.8550220201733201.  Saving model ...\n",
      "2022-04-03 04:46:45,841 | Validation loss got better 0.45772462449031115 --> 0.45226117119665155.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 04:49:36,307 | Epoch 17 Result\n",
      "2022-04-03 04:49:36,308 | \ttrain loss: 0.2394774892830417\tvalid_loss: 0.45486665093809014\n",
      "2022-04-03 04:49:36,308 | \tacc: 0.854383\tpc: 0.679621\trc: 0.673143\tf1: 0.662521\n",
      "2022-04-03 04:49:37,770 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:42<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.14it/s]\n",
      "2022-04-03 04:52:27,543 | Epoch 18 Result\n",
      "2022-04-03 04:52:27,543 | \ttrain loss: 0.22326922818804268\tvalid_loss: 0.4552589420703921\n",
      "2022-04-03 04:52:27,543 | \tacc: 0.853957\tpc: 0.690699\trc: 0.668436\tf1: 0.665188\n",
      "2022-04-03 04:52:29,009 | patience 1 --> 2\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 04:55:18,930 | Epoch 19 Result\n",
      "2022-04-03 04:55:18,931 | \ttrain loss: 0.20844524122190125\tvalid_loss: 0.45146180972370137\n",
      "2022-04-03 04:55:18,931 | \tacc: 0.855093\tpc: 0.677119\trc: 0.671918\tf1: 0.662728\n",
      "2022-04-03 04:55:20,334 | Validation accuracy got better 0.8550220201733201 --> 0.8550930529904816.  Saving model ...\n",
      "2022-04-03 04:55:21,002 | Validation loss got better 0.45226117119665155 --> 0.45146180972370137.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 04:58:11,618 | Epoch 20 Result\n",
      "2022-04-03 04:58:11,619 | \ttrain loss: 0.1946259662843735\tvalid_loss: 0.4536982166748491\n",
      "2022-04-03 04:58:11,619 | \tacc: 0.857082\tpc: 0.683083\trc: 0.663596\tf1: 0.662005\n",
      "2022-04-03 04:58:13,202 | Validation accuracy got better 0.8550930529904816 --> 0.8570819718710044.  Saving model ...\n",
      "2022-04-03 04:58:13,901 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 05:01:03,782 | Epoch 21 Result\n",
      "2022-04-03 05:01:03,782 | \ttrain loss: 0.18194287368613463\tvalid_loss: 0.45845438325112137\n",
      "2022-04-03 05:01:03,783 | \tacc: 0.858076\tpc: 0.688665\trc: 0.669659\tf1: 0.666621\n",
      "2022-04-03 05:01:05,360 | Validation accuracy got better 0.8570819718710044 --> 0.8580764313112658.  Saving model ...\n",
      "2022-04-03 05:01:05,967 | patience 1 --> 2\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.14it/s]\n",
      "2022-04-03 05:03:55,767 | Epoch 22 Result\n",
      "2022-04-03 05:03:55,768 | \ttrain loss: 0.17031157776105849\tvalid_loss: 0.4608031543145584\n",
      "2022-04-03 05:03:55,768 | \tacc: 0.857508\tpc: 0.696606\trc: 0.681703\tf1: 0.676983\n",
      "2022-04-03 05:03:57,322 | patience 2 --> 3\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 05:06:47,178 | Epoch 23 Result\n",
      "2022-04-03 05:06:47,178 | \ttrain loss: 0.160895140316134\tvalid_loss: 0.4701086611110288\n",
      "2022-04-03 05:06:47,179 | \tacc: 0.857082\tpc: 0.694403\trc: 0.675407\tf1: 0.671786\n",
      "2022-04-03 05:06:48,769 | patience 3 --> 4\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 05:09:38,613 | Epoch 24 Result\n",
      "2022-04-03 05:09:38,613 | \ttrain loss: 0.15068853982436953\tvalid_loss: 0.46951008677939865\n",
      "2022-04-03 05:09:38,614 | \tacc: 0.856443\tpc: 0.693003\trc: 0.685735\tf1: 0.676342\n",
      "2022-04-03 05:09:40,084 | patience 4 --> 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 05:09:40,085 | Early Stop!\n",
      "2022-04-03 05:09:40,086 | # train data: 132867\n",
      "2022-04-03 05:09:40,086 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:12:29,973 | Epoch 0 Result\n",
      "2022-04-03 05:12:29,973 | \ttrain loss: 5.083671797736496\tvalid_loss: 4.403045620967726\n",
      "2022-04-03 05:12:29,974 | \tacc: 0.407373\tpc: 0.060442\trc: 0.072275\tf1: 0.051877\n",
      "2022-04-03 05:12:31,139 | Validation accuracy got better None --> 0.40737320642136665.  Saving model ...\n",
      "2022-04-03 05:12:31,529 | Validation loss got better None --> 4.403045620967726.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:15:21,757 | Epoch 1 Result\n",
      "2022-04-03 05:15:21,757 | \ttrain loss: 3.4142319985699734\tvalid_loss: 2.1440998265851303\n",
      "2022-04-03 05:15:21,757 | \tacc: 0.514064\tpc: 0.077156\trc: 0.090631\tf1: 0.072404\n",
      "2022-04-03 05:15:23,302 | Validation accuracy got better 0.40737320642136665 --> 0.5140644977979827.  Saving model ...\n",
      "2022-04-03 05:15:24,050 | Validation loss got better 4.403045620967726 --> 2.1440998265851303.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 05:18:14,494 | Epoch 2 Result\n",
      "2022-04-03 05:18:14,495 | \ttrain loss: 1.688566384504658\tvalid_loss: 1.0238730678132928\n",
      "2022-04-03 05:18:14,495 | \tacc: 0.752735\tpc: 0.243539\trc: 0.247598\tf1: 0.228443\n",
      "2022-04-03 05:18:15,955 | Validation accuracy got better 0.5140644977979827 --> 0.7527347634607189.  Saving model ...\n",
      "2022-04-03 05:18:16,676 | Validation loss got better 2.1440998265851303 --> 1.0238730678132928.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 05:21:07,338 | Epoch 3 Result\n",
      "2022-04-03 05:21:07,338 | \ttrain loss: 0.9654728371173591\tvalid_loss: 0.5994400002262372\n",
      "2022-04-03 05:21:07,338 | \tacc: 0.828172\tpc: 0.384034\trc: 0.37829\tf1: 0.364281\n",
      "2022-04-03 05:21:09,013 | Validation accuracy got better 0.7527347634607189 --> 0.8281716152862623.  Saving model ...\n",
      "2022-04-03 05:21:09,712 | Validation loss got better 1.0238730678132928 --> 0.5994400002262372.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 05:24:00,241 | Epoch 4 Result\n",
      "2022-04-03 05:24:00,242 | \ttrain loss: 0.6183231949574733\tvalid_loss: 0.44471477596812975\n",
      "2022-04-03 05:24:00,242 | \tacc: 0.861273\tpc: 0.567947\trc: 0.543375\tf1: 0.540178\n",
      "2022-04-03 05:24:01,707 | Validation accuracy got better 0.8281716152862623 --> 0.8612729080835346.  Saving model ...\n",
      "2022-04-03 05:24:02,353 | Validation loss got better 0.5994400002262372 --> 0.44471477596812975.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 05:26:52,930 | Epoch 5 Result\n",
      "2022-04-03 05:26:52,930 | \ttrain loss: 0.44285734595911647\tvalid_loss: 0.382026645300283\n",
      "2022-04-03 05:26:52,931 | \tacc: 0.872496\tpc: 0.686721\trc: 0.631701\tf1: 0.63487\n",
      "2022-04-03 05:26:54,310 | Validation accuracy got better 0.8612729080835346 --> 0.8724960931950562.  Saving model ...\n",
      "2022-04-03 05:26:54,950 | Validation loss got better 0.44471477596812975 --> 0.382026645300283.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:29:45,540 | Epoch 6 Result\n",
      "2022-04-03 05:29:45,540 | \ttrain loss: 0.3514991366526888\tvalid_loss: 0.35947660604548193\n",
      "2022-04-03 05:29:45,541 | \tacc: 0.877184\tpc: 0.695798\trc: 0.676467\tf1: 0.667356\n",
      "2022-04-03 05:29:47,369 | Validation accuracy got better 0.8724960931950562 --> 0.877184259127717.  Saving model ...\n",
      "2022-04-03 05:29:48,059 | Validation loss got better 0.382026645300283 --> 0.35947660604548193.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:32:38,659 | Epoch 7 Result\n",
      "2022-04-03 05:32:38,659 | \ttrain loss: 0.30340592749693\tvalid_loss: 0.34510786947599104\n",
      "2022-04-03 05:32:38,659 | \tacc: 0.87896\tpc: 0.70521\trc: 0.687458\tf1: 0.685034\n",
      "2022-04-03 05:32:40,102 | Validation accuracy got better 0.877184259127717 --> 0.8789600795567553.  Saving model ...\n",
      "2022-04-03 05:32:40,789 | Validation loss got better 0.35947660604548193 --> 0.34510786947599104.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:35:31,347 | Epoch 8 Result\n",
      "2022-04-03 05:35:31,347 | \ttrain loss: 0.26852337901762563\tvalid_loss: 0.3444531473911593\n",
      "2022-04-03 05:35:31,347 | \tacc: 0.877113\tpc: 0.71405\trc: 0.699221\tf1: 0.695475\n",
      "2022-04-03 05:35:32,929 | Validation loss got better 0.34510786947599104 --> 0.3444531473911593.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 05:38:23,574 | Epoch 9 Result\n",
      "2022-04-03 05:38:23,574 | \ttrain loss: 0.24299257165777327\tvalid_loss: 0.3393626126871815\n",
      "2022-04-03 05:38:23,575 | \tacc: 0.880026\tpc: 0.723255\trc: 0.705063\tf1: 0.7031\n",
      "2022-04-03 05:38:25,039 | Validation accuracy got better 0.8789600795567553 --> 0.8800255718141782.  Saving model ...\n",
      "2022-04-03 05:38:25,684 | Validation loss got better 0.3444531473911593 --> 0.3393626126871815.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:41:16,287 | Epoch 10 Result\n",
      "2022-04-03 05:41:16,288 | \ttrain loss: 0.22054941232847447\tvalid_loss: 0.3402342172420267\n",
      "2022-04-03 05:41:16,288 | \tacc: 0.879102\tpc: 0.709791\trc: 0.701718\tf1: 0.696768\n",
      "2022-04-03 05:41:17,760 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:44:07,704 | Epoch 11 Result\n",
      "2022-04-03 05:44:07,704 | \ttrain loss: 0.2044573714969188\tvalid_loss: 0.3394541376303299\n",
      "2022-04-03 05:44:07,705 | \tacc: 0.880452\tpc: 0.719877\trc: 0.711745\tf1: 0.705894\n",
      "2022-04-03 05:44:09,280 | Validation accuracy got better 0.8800255718141782 --> 0.8804517687171474.  Saving model ...\n",
      "2022-04-03 05:44:10,005 | patience 1 --> 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 05:46:59,965 | Epoch 12 Result\n",
      "2022-04-03 05:46:59,965 | \ttrain loss: 0.18899443097963753\tvalid_loss: 0.346474567145884\n",
      "2022-04-03 05:46:59,966 | \tacc: 0.88031\tpc: 0.717968\trc: 0.706373\tf1: 0.70256\n",
      "2022-04-03 05:47:01,369 | patience 2 --> 3\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:49:51,278 | Epoch 13 Result\n",
      "2022-04-03 05:49:51,279 | \ttrain loss: 0.17717649855128823\tvalid_loss: 0.3478423764140349\n",
      "2022-04-03 05:49:51,279 | \tacc: 0.879386\tpc: 0.723475\trc: 0.707122\tf1: 0.704801\n",
      "2022-04-03 05:49:53,044 | patience 3 --> 4\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 05:52:43,055 | Epoch 14 Result\n",
      "2022-04-03 05:52:43,055 | \ttrain loss: 0.16316900498437703\tvalid_loss: 0.35080675710278963\n",
      "2022-04-03 05:52:43,055 | \tacc: 0.880168\tpc: 0.722742\trc: 0.707102\tf1: 0.705986\n",
      "2022-04-03 05:52:44,410 | patience 4 --> 5\n",
      "2022-04-03 05:52:44,410 | Early Stop!\n",
      "2022-04-03 05:52:44,411 | # train data: 132867\n",
      "2022-04-03 05:52:44,412 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 05:55:34,402 | Epoch 0 Result\n",
      "2022-04-03 05:55:34,403 | \ttrain loss: 5.033938235235719\tvalid_loss: 4.267659357078781\n",
      "2022-04-03 05:55:34,403 | \tacc: 0.459795\tpc: 0.083429\trc: 0.083238\tf1: 0.066099\n",
      "2022-04-03 05:55:35,593 | Validation accuracy got better None --> 0.4597954254865748.  Saving model ...\n",
      "2022-04-03 05:55:35,970 | Validation loss got better None --> 4.267659357078781.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 05:58:26,348 | Epoch 1 Result\n",
      "2022-04-03 05:58:26,348 | \ttrain loss: 3.237309949981782\tvalid_loss: 1.9477522531377438\n",
      "2022-04-03 05:58:26,349 | \tacc: 0.574869\tpc: 0.100568\trc: 0.110249\tf1: 0.09072\n",
      "2022-04-03 05:58:27,590 | Validation accuracy got better 0.4597954254865748 --> 0.5748685892882511.  Saving model ...\n",
      "2022-04-03 05:58:28,190 | Validation loss got better 4.267659357078781 --> 1.9477522531377438.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 06:01:18,864 | Epoch 2 Result\n",
      "2022-04-03 06:01:18,864 | \ttrain loss: 1.5221730303310177\tvalid_loss: 0.8785234667526962\n",
      "2022-04-03 06:01:18,865 | \tacc: 0.785126\tpc: 0.246444\trc: 0.273214\tf1: 0.250494\n",
      "2022-04-03 06:01:20,323 | Validation accuracy got better 0.5748685892882511 --> 0.7851257280863759.  Saving model ...\n",
      "2022-04-03 06:01:20,922 | Validation loss got better 1.9477522531377438 --> 0.8785234667526962.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 06:04:11,486 | Epoch 3 Result\n",
      "2022-04-03 06:04:11,487 | \ttrain loss: 0.8291618562132642\tvalid_loss: 0.49932753110003075\n",
      "2022-04-03 06:04:11,487 | \tacc: 0.852323\tpc: 0.466843\trc: 0.454592\tf1: 0.445707\n",
      "2022-04-03 06:04:12,995 | Validation accuracy got better 0.7851257280863759 --> 0.852322773121182.  Saving model ...\n",
      "2022-04-03 06:04:13,647 | Validation loss got better 0.8785234667526962 --> 0.49932753110003075.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.08it/s]\n",
      "2022-04-03 06:07:04,269 | Epoch 4 Result\n",
      "2022-04-03 06:07:04,269 | \ttrain loss: 0.5052898299857622\tvalid_loss: 0.36683680129196855\n",
      "2022-04-03 06:07:04,270 | \tacc: 0.87761\tpc: 0.695537\trc: 0.641953\tf1: 0.645736\n",
      "2022-04-03 06:07:05,729 | Validation accuracy got better 0.852322773121182 --> 0.8776104560306862.  Saving model ...\n",
      "2022-04-03 06:07:06,375 | Validation loss got better 0.49932753110003075 --> 0.36683680129196855.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 06:09:56,979 | Epoch 5 Result\n",
      "2022-04-03 06:09:56,980 | \ttrain loss: 0.3488665809585913\tvalid_loss: 0.32154876694013357\n",
      "2022-04-03 06:09:56,980 | \tacc: 0.886774\tpc: 0.753105\trc: 0.729344\tf1: 0.728281\n",
      "2022-04-03 06:09:58,441 | Validation accuracy got better 0.8776104560306862 --> 0.8867736894445234.  Saving model ...\n",
      "2022-04-03 06:09:59,268 | Validation loss got better 0.36683680129196855 --> 0.32154876694013357.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.13it/s]\n",
      "2022-04-03 06:12:49,874 | Epoch 6 Result\n",
      "2022-04-03 06:12:49,875 | \ttrain loss: 0.2799282014514415\tvalid_loss: 0.3064149046320183\n",
      "2022-04-03 06:12:49,875 | \tacc: 0.885992\tpc: 0.766181\trc: 0.747851\tf1: 0.744734\n",
      "2022-04-03 06:12:51,353 | Validation loss got better 0.32154876694013357 --> 0.3064149046320183.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 06:15:42,026 | Epoch 7 Result\n",
      "2022-04-03 06:15:42,027 | \ttrain loss: 0.24508556816881832\tvalid_loss: 0.3024524256559508\n",
      "2022-04-03 06:15:42,027 | \tacc: 0.884927\tpc: 0.780578\trc: 0.748214\tf1: 0.751086\n",
      "2022-04-03 06:15:43,485 | Validation loss got better 0.3064149046320183 --> 0.3024524256559508.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 06:18:34,065 | Epoch 8 Result\n",
      "2022-04-03 06:18:34,066 | \ttrain loss: 0.22016562174227094\tvalid_loss: 0.30142623706879407\n",
      "2022-04-03 06:18:34,066 | \tacc: 0.887484\tpc: 0.771963\trc: 0.761139\tf1: 0.755902\n",
      "2022-04-03 06:18:35,530 | Validation accuracy got better 0.8867736894445234 --> 0.8874840176161387.  Saving model ...\n",
      "2022-04-03 06:18:36,126 | Validation loss got better 0.3024524256559508 --> 0.30142623706879407.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 06:21:26,715 | Epoch 9 Result\n",
      "2022-04-03 06:21:26,715 | \ttrain loss: 0.2002564621612555\tvalid_loss: 0.2999660388230092\n",
      "2022-04-03 06:21:26,716 | \tacc: 0.887484\tpc: 0.766161\trc: 0.753078\tf1: 0.74937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 06:21:28,167 | Validation loss got better 0.30142623706879407 --> 0.2999660388230092.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "2022-04-03 06:24:18,689 | Epoch 10 Result\n",
      "2022-04-03 06:24:18,690 | \ttrain loss: 0.1835794257917778\tvalid_loss: 0.30170719471823204\n",
      "2022-04-03 06:24:18,690 | \tacc: 0.885921\tpc: 0.778922\trc: 0.754302\tf1: 0.75354\n",
      "2022-04-03 06:24:20,261 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 06:27:10,222 | Epoch 11 Result\n",
      "2022-04-03 06:27:10,223 | \ttrain loss: 0.17010377689496103\tvalid_loss: 0.304932320104402\n",
      "2022-04-03 06:27:10,223 | \tacc: 0.884003\tpc: 0.753493\trc: 0.752696\tf1: 0.742992\n",
      "2022-04-03 06:27:11,911 | patience 1 --> 2\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 06:30:01,940 | Epoch 12 Result\n",
      "2022-04-03 06:30:01,941 | \ttrain loss: 0.15633212066697014\tvalid_loss: 0.3130636542235303\n",
      "2022-04-03 06:30:01,941 | \tacc: 0.883648\tpc: 0.767357\trc: 0.760673\tf1: 0.755259\n",
      "2022-04-03 06:30:03,585 | patience 2 --> 3\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.09it/s]\n",
      "2022-04-03 06:32:53,670 | Epoch 13 Result\n",
      "2022-04-03 06:32:53,670 | \ttrain loss: 0.14568329968131308\tvalid_loss: 0.31409834530021946\n",
      "2022-04-03 06:32:53,670 | \tacc: 0.884856\tpc: 0.762913\trc: 0.758991\tf1: 0.751797\n",
      "2022-04-03 06:32:55,406 | patience 3 --> 4\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.08it/s]\n",
      "2022-04-03 06:35:45,461 | Epoch 14 Result\n",
      "2022-04-03 06:35:45,461 | \ttrain loss: 0.13453065038663367\tvalid_loss: 0.31712226885288747\n",
      "2022-04-03 06:35:45,461 | \tacc: 0.884288\tpc: 0.7621\trc: 0.764357\tf1: 0.754498\n",
      "2022-04-03 06:35:47,062 | patience 4 --> 5\n",
      "2022-04-03 06:35:47,063 | Early Stop!\n",
      "2022-04-03 06:35:47,064 | # train data: 132867\n",
      "2022-04-03 06:35:47,064 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 06:38:37,078 | Epoch 0 Result\n",
      "2022-04-03 06:38:37,078 | \ttrain loss: 4.962217871740681\tvalid_loss: 4.155525554494943\n",
      "2022-04-03 06:38:37,079 | \tacc: 0.451911\tpc: 0.100181\trc: 0.092066\tf1: 0.080693\n",
      "2022-04-03 06:38:38,267 | Validation accuracy got better None --> 0.4519107827816451.  Saving model ...\n",
      "2022-04-03 06:38:38,652 | Validation loss got better None --> 4.155525554494943.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 06:41:29,083 | Epoch 1 Result\n",
      "2022-04-03 06:41:29,083 | \ttrain loss: 3.100973797726258\tvalid_loss: 1.804253111984398\n",
      "2022-04-03 06:41:29,083 | \tacc: 0.622887\tpc: 0.131991\trc: 0.137426\tf1: 0.122109\n",
      "2022-04-03 06:41:30,964 | Validation accuracy got better 0.4519107827816451 --> 0.6228867736894446.  Saving model ...\n",
      "2022-04-03 06:41:31,658 | Validation loss got better 4.155525554494943 --> 1.804253111984398.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 06:44:22,278 | Epoch 2 Result\n",
      "2022-04-03 06:44:22,278 | \ttrain loss: 1.413612184336876\tvalid_loss: 0.8081775903193716\n",
      "2022-04-03 06:44:22,279 | \tacc: 0.809774\tpc: 0.309944\trc: 0.314559\tf1: 0.296161\n",
      "2022-04-03 06:44:23,750 | Validation accuracy got better 0.6228867736894446 --> 0.8097741156414263.  Saving model ...\n",
      "2022-04-03 06:44:24,428 | Validation loss got better 1.804253111984398 --> 0.8081775903193716.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 06:47:15,004 | Epoch 3 Result\n",
      "2022-04-03 06:47:15,004 | \ttrain loss: 0.7581007963271953\tvalid_loss: 0.463571247923762\n",
      "2022-04-03 06:47:15,005 | \tacc: 0.863688\tpc: 0.491659\trc: 0.47931\tf1: 0.472135\n",
      "2022-04-03 06:47:16,449 | Validation accuracy got better 0.8097741156414263 --> 0.8636880238670266.  Saving model ...\n",
      "2022-04-03 06:47:17,354 | Validation loss got better 0.8081775903193716 --> 0.463571247923762.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 06:50:08,114 | Epoch 4 Result\n",
      "2022-04-03 06:50:08,114 | \ttrain loss: 0.445432604283122\tvalid_loss: 0.3444838928624232\n",
      "2022-04-03 06:50:08,114 | \tacc: 0.886703\tpc: 0.744497\trc: 0.705479\tf1: 0.704982\n",
      "2022-04-03 06:50:09,565 | Validation accuracy got better 0.8636880238670266 --> 0.8867026566273618.  Saving model ...\n",
      "2022-04-03 06:50:10,397 | Validation loss got better 0.463571247923762 --> 0.3444838928624232.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.09it/s]\n",
      "2022-04-03 06:53:01,159 | Epoch 5 Result\n",
      "2022-04-03 06:53:01,160 | \ttrain loss: 0.30458257336472316\tvalid_loss: 0.3025090434128189\n",
      "2022-04-03 06:53:01,160 | \tacc: 0.893664\tpc: 0.781755\trc: 0.747163\tf1: 0.747742\n",
      "2022-04-03 06:53:02,992 | Validation accuracy got better 0.8867026566273618 --> 0.8936638727091917.  Saving model ...\n",
      "2022-04-03 06:53:03,781 | Validation loss got better 0.3444838928624232 --> 0.3025090434128189.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 06:55:54,338 | Epoch 6 Result\n",
      "2022-04-03 06:55:54,339 | \ttrain loss: 0.24740926606840286\tvalid_loss: 0.2921333952051009\n",
      "2022-04-03 06:55:54,339 | \tacc: 0.895866\tpc: 0.764965\trc: 0.758956\tf1: 0.753572\n",
      "2022-04-03 06:55:55,749 | Validation accuracy got better 0.8936638727091917 --> 0.895865890041199.  Saving model ...\n",
      "2022-04-03 06:55:56,429 | Validation loss got better 0.3025090434128189 --> 0.2921333952051009.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 06:58:47,053 | Epoch 7 Result\n",
      "2022-04-03 06:58:47,053 | \ttrain loss: 0.21519412519097983\tvalid_loss: 0.2894695292042135\n",
      "2022-04-03 06:58:47,054 | \tacc: 0.893309\tpc: 0.773188\trc: 0.764065\tf1: 0.760479\n",
      "2022-04-03 06:58:48,540 | Validation loss got better 0.2921333952051009 --> 0.2894695292042135.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.08it/s]\n",
      "2022-04-03 07:01:39,265 | Epoch 8 Result\n",
      "2022-04-03 07:01:39,265 | \ttrain loss: 0.19216724304691207\tvalid_loss: 0.2870144917555434\n",
      "2022-04-03 07:01:39,266 | \tacc: 0.893025\tpc: 0.769908\trc: 0.762811\tf1: 0.759007\n",
      "2022-04-03 07:01:40,936 | Validation loss got better 0.2894695292042135 --> 0.2870144917555434.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 07:04:31,664 | Epoch 9 Result\n",
      "2022-04-03 07:04:31,664 | \ttrain loss: 0.17465646467377932\tvalid_loss: 0.28958163753899174\n",
      "2022-04-03 07:04:31,664 | \tacc: 0.894303\tpc: 0.769543\trc: 0.765224\tf1: 0.759678\n",
      "2022-04-03 07:04:33,177 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 07:07:23,158 | Epoch 10 Result\n",
      "2022-04-03 07:07:23,159 | \ttrain loss: 0.15989227776188547\tvalid_loss: 0.2905270643558738\n",
      "2022-04-03 07:07:23,159 | \tacc: 0.892883\tpc: 0.768707\trc: 0.755268\tf1: 0.754679\n",
      "2022-04-03 07:07:24,618 | patience 1 --> 2\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 07:10:14,646 | Epoch 11 Result\n",
      "2022-04-03 07:10:14,647 | \ttrain loss: 0.1476321294501694\tvalid_loss: 0.2914927121437583\n",
      "2022-04-03 07:10:14,647 | \tacc: 0.892669\tpc: 0.769318\trc: 0.757321\tf1: 0.757906\n",
      "2022-04-03 07:10:16,217 | patience 2 --> 3\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 07:13:06,322 | Epoch 12 Result\n",
      "2022-04-03 07:13:06,322 | \ttrain loss: 0.1347358617884641\tvalid_loss: 0.2996373458466826\n",
      "2022-04-03 07:13:06,323 | \tacc: 0.891675\tpc: 0.760646\trc: 0.757278\tf1: 0.752805\n",
      "2022-04-03 07:13:07,789 | patience 3 --> 4\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 07:15:57,846 | Epoch 13 Result\n",
      "2022-04-03 07:15:57,847 | \ttrain loss: 0.12560750038393748\tvalid_loss: 0.30235210243553784\n",
      "2022-04-03 07:15:57,847 | \tacc: 0.890183\tpc: 0.756934\trc: 0.755888\tf1: 0.749622\n",
      "2022-04-03 07:15:59,554 | patience 4 --> 5\n",
      "2022-04-03 07:15:59,555 | Early Stop!\n",
      "2022-04-03 07:15:59,556 | # train data: 132867\n",
      "2022-04-03 07:15:59,556 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.09it/s]\n",
      "2022-04-03 07:18:49,656 | Epoch 0 Result\n",
      "2022-04-03 07:18:49,656 | \ttrain loss: 4.982949092521353\tvalid_loss: 4.160117723671173\n",
      "2022-04-03 07:18:49,657 | \tacc: 0.450632\tpc: 0.075794\trc: 0.083673\tf1: 0.068853\n",
      "2022-04-03 07:18:50,828 | Validation accuracy got better None --> 0.4506321920727376.  Saving model ...\n",
      "2022-04-03 07:18:51,212 | Validation loss got better None --> 4.160117723671173.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.11it/s]\n",
      "2022-04-03 07:21:41,654 | Epoch 1 Result\n",
      "2022-04-03 07:21:41,655 | \ttrain loss: 3.0762262762180983\tvalid_loss: 1.7582962822890413\n",
      "2022-04-03 07:21:41,655 | \tacc: 0.668206\tpc: 0.156682\trc: 0.164446\tf1: 0.14475\n",
      "2022-04-03 07:21:43,229 | Validation accuracy got better 0.4506321920727376 --> 0.6682057110384998.  Saving model ...\n",
      "2022-04-03 07:21:43,831 | Validation loss got better 4.160117723671173 --> 1.7582962822890413.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.05it/s]\n",
      "2022-04-03 07:24:34,558 | Epoch 2 Result\n",
      "2022-04-03 07:24:34,559 | \ttrain loss: 1.3504572175082887\tvalid_loss: 0.7585264161358267\n",
      "2022-04-03 07:24:34,559 | \tacc: 0.819221\tpc: 0.30972\trc: 0.322277\tf1: 0.303696\n",
      "2022-04-03 07:24:36,133 | Validation accuracy got better 0.6682057110384998 --> 0.8192214803239096.  Saving model ...\n",
      "2022-04-03 07:24:36,828 | Validation loss got better 1.7582962822890413 --> 0.7585264161358267.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 07:27:27,631 | Epoch 3 Result\n",
      "2022-04-03 07:27:27,632 | \ttrain loss: 0.7085583997403324\tvalid_loss: 0.4274558888560145\n",
      "2022-04-03 07:27:27,632 | \tacc: 0.873846\tpc: 0.542439\trc: 0.521881\tf1: 0.515455\n",
      "2022-04-03 07:27:28,892 | Validation accuracy got better 0.8192214803239096 --> 0.8738457167211252.  Saving model ...\n",
      "2022-04-03 07:27:29,534 | Validation loss got better 0.7585264161358267 --> 0.4274558888560145.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.09it/s]\n",
      "2022-04-03 07:30:20,299 | Epoch 4 Result\n",
      "2022-04-03 07:30:20,300 | \ttrain loss: 0.40485057919804573\tvalid_loss: 0.31580744807160294\n",
      "2022-04-03 07:30:20,300 | \tacc: 0.894658\tpc: 0.746318\trc: 0.725842\tf1: 0.721177\n",
      "2022-04-03 07:30:21,762 | Validation accuracy got better 0.8738457167211252 --> 0.894658332149453.  Saving model ...\n",
      "2022-04-03 07:30:22,327 | Validation loss got better 0.4274558888560145 --> 0.31580744807160294.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.08it/s]\n",
      "2022-04-03 07:33:13,093 | Epoch 5 Result\n",
      "2022-04-03 07:33:13,094 | \ttrain loss: 0.27295713967600915\tvalid_loss: 0.28207062282825096\n",
      "2022-04-03 07:33:13,094 | \tacc: 0.90027\tpc: 0.772768\trc: 0.769152\tf1: 0.759567\n",
      "2022-04-03 07:33:14,551 | Validation accuracy got better 0.894658332149453 --> 0.9002699247052138.  Saving model ...\n",
      "2022-04-03 07:33:15,155 | Validation loss got better 0.31580744807160294 --> 0.28207062282825096.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.08it/s]\n",
      "2022-04-03 07:36:06,026 | Epoch 6 Result\n",
      "2022-04-03 07:36:06,026 | \ttrain loss: 0.21956852221497566\tvalid_loss: 0.27373044615121095\n",
      "2022-04-03 07:36:06,026 | \tacc: 0.899773\tpc: 0.767285\trc: 0.7787\tf1: 0.764272\n",
      "2022-04-03 07:36:07,668 | Validation loss got better 0.28207062282825096 --> 0.27373044615121095.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 07:38:58,403 | Epoch 7 Result\n",
      "2022-04-03 07:38:58,403 | \ttrain loss: 0.19318054663408868\tvalid_loss: 0.2689707800015619\n",
      "2022-04-03 07:38:58,403 | \tacc: 0.900696\tpc: 0.771595\trc: 0.779828\tf1: 0.767419\n",
      "2022-04-03 07:39:00,010 | Validation accuracy got better 0.9002699247052138 --> 0.900696121608183.  Saving model ...\n",
      "2022-04-03 07:39:00,715 | Validation loss got better 0.27373044615121095 --> 0.2689707800015619.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.04it/s]\n",
      "2022-04-03 07:41:51,515 | Epoch 8 Result\n",
      "2022-04-03 07:41:51,515 | \ttrain loss: 0.1743334252196208\tvalid_loss: 0.2713867105582777\n",
      "2022-04-03 07:41:51,516 | \tacc: 0.901264\tpc: 0.762245\trc: 0.781343\tf1: 0.764523\n",
      "2022-04-03 07:41:52,902 | Validation accuracy got better 0.900696121608183 --> 0.9012643841454752.  Saving model ...\n",
      "2022-04-03 07:41:53,508 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.09it/s]\n",
      "2022-04-03 07:44:43,561 | Epoch 9 Result\n",
      "2022-04-03 07:44:43,561 | \ttrain loss: 0.15816516909758324\tvalid_loss: 0.27375736856751864\n",
      "2022-04-03 07:44:43,562 | \tacc: 0.898423\tpc: 0.762791\trc: 0.783587\tf1: 0.766104\n",
      "2022-04-03 07:44:45,345 | patience 1 --> 2\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.09it/s]\n",
      "2022-04-03 07:47:35,469 | Epoch 10 Result\n",
      "2022-04-03 07:47:35,469 | \ttrain loss: 0.14459133460651533\tvalid_loss: 0.2747003412378801\n",
      "2022-04-03 07:47:35,469 | \tacc: 0.899418\tpc: 0.767335\trc: 0.776402\tf1: 0.763063\n",
      "2022-04-03 07:47:37,296 | patience 2 --> 3\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.10it/s]\n",
      "2022-04-03 07:50:27,384 | Epoch 11 Result\n",
      "2022-04-03 07:50:27,384 | \ttrain loss: 0.13289055717088144\tvalid_loss: 0.27762156081379163\n",
      "2022-04-03 07:50:27,385 | \tacc: 0.899986\tpc: 0.764578\trc: 0.77764\tf1: 0.763714\n",
      "2022-04-03 07:50:28,867 | patience 3 --> 4\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [02:43<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:06<00:00,  4.08it/s]\n",
      "2022-04-03 07:53:19,086 | Epoch 12 Result\n",
      "2022-04-03 07:53:19,087 | \ttrain loss: 0.12344955068741037\tvalid_loss: 0.28161020357850297\n",
      "2022-04-03 07:53:19,087 | \tacc: 0.899062\tpc: 0.763691\trc: 0.769128\tf1: 0.759208\n",
      "2022-04-03 07:53:20,667 | patience 4 --> 5\n",
      "2022-04-03 07:53:20,667 | Early Stop!\n",
      "2022-04-03 07:53:20,668 | # train data: 132867\n",
      "2022-04-03 07:53:20,669 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 07:55:03,106 | Epoch 0 Result\n",
      "2022-04-03 07:55:03,106 | \ttrain loss: 5.06295085388095\tvalid_loss: 4.3778192204734045\n",
      "2022-04-03 07:55:03,107 | \tacc: 0.097812\tpc: 0.000435\trc: 0.004444\tf1: 0.000792\n",
      "2022-04-03 07:55:03,697 | Validation accuracy got better None --> 0.09781218923142491.  Saving model ...\n",
      "2022-04-03 07:55:03,749 | Validation loss got better None --> 4.3778192204734045.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 07:56:45,857 | Epoch 1 Result\n",
      "2022-04-03 07:56:45,857 | \ttrain loss: 3.9032895983903324\tvalid_loss: 3.1026644633564526\n",
      "2022-04-03 07:56:45,858 | \tacc: 0.312331\tpc: 0.05002\trc: 0.043791\tf1: 0.032565\n",
      "2022-04-03 07:56:46,495 | Validation accuracy got better 0.09781218923142491 --> 0.31233129705924134.  Saving model ...\n",
      "2022-04-03 07:56:46,558 | Validation loss got better 4.3778192204734045 --> 3.1026644633564526.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 07:58:28,841 | Epoch 2 Result\n",
      "2022-04-03 07:58:28,842 | \ttrain loss: 2.9162572013480994\tvalid_loss: 2.1172445422293262\n",
      "2022-04-03 07:58:28,842 | \tacc: 0.497798\tpc: 0.13539\trc: 0.099498\tf1: 0.092275\n",
      "2022-04-03 07:58:29,491 | Validation accuracy got better 0.31233129705924134 --> 0.49779798266799263.  Saving model ...\n",
      "2022-04-03 07:58:29,569 | Validation loss got better 3.1026644633564526 --> 2.1172445422293262.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:00:11,698 | Epoch 3 Result\n",
      "2022-04-03 08:00:11,698 | \ttrain loss: 2.1034798762939118\tvalid_loss: 1.452214625532408\n",
      "2022-04-03 08:00:11,698 | \tacc: 0.62516\tpc: 0.220326\trc: 0.183377\tf1: 0.177442\n",
      "2022-04-03 08:00:12,320 | Validation accuracy got better 0.49779798266799263 --> 0.6251598238386135.  Saving model ...\n",
      "2022-04-03 08:00:12,382 | Validation loss got better 2.1172445422293262 --> 1.452214625532408.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:01:54,543 | Epoch 4 Result\n",
      "2022-04-03 08:01:54,543 | \ttrain loss: 1.5715890050349794\tvalid_loss: 1.1085507900204437\n",
      "2022-04-03 08:01:54,544 | \tacc: 0.684685\tpc: 0.306581\trc: 0.259931\tf1: 0.262217\n",
      "2022-04-03 08:01:55,174 | Validation accuracy got better 0.6251598238386135 --> 0.6846853246199744.  Saving model ...\n",
      "2022-04-03 08:01:55,243 | Validation loss got better 1.452214625532408 --> 1.1085507900204437.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:03:37,398 | Epoch 5 Result\n",
      "2022-04-03 08:03:37,399 | \ttrain loss: 1.2719463716204333\tvalid_loss: 0.9263774518821707\n",
      "2022-04-03 08:03:37,399 | \tacc: 0.713098\tpc: 0.409986\trc: 0.32001\tf1: 0.3295\n",
      "2022-04-03 08:03:38,024 | Validation accuracy got better 0.6846853246199744 --> 0.7130984514845858.  Saving model ...\n",
      "2022-04-03 08:03:38,088 | Validation loss got better 1.1085507900204437 --> 0.9263774518821707.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:05:20,238 | Epoch 6 Result\n",
      "2022-04-03 08:05:20,238 | \ttrain loss: 1.0902657093541646\tvalid_loss: 0.8153356051373878\n",
      "2022-04-03 08:05:20,239 | \tacc: 0.734621\tpc: 0.467294\trc: 0.37347\tf1: 0.387994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 08:05:20,862 | Validation accuracy got better 0.7130984514845858 --> 0.7346213950845291.  Saving model ...\n",
      "2022-04-03 08:05:20,928 | Validation loss got better 0.9263774518821707 --> 0.8153356051373878.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:07:03,119 | Epoch 7 Result\n",
      "2022-04-03 08:07:03,119 | \ttrain loss: 0.9708926495400234\tvalid_loss: 0.742825942345007\n",
      "2022-04-03 08:07:03,120 | \tacc: 0.747762\tpc: 0.508208\trc: 0.411118\tf1: 0.429234\n",
      "2022-04-03 08:07:03,753 | Validation accuracy got better 0.7346213950845291 --> 0.7477624662594119.  Saving model ...\n",
      "2022-04-03 08:07:03,834 | Validation loss got better 0.8153356051373878 --> 0.742825942345007.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:08:46,041 | Epoch 8 Result\n",
      "2022-04-03 08:08:46,041 | \ttrain loss: 0.888829228483555\tvalid_loss: 0.6911514299229848\n",
      "2022-04-03 08:08:46,042 | \tacc: 0.758133\tpc: 0.528105\trc: 0.434336\tf1: 0.45266\n",
      "2022-04-03 08:08:46,700 | Validation accuracy got better 0.7477624662594119 --> 0.7581332575649951.  Saving model ...\n",
      "2022-04-03 08:08:46,784 | Validation loss got better 0.742825942345007 --> 0.6911514299229848.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:10:28,917 | Epoch 9 Result\n",
      "2022-04-03 08:10:28,917 | \ttrain loss: 0.8308036711828999\tvalid_loss: 0.6550679014968439\n",
      "2022-04-03 08:10:28,918 | \tacc: 0.769214\tpc: 0.56424\trc: 0.467262\tf1: 0.48874\n",
      "2022-04-03 08:10:29,541 | Validation accuracy got better 0.7581332575649951 --> 0.7692143770421935.  Saving model ...\n",
      "2022-04-03 08:10:29,614 | Validation loss got better 0.6911514299229848 --> 0.6550679014968439.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:12:11,776 | Epoch 10 Result\n",
      "2022-04-03 08:12:11,777 | \ttrain loss: 0.7823988012578929\tvalid_loss: 0.6258598408554745\n",
      "2022-04-03 08:12:11,777 | \tacc: 0.775181\tpc: 0.571673\trc: 0.484346\tf1: 0.502845\n",
      "2022-04-03 08:12:12,399 | Validation accuracy got better 0.7692143770421935 --> 0.7751811336837618.  Saving model ...\n",
      "2022-04-03 08:12:12,462 | Validation loss got better 0.6550679014968439 --> 0.6258598408554745.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:13:54,609 | Epoch 11 Result\n",
      "2022-04-03 08:13:54,609 | \ttrain loss: 0.7484084843052317\tvalid_loss: 0.6049311051468295\n",
      "2022-04-03 08:13:54,610 | \tacc: 0.779798\tpc: 0.594102\trc: 0.494608\tf1: 0.517158\n",
      "2022-04-03 08:13:55,229 | Validation accuracy got better 0.7751811336837618 --> 0.7797982667992612.  Saving model ...\n",
      "2022-04-03 08:13:55,293 | Validation loss got better 0.6258598408554745 --> 0.6049311051468295.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 08:15:37,508 | Epoch 12 Result\n",
      "2022-04-03 08:15:37,508 | \ttrain loss: 0.7198749206742572\tvalid_loss: 0.587726016751845\n",
      "2022-04-03 08:15:37,509 | \tacc: 0.781929\tpc: 0.618092\trc: 0.512252\tf1: 0.534992\n",
      "2022-04-03 08:15:38,175 | Validation accuracy got better 0.7797982667992612 --> 0.7819292513141071.  Saving model ...\n",
      "2022-04-03 08:15:38,262 | Validation loss got better 0.6049311051468295 --> 0.587726016751845.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:17:20,415 | Epoch 13 Result\n",
      "2022-04-03 08:17:20,416 | \ttrain loss: 0.6963718867577743\tvalid_loss: 0.5724878121817852\n",
      "2022-04-03 08:17:20,416 | \tacc: 0.787754\tpc: 0.609998\trc: 0.5165\tf1: 0.536664\n",
      "2022-04-03 08:17:21,053 | Validation accuracy got better 0.7819292513141071 --> 0.7877539423213524.  Saving model ...\n",
      "2022-04-03 08:17:21,123 | Validation loss got better 0.587726016751845 --> 0.5724878121817852.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:19:03,291 | Epoch 14 Result\n",
      "2022-04-03 08:19:03,291 | \ttrain loss: 0.6772116849315812\tvalid_loss: 0.561306329829599\n",
      "2022-04-03 08:19:03,292 | \tacc: 0.790666\tpc: 0.631384\trc: 0.535734\tf1: 0.556454\n",
      "2022-04-03 08:19:03,922 | Validation accuracy got better 0.7877539423213524 --> 0.7906662878249752.  Saving model ...\n",
      "2022-04-03 08:19:03,991 | Validation loss got better 0.5724878121817852 --> 0.561306329829599.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:20:46,167 | Epoch 15 Result\n",
      "2022-04-03 08:20:46,167 | \ttrain loss: 0.6616988503510458\tvalid_loss: 0.5505375816056904\n",
      "2022-04-03 08:20:46,168 | \tacc: 0.794715\tpc: 0.629858\trc: 0.536577\tf1: 0.558704\n",
      "2022-04-03 08:20:46,790 | Validation accuracy got better 0.7906662878249752 --> 0.7947151584031823.  Saving model ...\n",
      "2022-04-03 08:20:46,853 | Validation loss got better 0.561306329829599 --> 0.5505375816056904.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:22:29,058 | Epoch 16 Result\n",
      "2022-04-03 08:22:29,059 | \ttrain loss: 0.6462998952473306\tvalid_loss: 0.542776935902284\n",
      "2022-04-03 08:22:29,059 | \tacc: 0.795994\tpc: 0.631216\trc: 0.543425\tf1: 0.562575\n",
      "2022-04-03 08:22:29,687 | Validation accuracy got better 0.7947151584031823 --> 0.7959937491120898.  Saving model ...\n",
      "2022-04-03 08:22:29,749 | Validation loss got better 0.5505375816056904 --> 0.542776935902284.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:24:11,962 | Epoch 17 Result\n",
      "2022-04-03 08:24:11,962 | \ttrain loss: 0.6327416625293629\tvalid_loss: 0.5336130575321499\n",
      "2022-04-03 08:24:11,963 | \tacc: 0.795923\tpc: 0.626434\trc: 0.54861\tf1: 0.567804\n",
      "2022-04-03 08:24:12,593 | Validation loss got better 0.542776935902284 --> 0.5336130575321499.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:25:54,826 | Epoch 18 Result\n",
      "2022-04-03 08:25:54,827 | \ttrain loss: 0.6220314417369186\tvalid_loss: 0.527284014985412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 08:25:54,827 | \tacc: 0.799119\tpc: 0.639981\trc: 0.554024\tf1: 0.574217\n",
      "2022-04-03 08:25:55,454 | Validation accuracy got better 0.7959937491120898 --> 0.799119193067197.  Saving model ...\n",
      "2022-04-03 08:25:55,517 | Validation loss got better 0.5336130575321499 --> 0.527284014985412.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:27:37,716 | Epoch 19 Result\n",
      "2022-04-03 08:27:37,717 | \ttrain loss: 0.6120316319385355\tvalid_loss: 0.5226666372359892\n",
      "2022-04-03 08:27:37,717 | \tacc: 0.801534\tpc: 0.640052\trc: 0.561792\tf1: 0.580472\n",
      "2022-04-03 08:27:38,353 | Validation accuracy got better 0.799119193067197 --> 0.801534308850689.  Saving model ...\n",
      "2022-04-03 08:27:38,416 | Validation loss got better 0.527284014985412 --> 0.5226666372359892.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:29:20,578 | Epoch 20 Result\n",
      "2022-04-03 08:29:20,579 | \ttrain loss: 0.6032723343662053\tvalid_loss: 0.5154233564451889\n",
      "2022-04-03 08:29:20,579 | \tacc: 0.800824\tpc: 0.6352\trc: 0.558129\tf1: 0.576162\n",
      "2022-04-03 08:29:21,218 | Validation loss got better 0.5226666372359892 --> 0.5154233564451889.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 08:31:03,502 | Epoch 21 Result\n",
      "2022-04-03 08:31:03,502 | \ttrain loss: 0.5962030595221729\tvalid_loss: 0.5114399335282417\n",
      "2022-04-03 08:31:03,503 | \tacc: 0.803239\tpc: 0.632022\trc: 0.566155\tf1: 0.579704\n",
      "2022-04-03 08:31:04,132 | Validation accuracy got better 0.801534308850689 --> 0.8032390964625657.  Saving model ...\n",
      "2022-04-03 08:31:04,195 | Validation loss got better 0.5154233564451889 --> 0.5114399335282417.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:32:46,440 | Epoch 22 Result\n",
      "2022-04-03 08:32:46,441 | \ttrain loss: 0.5892408006837261\tvalid_loss: 0.5041889644410905\n",
      "2022-04-03 08:32:46,441 | \tacc: 0.80331\tpc: 0.640696\trc: 0.570229\tf1: 0.586848\n",
      "2022-04-03 08:32:47,087 | Validation accuracy got better 0.8032390964625657 --> 0.8033101292797272.  Saving model ...\n",
      "2022-04-03 08:32:47,151 | Validation loss got better 0.5114399335282417 --> 0.5041889644410905.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:34:29,458 | Epoch 23 Result\n",
      "2022-04-03 08:34:29,458 | \ttrain loss: 0.5810262246866602\tvalid_loss: 0.5031850721402878\n",
      "2022-04-03 08:34:29,459 | \tacc: 0.805157\tpc: 0.64104\trc: 0.568162\tf1: 0.584197\n",
      "2022-04-03 08:34:30,105 | Validation accuracy got better 0.8033101292797272 --> 0.8051569825259269.  Saving model ...\n",
      "2022-04-03 08:34:30,170 | Validation loss got better 0.5041889644410905 --> 0.5031850721402878.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:36:12,362 | Epoch 24 Result\n",
      "2022-04-03 08:36:12,363 | \ttrain loss: 0.574028225255574\tvalid_loss: 0.49980617270650535\n",
      "2022-04-03 08:36:12,363 | \tacc: 0.80608\tpc: 0.637971\trc: 0.572274\tf1: 0.587221\n",
      "2022-04-03 08:36:12,997 | Validation accuracy got better 0.8051569825259269 --> 0.8060804091490269.  Saving model ...\n",
      "2022-04-03 08:36:13,063 | Validation loss got better 0.5031850721402878 --> 0.49980617270650535.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:37:55,273 | Epoch 25 Result\n",
      "2022-04-03 08:37:55,273 | \ttrain loss: 0.5699940306901585\tvalid_loss: 0.49670337248735935\n",
      "2022-04-03 08:37:55,274 | \tacc: 0.805654\tpc: 0.641244\trc: 0.570629\tf1: 0.586579\n",
      "2022-04-03 08:37:55,926 | Validation loss got better 0.49980617270650535 --> 0.49670337248735935.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:39:38,208 | Epoch 26 Result\n",
      "2022-04-03 08:39:38,208 | \ttrain loss: 0.5637656274643208\tvalid_loss: 0.4911864352744485\n",
      "2022-04-03 08:39:38,208 | \tacc: 0.808993\tpc: 0.639212\trc: 0.583977\tf1: 0.595128\n",
      "2022-04-03 08:39:38,856 | Validation accuracy got better 0.8060804091490269 --> 0.8089927546526495.  Saving model ...\n",
      "2022-04-03 08:39:38,922 | Validation loss got better 0.49670337248735935 --> 0.4911864352744485.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:41:21,225 | Epoch 27 Result\n",
      "2022-04-03 08:41:21,226 | \ttrain loss: 0.5587482796539005\tvalid_loss: 0.4892888468662299\n",
      "2022-04-03 08:41:21,226 | \tacc: 0.810271\tpc: 0.643929\trc: 0.58537\tf1: 0.597619\n",
      "2022-04-03 08:41:21,882 | Validation accuracy got better 0.8089927546526495 --> 0.8102713453615571.  Saving model ...\n",
      "2022-04-03 08:41:21,947 | Validation loss got better 0.4911864352744485 --> 0.4892888468662299.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:43:04,176 | Epoch 28 Result\n",
      "2022-04-03 08:43:04,177 | \ttrain loss: 0.5532140006771288\tvalid_loss: 0.48609033179970723\n",
      "2022-04-03 08:43:04,177 | \tacc: 0.809277\tpc: 0.642128\trc: 0.582798\tf1: 0.596181\n",
      "2022-04-03 08:43:04,830 | Validation loss got better 0.4892888468662299 --> 0.48609033179970723.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:44:47,066 | Epoch 29 Result\n",
      "2022-04-03 08:44:47,066 | \ttrain loss: 0.5489769498469499\tvalid_loss: 0.48269525074217023\n",
      "2022-04-03 08:44:47,067 | \tacc: 0.809206\tpc: 0.646043\trc: 0.584776\tf1: 0.598085\n",
      "2022-04-03 08:44:47,703 | Validation loss got better 0.48609033179970723 --> 0.48269525074217023.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:46:30,013 | Epoch 30 Result\n",
      "2022-04-03 08:46:30,014 | \ttrain loss: 0.5459044297677973\tvalid_loss: 0.4818011374953864\n",
      "2022-04-03 08:46:30,014 | \tacc: 0.810484\tpc: 0.644574\trc: 0.582827\tf1: 0.595825\n",
      "2022-04-03 08:46:30,675 | Validation accuracy got better 0.8102713453615571 --> 0.8104844438130416.  Saving model ...\n",
      "2022-04-03 08:46:30,739 | Validation loss got better 0.48269525074217023 --> 0.4818011374953864.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 08:48:12,969 | Epoch 31 Result\n",
      "2022-04-03 08:48:12,969 | \ttrain loss: 0.5418626227991692\tvalid_loss: 0.4800862959965943\n",
      "2022-04-03 08:48:12,969 | \tacc: 0.810555\tpc: 0.649531\trc: 0.583625\tf1: 0.599044\n",
      "2022-04-03 08:48:13,603 | Validation accuracy got better 0.8104844438130416 --> 0.8105554766302031.  Saving model ...\n",
      "2022-04-03 08:48:13,667 | Validation loss got better 0.4818011374953864 --> 0.4800862959965943.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 08:49:55,925 | Epoch 32 Result\n",
      "2022-04-03 08:49:55,926 | \ttrain loss: 0.5387441453598016\tvalid_loss: 0.4760619667819793\n",
      "2022-04-03 08:49:55,926 | \tacc: 0.812331\tpc: 0.650386\trc: 0.585595\tf1: 0.600114\n",
      "2022-04-03 08:49:56,563 | Validation accuracy got better 0.8105554766302031 --> 0.8123312970592413.  Saving model ...\n",
      "2022-04-03 08:49:56,628 | Validation loss got better 0.4800862959965943 --> 0.4760619667819793.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:51:38,886 | Epoch 33 Result\n",
      "2022-04-03 08:51:38,886 | \ttrain loss: 0.5334953171618652\tvalid_loss: 0.4763000069871716\n",
      "2022-04-03 08:51:38,887 | \tacc: 0.812402\tpc: 0.653722\trc: 0.599151\tf1: 0.609252\n",
      "2022-04-03 08:51:39,527 | Validation accuracy got better 0.8123312970592413 --> 0.8124023298764029.  Saving model ...\n",
      "2022-04-03 08:51:39,591 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:53:21,698 | Epoch 34 Result\n",
      "2022-04-03 08:53:21,698 | \ttrain loss: 0.531059689916543\tvalid_loss: 0.47374537425008006\n",
      "2022-04-03 08:53:21,698 | \tacc: 0.813042\tpc: 0.654206\trc: 0.596311\tf1: 0.607521\n",
      "2022-04-03 08:53:22,352 | Validation accuracy got better 0.8124023298764029 --> 0.8130416252308567.  Saving model ...\n",
      "2022-04-03 08:53:22,419 | Validation loss got better 0.4760619667819793 --> 0.47374537425008006.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.72it/s]\n",
      "2022-04-03 08:55:04,655 | Epoch 35 Result\n",
      "2022-04-03 08:55:04,656 | \ttrain loss: 0.527353167323255\tvalid_loss: 0.4699084533515819\n",
      "2022-04-03 08:55:04,656 | \tacc: 0.814675\tpc: 0.648534\trc: 0.598452\tf1: 0.608317\n",
      "2022-04-03 08:55:05,311 | Validation accuracy got better 0.8130416252308567 --> 0.8146753800255718.  Saving model ...\n",
      "2022-04-03 08:55:05,377 | Validation loss got better 0.47374537425008006 --> 0.4699084533515819.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:56:47,583 | Epoch 36 Result\n",
      "2022-04-03 08:56:47,583 | \ttrain loss: 0.521867762591142\tvalid_loss: 0.4694053915383921\n",
      "2022-04-03 08:56:47,584 | \tacc: 0.814746\tpc: 0.654214\trc: 0.59723\tf1: 0.60659\n",
      "2022-04-03 08:56:48,235 | Validation accuracy got better 0.8146753800255718 --> 0.8147464128427333.  Saving model ...\n",
      "2022-04-03 08:56:48,300 | Validation loss got better 0.4699084533515819 --> 0.4694053915383921.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 08:58:30,566 | Epoch 37 Result\n",
      "2022-04-03 08:58:30,566 | \ttrain loss: 0.5208741166883291\tvalid_loss: 0.4663529036176833\n",
      "2022-04-03 08:58:30,566 | \tacc: 0.813894\tpc: 0.651655\trc: 0.595745\tf1: 0.607943\n",
      "2022-04-03 08:58:31,248 | Validation loss got better 0.4694053915383921 --> 0.4663529036176833.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:00:13,406 | Epoch 38 Result\n",
      "2022-04-03 09:00:13,407 | \ttrain loss: 0.5176453429371208\tvalid_loss: 0.46538708287556246\n",
      "2022-04-03 09:00:13,407 | \tacc: 0.817019\tpc: 0.653916\trc: 0.60133\tf1: 0.611416\n",
      "2022-04-03 09:00:14,047 | Validation accuracy got better 0.8147464128427333 --> 0.8170194629919023.  Saving model ...\n",
      "2022-04-03 09:00:14,112 | Validation loss got better 0.4663529036176833 --> 0.46538708287556246.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:01:56,379 | Epoch 39 Result\n",
      "2022-04-03 09:01:56,380 | \ttrain loss: 0.5146172310157807\tvalid_loss: 0.4643419203492013\n",
      "2022-04-03 09:01:56,380 | \tacc: 0.815528\tpc: 0.659\trc: 0.595298\tf1: 0.609675\n",
      "2022-04-03 09:01:57,023 | Validation loss got better 0.46538708287556246 --> 0.4643419203492013.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:03:39,250 | Epoch 40 Result\n",
      "2022-04-03 09:03:39,250 | \ttrain loss: 0.5119971982926763\tvalid_loss: 0.46485016879108687\n",
      "2022-04-03 09:03:39,250 | \tacc: 0.814746\tpc: 0.649559\trc: 0.600302\tf1: 0.608924\n",
      "2022-04-03 09:03:39,892 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:05:22,019 | Epoch 41 Result\n",
      "2022-04-03 09:05:22,019 | \ttrain loss: 0.5081457516657135\tvalid_loss: 0.46354019978893535\n",
      "2022-04-03 09:05:22,019 | \tacc: 0.816096\tpc: 0.654381\trc: 0.601076\tf1: 0.612572\n",
      "2022-04-03 09:05:22,689 | Validation loss got better 0.4643419203492013 --> 0.46354019978893535.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:07:04,878 | Epoch 42 Result\n",
      "2022-04-03 09:07:04,878 | \ttrain loss: 0.5089641195096073\tvalid_loss: 0.45937924832846566\n",
      "2022-04-03 09:07:04,878 | \tacc: 0.816238\tpc: 0.652488\trc: 0.598564\tf1: 0.608996\n",
      "2022-04-03 09:07:05,573 | Validation loss got better 0.46354019978893535 --> 0.45937924832846566.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:08:47,815 | Epoch 43 Result\n",
      "2022-04-03 09:08:47,815 | \ttrain loss: 0.5032617141650356\tvalid_loss: 0.45829854859667657\n",
      "2022-04-03 09:08:47,816 | \tacc: 0.818227\tpc: 0.660083\trc: 0.611775\tf1: 0.620436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 09:08:48,459 | Validation accuracy got better 0.8170194629919023 --> 0.8182270208836483.  Saving model ...\n",
      "2022-04-03 09:08:48,524 | Validation loss got better 0.45937924832846566 --> 0.45829854859667657.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:10:30,762 | Epoch 44 Result\n",
      "2022-04-03 09:10:30,763 | \ttrain loss: 0.5037697544034522\tvalid_loss: 0.4570900541185774\n",
      "2022-04-03 09:10:30,763 | \tacc: 0.81844\tpc: 0.6556\trc: 0.606986\tf1: 0.615111\n",
      "2022-04-03 09:10:31,414 | Validation accuracy got better 0.8182270208836483 --> 0.8184401193351328.  Saving model ...\n",
      "2022-04-03 09:10:31,479 | Validation loss got better 0.45829854859667657 --> 0.4570900541185774.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:12:13,809 | Epoch 45 Result\n",
      "2022-04-03 09:12:13,809 | \ttrain loss: 0.49969253213581083\tvalid_loss: 0.45549921285599737\n",
      "2022-04-03 09:12:13,809 | \tacc: 0.817659\tpc: 0.659467\trc: 0.608188\tf1: 0.618405\n",
      "2022-04-03 09:12:14,448 | Validation loss got better 0.4570900541185774 --> 0.45549921285599737.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:13:56,662 | Epoch 46 Result\n",
      "2022-04-03 09:13:56,663 | \ttrain loss: 0.4974716822802471\tvalid_loss: 0.45474951024048027\n",
      "2022-04-03 09:13:56,663 | \tacc: 0.819221\tpc: 0.661351\trc: 0.612803\tf1: 0.621524\n",
      "2022-04-03 09:13:57,295 | Validation accuracy got better 0.8184401193351328 --> 0.8192214803239096.  Saving model ...\n",
      "2022-04-03 09:13:57,359 | Validation loss got better 0.45549921285599737 --> 0.45474951024048027.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:15:39,550 | Epoch 47 Result\n",
      "2022-04-03 09:15:39,551 | \ttrain loss: 0.4953484774251349\tvalid_loss: 0.453836560198522\n",
      "2022-04-03 09:15:39,551 | \tacc: 0.818582\tpc: 0.654369\trc: 0.606074\tf1: 0.614209\n",
      "2022-04-03 09:15:40,174 | Validation loss got better 0.45474951024048027 --> 0.453836560198522.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:17:22,414 | Epoch 48 Result\n",
      "2022-04-03 09:17:22,414 | \ttrain loss: 0.4927355218867827\tvalid_loss: 0.4513285201387423\n",
      "2022-04-03 09:17:22,414 | \tacc: 0.820429\tpc: 0.65998\trc: 0.610212\tf1: 0.621158\n",
      "2022-04-03 09:17:23,091 | Validation accuracy got better 0.8192214803239096 --> 0.8204290382156556.  Saving model ...\n",
      "2022-04-03 09:17:23,157 | Validation loss got better 0.453836560198522 --> 0.4513285201387423.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:19:05,383 | Epoch 49 Result\n",
      "2022-04-03 09:19:05,383 | \ttrain loss: 0.49142425986253324\tvalid_loss: 0.4517127636363347\n",
      "2022-04-03 09:19:05,383 | \tacc: 0.818724\tpc: 0.660682\trc: 0.6078\tf1: 0.619676\n",
      "2022-04-03 09:19:06,008 | patience 0 --> 1\n",
      "2022-04-03 09:19:06,010 | # train data: 132867\n",
      "2022-04-03 09:19:06,010 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:20:48,155 | Epoch 0 Result\n",
      "2022-04-03 09:20:48,156 | \ttrain loss: 5.17160580915423\tvalid_loss: 4.464710017059452\n",
      "2022-04-03 09:20:48,156 | \tacc: 0.111166\tpc: 0.013624\trc: 0.006535\tf1: 0.004043\n",
      "2022-04-03 09:20:48,751 | Validation accuracy got better None --> 0.1111663588577923.  Saving model ...\n",
      "2022-04-03 09:20:48,804 | Validation loss got better None --> 4.464710017059452.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:22:31,030 | Epoch 1 Result\n",
      "2022-04-03 09:22:31,030 | \ttrain loss: 3.9191272458710245\tvalid_loss: 3.090290480639586\n",
      "2022-04-03 09:22:31,031 | \tacc: 0.320642\tpc: 0.038254\trc: 0.044826\tf1: 0.032675\n",
      "2022-04-03 09:22:31,649 | Validation accuracy got better 0.1111663588577923 --> 0.3206421366671402.  Saving model ...\n",
      "2022-04-03 09:22:31,711 | Validation loss got better 4.464710017059452 --> 3.090290480639586.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:24:13,910 | Epoch 2 Result\n",
      "2022-04-03 09:24:13,911 | \ttrain loss: 2.9070204720407444\tvalid_loss: 2.0978538443680126\n",
      "2022-04-03 09:24:13,911 | \tacc: 0.498437\tpc: 0.129806\trc: 0.098285\tf1: 0.091342\n",
      "2022-04-03 09:24:14,538 | Validation accuracy got better 0.3206421366671402 --> 0.49843727802244636.  Saving model ...\n",
      "2022-04-03 09:24:14,598 | Validation loss got better 3.090290480639586 --> 2.0978538443680126.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:25:56,828 | Epoch 3 Result\n",
      "2022-04-03 09:25:56,829 | \ttrain loss: 2.093000203704136\tvalid_loss: 1.4412586335042505\n",
      "2022-04-03 09:25:56,829 | \tacc: 0.62175\tpc: 0.228729\trc: 0.181505\tf1: 0.176728\n",
      "2022-04-03 09:25:57,454 | Validation accuracy got better 0.49843727802244636 --> 0.6217502486148601.  Saving model ...\n",
      "2022-04-03 09:25:57,514 | Validation loss got better 2.0978538443680126 --> 1.4412586335042505.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:27:39,763 | Epoch 4 Result\n",
      "2022-04-03 09:27:39,763 | \ttrain loss: 1.561264857033758\tvalid_loss: 1.0950477617439653\n",
      "2022-04-03 09:27:39,764 | \tacc: 0.688947\tpc: 0.318869\trc: 0.259866\tf1: 0.262343\n",
      "2022-04-03 09:27:40,392 | Validation accuracy got better 0.6217502486148601 --> 0.6889472936496661.  Saving model ...\n",
      "2022-04-03 09:27:40,452 | Validation loss got better 1.4412586335042505 --> 1.0950477617439653.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:29:23,553 | Epoch 5 Result\n",
      "2022-04-03 09:29:23,553 | \ttrain loss: 1.2607751543733783\tvalid_loss: 0.9139651340726324\n",
      "2022-04-03 09:29:23,553 | \tacc: 0.718142\tpc: 0.416109\trc: 0.329127\tf1: 0.342195\n",
      "2022-04-03 09:29:24,173 | Validation accuracy got better 0.6889472936496661 --> 0.7181417815030544.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 09:29:24,235 | Validation loss got better 1.0950477617439653 --> 0.9139651340726324.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:31:06,555 | Epoch 6 Result\n",
      "2022-04-03 09:31:06,555 | \ttrain loss: 1.0817231383763086\tvalid_loss: 0.8033552817076272\n",
      "2022-04-03 09:31:06,555 | \tacc: 0.738244\tpc: 0.494819\trc: 0.386474\tf1: 0.407657\n",
      "2022-04-03 09:31:07,169 | Validation accuracy got better 0.7181417815030544 --> 0.738244068759767.  Saving model ...\n",
      "2022-04-03 09:31:07,230 | Validation loss got better 0.9139651340726324 --> 0.8033552817076272.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:32:49,475 | Epoch 7 Result\n",
      "2022-04-03 09:32:49,475 | \ttrain loss: 0.9643530763372634\tvalid_loss: 0.7328131826175582\n",
      "2022-04-03 09:32:49,476 | \tacc: 0.751598\tpc: 0.539867\trc: 0.415728\tf1: 0.439101\n",
      "2022-04-03 09:32:50,097 | Validation accuracy got better 0.738244068759767 --> 0.7515982383861344.  Saving model ...\n",
      "2022-04-03 09:32:50,159 | Validation loss got better 0.8033552817076272 --> 0.7328131826175582.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:34:32,328 | Epoch 8 Result\n",
      "2022-04-03 09:34:32,328 | \ttrain loss: 0.8850231567009237\tvalid_loss: 0.6803971092578006\n",
      "2022-04-03 09:34:32,329 | \tacc: 0.76275\tpc: 0.558596\trc: 0.453334\tf1: 0.473572\n",
      "2022-04-03 09:34:32,954 | Validation accuracy got better 0.7515982383861344 --> 0.7627503906804944.  Saving model ...\n",
      "2022-04-03 09:34:33,017 | Validation loss got better 0.7328131826175582 --> 0.6803971092578006.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:36:15,247 | Epoch 9 Result\n",
      "2022-04-03 09:36:15,247 | \ttrain loss: 0.8252525195156735\tvalid_loss: 0.6442767943589419\n",
      "2022-04-03 09:36:15,248 | \tacc: 0.768149\tpc: 0.571811\trc: 0.472452\tf1: 0.492433\n",
      "2022-04-03 09:36:15,871 | Validation accuracy got better 0.7627503906804944 --> 0.7681488847847706.  Saving model ...\n",
      "2022-04-03 09:36:15,933 | Validation loss got better 0.6803971092578006 --> 0.6442767943589419.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 09:37:58,267 | Epoch 10 Result\n",
      "2022-04-03 09:37:58,267 | \ttrain loss: 0.7815081353530007\tvalid_loss: 0.6161183073263579\n",
      "2022-04-03 09:37:58,267 | \tacc: 0.777667\tpc: 0.589006\trc: 0.500799\tf1: 0.519977\n",
      "2022-04-03 09:37:58,888 | Validation accuracy got better 0.7681488847847706 --> 0.7776672822844154.  Saving model ...\n",
      "2022-04-03 09:37:58,950 | Validation loss got better 0.6442767943589419 --> 0.6161183073263579.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:39:41,248 | Epoch 11 Result\n",
      "2022-04-03 09:39:41,249 | \ttrain loss: 0.7464470261594083\tvalid_loss: 0.5939415383023927\n",
      "2022-04-03 09:39:41,249 | \tacc: 0.781929\tpc: 0.617093\trc: 0.51407\tf1: 0.535132\n",
      "2022-04-03 09:39:41,882 | Validation accuracy got better 0.7776672822844154 --> 0.7819292513141071.  Saving model ...\n",
      "2022-04-03 09:39:41,945 | Validation loss got better 0.6161183073263579 --> 0.5939415383023927.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:41:24,211 | Epoch 12 Result\n",
      "2022-04-03 09:41:24,212 | \ttrain loss: 0.717417320916633\tvalid_loss: 0.5783659644146537\n",
      "2022-04-03 09:41:24,212 | \tacc: 0.783421\tpc: 0.602241\trc: 0.52121\tf1: 0.534918\n",
      "2022-04-03 09:41:24,835 | Validation accuracy got better 0.7819292513141071 --> 0.7834209404744992.  Saving model ...\n",
      "2022-04-03 09:41:24,897 | Validation loss got better 0.5939415383023927 --> 0.5783659644146537.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:43:07,223 | Epoch 13 Result\n",
      "2022-04-03 09:43:07,223 | \ttrain loss: 0.6962533320377322\tvalid_loss: 0.5605287396919661\n",
      "2022-04-03 09:43:07,224 | \tacc: 0.78889\tpc: 0.611529\trc: 0.524368\tf1: 0.540101\n",
      "2022-04-03 09:43:07,854 | Validation accuracy got better 0.7834209404744992 --> 0.7888904673959369.  Saving model ...\n",
      "2022-04-03 09:43:07,918 | Validation loss got better 0.5783659644146537 --> 0.5605287396919661.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:44:50,174 | Epoch 14 Result\n",
      "2022-04-03 09:44:50,174 | \ttrain loss: 0.6743273314695628\tvalid_loss: 0.5521262819446239\n",
      "2022-04-03 09:44:50,175 | \tacc: 0.791235\tpc: 0.640869\trc: 0.544475\tf1: 0.5643\n",
      "2022-04-03 09:44:50,817 | Validation accuracy got better 0.7888904673959369 --> 0.7912345503622674.  Saving model ...\n",
      "2022-04-03 09:44:50,880 | Validation loss got better 0.5605287396919661 --> 0.5521262819446239.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:46:33,080 | Epoch 15 Result\n",
      "2022-04-03 09:46:33,080 | \ttrain loss: 0.6584085312280615\tvalid_loss: 0.5414963093547764\n",
      "2022-04-03 09:46:33,081 | \tacc: 0.792726\tpc: 0.614131\trc: 0.541145\tf1: 0.555308\n",
      "2022-04-03 09:46:33,705 | Validation accuracy got better 0.7912345503622674 --> 0.7927262395226594.  Saving model ...\n",
      "2022-04-03 09:46:33,767 | Validation loss got better 0.5521262819446239 --> 0.5414963093547764.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:48:16,066 | Epoch 16 Result\n",
      "2022-04-03 09:48:16,066 | \ttrain loss: 0.6445718734201049\tvalid_loss: 0.5327420587278188\n",
      "2022-04-03 09:48:16,066 | \tacc: 0.797272\tpc: 0.635193\trc: 0.559844\tf1: 0.56978\n",
      "2022-04-03 09:48:16,700 | Validation accuracy got better 0.7927262395226594 --> 0.7972723398209973.  Saving model ...\n",
      "2022-04-03 09:48:16,763 | Validation loss got better 0.5414963093547764 --> 0.5327420587278188.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:49:59,059 | Epoch 17 Result\n",
      "2022-04-03 09:49:59,060 | \ttrain loss: 0.6349710580671314\tvalid_loss: 0.522681673610561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 09:49:59,060 | \tacc: 0.799545\tpc: 0.620667\trc: 0.562834\tf1: 0.571995\n",
      "2022-04-03 09:49:59,695 | Validation accuracy got better 0.7972723398209973 --> 0.7995453899701662.  Saving model ...\n",
      "2022-04-03 09:49:59,758 | Validation loss got better 0.5327420587278188 --> 0.522681673610561.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:51:41,994 | Epoch 18 Result\n",
      "2022-04-03 09:51:41,995 | \ttrain loss: 0.6209189082919679\tvalid_loss: 0.514467104420538\n",
      "2022-04-03 09:51:41,995 | \tacc: 0.802458\tpc: 0.645822\trc: 0.5716\tf1: 0.587627\n",
      "2022-04-03 09:51:42,622 | Validation accuracy got better 0.7995453899701662 --> 0.8024577354737888.  Saving model ...\n",
      "2022-04-03 09:51:42,685 | Validation loss got better 0.522681673610561 --> 0.514467104420538.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.71it/s]\n",
      "2022-04-03 09:53:24,969 | Epoch 19 Result\n",
      "2022-04-03 09:53:24,970 | \ttrain loss: 0.6102437533114818\tvalid_loss: 0.5097979461796194\n",
      "2022-04-03 09:53:24,970 | \tacc: 0.802955\tpc: 0.62403\trc: 0.567642\tf1: 0.577703\n",
      "2022-04-03 09:53:25,601 | Validation accuracy got better 0.8024577354737888 --> 0.8029549651939196.  Saving model ...\n",
      "2022-04-03 09:53:25,663 | Validation loss got better 0.514467104420538 --> 0.5097979461796194.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:55:07,975 | Epoch 20 Result\n",
      "2022-04-03 09:55:07,976 | \ttrain loss: 0.6028485805913467\tvalid_loss: 0.5047113540447271\n",
      "2022-04-03 09:55:07,976 | \tacc: 0.805654\tpc: 0.639612\trc: 0.57539\tf1: 0.588001\n",
      "2022-04-03 09:55:08,604 | Validation accuracy got better 0.8029549651939196 --> 0.8056542122460577.  Saving model ...\n",
      "2022-04-03 09:55:08,666 | Validation loss got better 0.5097979461796194 --> 0.5047113540447271.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:56:51,018 | Epoch 21 Result\n",
      "2022-04-03 09:56:51,019 | \ttrain loss: 0.5948669344656247\tvalid_loss: 0.4991115989087573\n",
      "2022-04-03 09:56:51,019 | \tacc: 0.807359\tpc: 0.638696\trc: 0.577468\tf1: 0.588399\n",
      "2022-04-03 09:56:51,635 | Validation accuracy got better 0.8056542122460577 --> 0.8073589998579344.  Saving model ...\n",
      "2022-04-03 09:56:51,697 | Validation loss got better 0.5047113540447271 --> 0.4991115989087573.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 09:58:33,958 | Epoch 22 Result\n",
      "2022-04-03 09:58:33,959 | \ttrain loss: 0.5874520420309922\tvalid_loss: 0.4965427961178777\n",
      "2022-04-03 09:58:33,959 | \tacc: 0.80608\tpc: 0.626723\trc: 0.578029\tf1: 0.585743\n",
      "2022-04-03 09:58:34,582 | Validation loss got better 0.4991115989087573 --> 0.4965427961178777.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:00:16,917 | Epoch 23 Result\n",
      "2022-04-03 10:00:16,918 | \ttrain loss: 0.5794934740476875\tvalid_loss: 0.4907267273683273\n",
      "2022-04-03 10:00:16,918 | \tacc: 0.809916\tpc: 0.640939\trc: 0.593536\tf1: 0.597282\n",
      "2022-04-03 10:00:17,544 | Validation accuracy got better 0.8073589998579344 --> 0.8099161812757494.  Saving model ...\n",
      "2022-04-03 10:00:17,608 | Validation loss got better 0.4965427961178777 --> 0.4907267273683273.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:01:59,911 | Epoch 24 Result\n",
      "2022-04-03 10:01:59,911 | \ttrain loss: 0.5746534018036462\tvalid_loss: 0.4876571700796178\n",
      "2022-04-03 10:01:59,912 | \tacc: 0.810271\tpc: 0.638018\trc: 0.591782\tf1: 0.599774\n",
      "2022-04-03 10:02:00,556 | Validation accuracy got better 0.8099161812757494 --> 0.8102713453615571.  Saving model ...\n",
      "2022-04-03 10:02:00,619 | Validation loss got better 0.4907267273683273 --> 0.4876571700796178.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:03:42,976 | Epoch 25 Result\n",
      "2022-04-03 10:03:42,976 | \ttrain loss: 0.567988955412568\tvalid_loss: 0.4816843926152954\n",
      "2022-04-03 10:03:42,976 | \tacc: 0.810627\tpc: 0.63682\trc: 0.587063\tf1: 0.597049\n",
      "2022-04-03 10:03:43,610 | Validation accuracy got better 0.8102713453615571 --> 0.8106265094473647.  Saving model ...\n",
      "2022-04-03 10:03:43,671 | Validation loss got better 0.4876571700796178 --> 0.4816843926152954.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:05:26,032 | Epoch 26 Result\n",
      "2022-04-03 10:05:26,032 | \ttrain loss: 0.5599914804425443\tvalid_loss: 0.4799219669308712\n",
      "2022-04-03 10:05:26,033 | \tacc: 0.810342\tpc: 0.637259\trc: 0.588955\tf1: 0.596029\n",
      "2022-04-03 10:05:26,667 | Validation loss got better 0.4816843926152954 --> 0.4799219669308712.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:07:09,079 | Epoch 27 Result\n",
      "2022-04-03 10:07:09,079 | \ttrain loss: 0.5569374461064803\tvalid_loss: 0.47701503258737793\n",
      "2022-04-03 10:07:09,079 | \tacc: 0.81226\tpc: 0.644496\trc: 0.593393\tf1: 0.601199\n",
      "2022-04-03 10:07:09,705 | Validation accuracy got better 0.8106265094473647 --> 0.8122602642420799.  Saving model ...\n",
      "2022-04-03 10:07:09,767 | Validation loss got better 0.4799219669308712 --> 0.47701503258737793.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:08:52,073 | Epoch 28 Result\n",
      "2022-04-03 10:08:52,074 | \ttrain loss: 0.5513628128243484\tvalid_loss: 0.47411807812247564\n",
      "2022-04-03 10:08:52,074 | \tacc: 0.814462\tpc: 0.649187\trc: 0.590633\tf1: 0.60145\n",
      "2022-04-03 10:08:52,708 | Validation accuracy got better 0.8122602642420799 --> 0.8144622815740872.  Saving model ...\n",
      "2022-04-03 10:08:52,772 | Validation loss got better 0.47701503258737793 --> 0.47411807812247564.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:10:35,101 | Epoch 29 Result\n",
      "2022-04-03 10:10:35,102 | \ttrain loss: 0.546903164818378\tvalid_loss: 0.4712714028470234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:10:35,102 | \tacc: 0.815386\tpc: 0.647347\trc: 0.596848\tf1: 0.603867\n",
      "2022-04-03 10:10:35,746 | Validation accuracy got better 0.8144622815740872 --> 0.8153857081971871.  Saving model ...\n",
      "2022-04-03 10:10:35,810 | Validation loss got better 0.47411807812247564 --> 0.4712714028470234.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:12:18,201 | Epoch 30 Result\n",
      "2022-04-03 10:12:18,201 | \ttrain loss: 0.543429673192671\tvalid_loss: 0.47050741310230726\n",
      "2022-04-03 10:12:18,201 | \tacc: 0.815173\tpc: 0.64842\trc: 0.602049\tf1: 0.609434\n",
      "2022-04-03 10:12:18,834 | Validation loss got better 0.4712714028470234 --> 0.47050741310230726.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:14:01,178 | Epoch 31 Result\n",
      "2022-04-03 10:14:01,179 | \ttrain loss: 0.5403711787424722\tvalid_loss: 0.4677510475600912\n",
      "2022-04-03 10:14:01,179 | \tacc: 0.816451\tpc: 0.654783\trc: 0.598985\tf1: 0.607008\n",
      "2022-04-03 10:14:01,815 | Validation accuracy got better 0.8153857081971871 --> 0.8164512004546101.  Saving model ...\n",
      "2022-04-03 10:14:01,878 | Validation loss got better 0.47050741310230726 --> 0.4677510475600912.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:15:44,191 | Epoch 32 Result\n",
      "2022-04-03 10:15:44,191 | \ttrain loss: 0.5368771202662017\tvalid_loss: 0.4660232891530404\n",
      "2022-04-03 10:15:44,192 | \tacc: 0.815883\tpc: 0.647709\trc: 0.608001\tf1: 0.611448\n",
      "2022-04-03 10:15:44,822 | Validation loss got better 0.4677510475600912 --> 0.4660232891530404.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:17:27,138 | Epoch 33 Result\n",
      "2022-04-03 10:17:27,139 | \ttrain loss: 0.5314017802610791\tvalid_loss: 0.46412049877252376\n",
      "2022-04-03 10:17:27,139 | \tacc: 0.817659\tpc: 0.647744\trc: 0.609859\tf1: 0.615273\n",
      "2022-04-03 10:17:27,780 | Validation accuracy got better 0.8164512004546101 --> 0.817658758346356.  Saving model ...\n",
      "2022-04-03 10:17:27,843 | Validation loss got better 0.4660232891530404 --> 0.46412049877252376.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:19:10,222 | Epoch 34 Result\n",
      "2022-04-03 10:19:10,222 | \ttrain loss: 0.5300903018962879\tvalid_loss: 0.4633849210606361\n",
      "2022-04-03 10:19:10,223 | \tacc: 0.816593\tpc: 0.650689\trc: 0.60574\tf1: 0.612887\n",
      "2022-04-03 10:19:10,861 | Validation loss got better 0.46412049877252376 --> 0.4633849210606361.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:20:53,225 | Epoch 35 Result\n",
      "2022-04-03 10:20:53,225 | \ttrain loss: 0.5265594624170815\tvalid_loss: 0.4579810221131882\n",
      "2022-04-03 10:20:53,226 | \tacc: 0.819221\tpc: 0.648908\trc: 0.600526\tf1: 0.608924\n",
      "2022-04-03 10:20:53,855 | Validation accuracy got better 0.817658758346356 --> 0.8192214803239096.  Saving model ...\n",
      "2022-04-03 10:20:53,917 | Validation loss got better 0.4633849210606361 --> 0.4579810221131882.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:22:36,255 | Epoch 36 Result\n",
      "2022-04-03 10:22:36,255 | \ttrain loss: 0.5221034057474093\tvalid_loss: 0.4594704410639959\n",
      "2022-04-03 10:22:36,256 | \tacc: 0.819506\tpc: 0.653177\trc: 0.608156\tf1: 0.614286\n",
      "2022-04-03 10:22:36,887 | Validation accuracy got better 0.8192214803239096 --> 0.8195056115925557.  Saving model ...\n",
      "2022-04-03 10:22:36,985 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 10:24:19,326 | Epoch 37 Result\n",
      "2022-04-03 10:24:19,326 | \ttrain loss: 0.5185842767622615\tvalid_loss: 0.4562879177907225\n",
      "2022-04-03 10:24:19,327 | \tacc: 0.81915\tpc: 0.651537\trc: 0.605487\tf1: 0.615395\n",
      "2022-04-03 10:24:19,963 | Validation loss got better 0.4579810221131882 --> 0.4562879177907225.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:26:02,423 | Epoch 38 Result\n",
      "2022-04-03 10:26:02,424 | \ttrain loss: 0.5163281107240086\tvalid_loss: 0.4551436927850688\n",
      "2022-04-03 10:26:02,424 | \tacc: 0.821139\tpc: 0.660672\trc: 0.616703\tf1: 0.621118\n",
      "2022-04-03 10:26:03,067 | Validation accuracy got better 0.8195056115925557 --> 0.8211393663872709.  Saving model ...\n",
      "2022-04-03 10:26:03,131 | Validation loss got better 0.4562879177907225 --> 0.4551436927850688.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:27:45,523 | Epoch 39 Result\n",
      "2022-04-03 10:27:45,524 | \ttrain loss: 0.5138365297943684\tvalid_loss: 0.4530260497694887\n",
      "2022-04-03 10:27:45,524 | \tacc: 0.820216\tpc: 0.649811\trc: 0.602845\tf1: 0.611698\n",
      "2022-04-03 10:27:46,205 | Validation loss got better 0.4551436927850688 --> 0.4530260497694887.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:29:28,581 | Epoch 40 Result\n",
      "2022-04-03 10:29:28,581 | \ttrain loss: 0.5107370940799537\tvalid_loss: 0.45039654589288697\n",
      "2022-04-03 10:29:28,582 | \tacc: 0.821566\tpc: 0.65977\trc: 0.60965\tf1: 0.619628\n",
      "2022-04-03 10:29:29,235 | Validation accuracy got better 0.8211393663872709 --> 0.8215655632902401.  Saving model ...\n",
      "2022-04-03 10:29:29,299 | Validation loss got better 0.4530260497694887 --> 0.45039654589288697.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:31:11,693 | Epoch 41 Result\n",
      "2022-04-03 10:31:11,693 | \ttrain loss: 0.509997484473676\tvalid_loss: 0.4521974416970699\n",
      "2022-04-03 10:31:11,693 | \tacc: 0.820997\tpc: 0.650919\trc: 0.611942\tf1: 0.618356\n",
      "2022-04-03 10:31:12,322 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:32:54,670 | Epoch 42 Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:32:54,670 | \ttrain loss: 0.5067180637296147\tvalid_loss: 0.4482389131481801\n",
      "2022-04-03 10:32:54,671 | \tacc: 0.82256\tpc: 0.650048\trc: 0.610804\tf1: 0.617583\n",
      "2022-04-03 10:32:55,291 | Validation accuracy got better 0.8215655632902401 --> 0.8225600227305014.  Saving model ...\n",
      "2022-04-03 10:32:55,353 | Validation loss got better 0.45039654589288697 --> 0.4482389131481801.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:34:38,799 | Epoch 43 Result\n",
      "2022-04-03 10:34:38,799 | \ttrain loss: 0.5036746408595965\tvalid_loss: 0.4465943123065099\n",
      "2022-04-03 10:34:38,799 | \tacc: 0.821566\tpc: 0.650619\trc: 0.607032\tf1: 0.615684\n",
      "2022-04-03 10:34:39,433 | Validation loss got better 0.4482389131481801 --> 0.4465943123065099.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:36:21,823 | Epoch 44 Result\n",
      "2022-04-03 10:36:21,823 | \ttrain loss: 0.5018424111422961\tvalid_loss: 0.44588239942529795\n",
      "2022-04-03 10:36:21,824 | \tacc: 0.823697\tpc: 0.655892\trc: 0.61402\tf1: 0.620739\n",
      "2022-04-03 10:36:22,461 | Validation accuracy got better 0.8225600227305014 --> 0.8236965478050859.  Saving model ...\n",
      "2022-04-03 10:36:22,523 | Validation loss got better 0.4465943123065099 --> 0.44588239942529795.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:38:04,774 | Epoch 45 Result\n",
      "2022-04-03 10:38:04,775 | \ttrain loss: 0.4984395861048318\tvalid_loss: 0.445216061886374\n",
      "2022-04-03 10:38:04,775 | \tacc: 0.823483\tpc: 0.652705\trc: 0.619281\tf1: 0.622742\n",
      "2022-04-03 10:38:05,405 | Validation loss got better 0.44588239942529795 --> 0.445216061886374.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:39:47,775 | Epoch 46 Result\n",
      "2022-04-03 10:39:47,775 | \ttrain loss: 0.4994491881150205\tvalid_loss: 0.4429269845825414\n",
      "2022-04-03 10:39:47,776 | \tacc: 0.824194\tpc: 0.656267\trc: 0.611712\tf1: 0.618904\n",
      "2022-04-03 10:39:48,406 | Validation accuracy got better 0.8236965478050859 --> 0.8241937775252166.  Saving model ...\n",
      "2022-04-03 10:39:48,469 | Validation loss got better 0.445216061886374 --> 0.4429269845825414.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 10:41:30,863 | Epoch 47 Result\n",
      "2022-04-03 10:41:30,863 | \ttrain loss: 0.4942869209877703\tvalid_loss: 0.4427788217461639\n",
      "2022-04-03 10:41:30,863 | \tacc: 0.824336\tpc: 0.66404\trc: 0.618241\tf1: 0.626143\n",
      "2022-04-03 10:41:31,495 | Validation accuracy got better 0.8241937775252166 --> 0.8243358431595397.  Saving model ...\n",
      "2022-04-03 10:41:31,558 | Validation loss got better 0.4429269845825414 --> 0.4427788217461639.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:43:13,907 | Epoch 48 Result\n",
      "2022-04-03 10:43:13,907 | \ttrain loss: 0.4932775860590294\tvalid_loss: 0.44285263659890056\n",
      "2022-04-03 10:43:13,907 | \tacc: 0.823341\tpc: 0.65122\trc: 0.608376\tf1: 0.616304\n",
      "2022-04-03 10:43:14,533 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:44:56,833 | Epoch 49 Result\n",
      "2022-04-03 10:44:56,834 | \ttrain loss: 0.4893675408823107\tvalid_loss: 0.4412213313273026\n",
      "2022-04-03 10:44:56,834 | \tacc: 0.825828\tpc: 0.658932\trc: 0.614159\tf1: 0.622405\n",
      "2022-04-03 10:44:57,470 | Validation accuracy got better 0.8243358431595397 --> 0.8258275323199318.  Saving model ...\n",
      "2022-04-03 10:44:57,534 | Validation loss got better 0.4427788217461639 --> 0.4412213313273026.  Saving model ...\n",
      "2022-04-03 10:44:57,599 | # train data: 132867\n",
      "2022-04-03 10:44:57,599 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:46:39,921 | Epoch 0 Result\n",
      "2022-04-03 10:46:39,922 | \ttrain loss: 5.117239880651729\tvalid_loss: 4.405901860235631\n",
      "2022-04-03 10:46:39,922 | \tacc: 0.102358\tpc: 0.003579\trc: 0.00512\tf1: 0.001871\n",
      "2022-04-03 10:46:40,524 | Validation accuracy got better None --> 0.10235828952976275.  Saving model ...\n",
      "2022-04-03 10:46:40,578 | Validation loss got better None --> 4.405901860235631.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:48:23,038 | Epoch 1 Result\n",
      "2022-04-03 10:48:23,039 | \ttrain loss: 3.906843081004189\tvalid_loss: 3.099597694488018\n",
      "2022-04-03 10:48:23,039 | \tacc: 0.303736\tpc: 0.038763\trc: 0.040764\tf1: 0.028744\n",
      "2022-04-03 10:48:23,677 | Validation accuracy got better 0.10235828952976275 --> 0.3037363261826964.  Saving model ...\n",
      "2022-04-03 10:48:23,739 | Validation loss got better 4.405901860235631 --> 3.099597694488018.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 10:50:06,117 | Epoch 2 Result\n",
      "2022-04-03 10:50:06,118 | \ttrain loss: 2.915786012205397\tvalid_loss: 2.103029952568838\n",
      "2022-04-03 10:50:06,118 | \tacc: 0.505327\tpc: 0.134615\trc: 0.10214\tf1: 0.094381\n",
      "2022-04-03 10:50:06,748 | Validation accuracy got better 0.3037363261826964 --> 0.5053274612871147.  Saving model ...\n",
      "2022-04-03 10:50:06,811 | Validation loss got better 3.099597694488018 --> 2.103029952568838.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 10:51:49,285 | Epoch 3 Result\n",
      "2022-04-03 10:51:49,285 | \ttrain loss: 2.0999192816737766\tvalid_loss: 1.440423365800383\n",
      "2022-04-03 10:51:49,286 | \tacc: 0.624805\tpc: 0.226271\trc: 0.182675\tf1: 0.177734\n",
      "2022-04-03 10:51:49,906 | Validation accuracy got better 0.5053274612871147 --> 0.6248046597528057.  Saving model ...\n",
      "2022-04-03 10:51:49,969 | Validation loss got better 2.103029952568838 --> 1.440423365800383.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 10:53:32,355 | Epoch 4 Result\n",
      "2022-04-03 10:53:32,355 | \ttrain loss: 1.5679539164502219\tvalid_loss: 1.098903138083073\n",
      "2022-04-03 10:53:32,355 | \tacc: 0.685609\tpc: 0.320035\trc: 0.253411\tf1: 0.256764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:53:32,996 | Validation accuracy got better 0.6248046597528057 --> 0.6856087512430743.  Saving model ...\n",
      "2022-04-03 10:53:33,058 | Validation loss got better 1.440423365800383 --> 1.098903138083073.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:55:15,378 | Epoch 5 Result\n",
      "2022-04-03 10:55:15,378 | \ttrain loss: 1.2668443406398098\tvalid_loss: 0.9159995199079658\n",
      "2022-04-03 10:55:15,378 | \tacc: 0.714732\tpc: 0.410468\trc: 0.320295\tf1: 0.333545\n",
      "2022-04-03 10:55:15,996 | Validation accuracy got better 0.6856087512430743 --> 0.714732206279301.  Saving model ...\n",
      "2022-04-03 10:55:16,059 | Validation loss got better 1.098903138083073 --> 0.9159995199079658.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:56:58,473 | Epoch 6 Result\n",
      "2022-04-03 10:56:58,474 | \ttrain loss: 1.0832934471164595\tvalid_loss: 0.8029582407650986\n",
      "2022-04-03 10:56:58,474 | \tacc: 0.734977\tpc: 0.481513\trc: 0.365188\tf1: 0.381856\n",
      "2022-04-03 10:56:59,096 | Validation accuracy got better 0.714732206279301 --> 0.7349765591703367.  Saving model ...\n",
      "2022-04-03 10:56:59,158 | Validation loss got better 0.9159995199079658 --> 0.8029582407650986.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 10:58:41,555 | Epoch 7 Result\n",
      "2022-04-03 10:58:41,555 | \ttrain loss: 0.9662738338322441\tvalid_loss: 0.7310597853559647\n",
      "2022-04-03 10:58:41,555 | \tacc: 0.749254\tpc: 0.539834\trc: 0.416546\tf1: 0.442584\n",
      "2022-04-03 10:58:42,183 | Validation accuracy got better 0.7349765591703367 --> 0.749254155419804.  Saving model ...\n",
      "2022-04-03 10:58:42,244 | Validation loss got better 0.8029582407650986 --> 0.7310597853559647.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:00:24,601 | Epoch 8 Result\n",
      "2022-04-03 11:00:24,601 | \ttrain loss: 0.8869453317871402\tvalid_loss: 0.6800299122482898\n",
      "2022-04-03 11:00:24,602 | \tacc: 0.760548\tpc: 0.573471\trc: 0.453525\tf1: 0.478682\n",
      "2022-04-03 11:00:25,228 | Validation accuracy got better 0.749254155419804 --> 0.760548373348487.  Saving model ...\n",
      "2022-04-03 11:00:25,291 | Validation loss got better 0.7310597853559647 --> 0.6800299122482898.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:02:07,680 | Epoch 9 Result\n",
      "2022-04-03 11:02:07,681 | \ttrain loss: 0.8237288133197813\tvalid_loss: 0.6432017118420379\n",
      "2022-04-03 11:02:07,681 | \tacc: 0.770138\tpc: 0.585119\trc: 0.480613\tf1: 0.502391\n",
      "2022-04-03 11:02:08,306 | Validation accuracy got better 0.760548373348487 --> 0.7701378036652934.  Saving model ...\n",
      "2022-04-03 11:02:08,372 | Validation loss got better 0.6800299122482898 --> 0.6432017118420379.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:03:50,837 | Epoch 10 Result\n",
      "2022-04-03 11:03:50,838 | \ttrain loss: 0.7802778319921425\tvalid_loss: 0.6154613232372125\n",
      "2022-04-03 11:03:50,838 | \tacc: 0.777951\tpc: 0.602656\trc: 0.507661\tf1: 0.528999\n",
      "2022-04-03 11:03:51,461 | Validation accuracy got better 0.7701378036652934 --> 0.7779514135530615.  Saving model ...\n",
      "2022-04-03 11:03:51,530 | Validation loss got better 0.6432017118420379 --> 0.6154613232372125.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:05:34,010 | Epoch 11 Result\n",
      "2022-04-03 11:05:34,011 | \ttrain loss: 0.745487311070813\tvalid_loss: 0.5939921004339652\n",
      "2022-04-03 11:05:34,011 | \tacc: 0.780722\tpc: 0.609229\trc: 0.512847\tf1: 0.53416\n",
      "2022-04-03 11:05:34,634 | Validation accuracy got better 0.7779514135530615 --> 0.7807216934223611.  Saving model ...\n",
      "2022-04-03 11:05:34,699 | Validation loss got better 0.6154613232372125 --> 0.5939921004339652.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:07:17,066 | Epoch 12 Result\n",
      "2022-04-03 11:07:17,067 | \ttrain loss: 0.7172986612775764\tvalid_loss: 0.5754356182236312\n",
      "2022-04-03 11:07:17,067 | \tacc: 0.785339\tpc: 0.617131\trc: 0.52979\tf1: 0.549471\n",
      "2022-04-03 11:07:17,689 | Validation accuracy got better 0.7807216934223611 --> 0.7853388265378605.  Saving model ...\n",
      "2022-04-03 11:07:17,752 | Validation loss got better 0.5939921004339652 --> 0.5754356182236312.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 11:09:00,100 | Epoch 13 Result\n",
      "2022-04-03 11:09:00,100 | \ttrain loss: 0.692379599880212\tvalid_loss: 0.5618433687967711\n",
      "2022-04-03 11:09:00,100 | \tacc: 0.78818\tpc: 0.630934\trc: 0.5352\tf1: 0.556481\n",
      "2022-04-03 11:09:00,724 | Validation accuracy got better 0.7853388265378605 --> 0.7881801392243216.  Saving model ...\n",
      "2022-04-03 11:09:00,787 | Validation loss got better 0.5754356182236312 --> 0.5618433687967711.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:10:43,148 | Epoch 14 Result\n",
      "2022-04-03 11:10:43,149 | \ttrain loss: 0.6753850686226877\tvalid_loss: 0.548723958910045\n",
      "2022-04-03 11:10:43,149 | \tacc: 0.791874\tpc: 0.629362\trc: 0.545875\tf1: 0.564261\n",
      "2022-04-03 11:10:43,771 | Validation accuracy got better 0.7881801392243216 --> 0.7918738457167211.  Saving model ...\n",
      "2022-04-03 11:10:43,833 | Validation loss got better 0.5618433687967711 --> 0.548723958910045.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:12:26,215 | Epoch 15 Result\n",
      "2022-04-03 11:12:26,216 | \ttrain loss: 0.6586103420059034\tvalid_loss: 0.5381509817227466\n",
      "2022-04-03 11:12:26,216 | \tacc: 0.793152\tpc: 0.644227\trc: 0.557308\tf1: 0.576306\n",
      "2022-04-03 11:12:26,847 | Validation accuracy got better 0.7918738457167211 --> 0.7931524364256286.  Saving model ...\n",
      "2022-04-03 11:12:26,910 | Validation loss got better 0.548723958910045 --> 0.5381509817227466.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:14:09,374 | Epoch 16 Result\n",
      "2022-04-03 11:14:09,374 | \ttrain loss: 0.6443858569288174\tvalid_loss: 0.5280132157708759\n",
      "2022-04-03 11:14:09,374 | \tacc: 0.796136\tpc: 0.636121\trc: 0.559792\tf1: 0.578352\n",
      "2022-04-03 11:14:10,025 | Validation accuracy got better 0.7931524364256286 --> 0.7961358147464128.  Saving model ...\n",
      "2022-04-03 11:14:10,088 | Validation loss got better 0.5381509817227466 --> 0.5280132157708759.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:15:52,495 | Epoch 17 Result\n",
      "2022-04-03 11:15:52,495 | \ttrain loss: 0.6290941460919791\tvalid_loss: 0.5219905560523682\n",
      "2022-04-03 11:15:52,496 | \tacc: 0.797699\tpc: 0.653586\trc: 0.572483\tf1: 0.590692\n",
      "2022-04-03 11:15:53,136 | Validation accuracy got better 0.7961358147464128 --> 0.7976985367239665.  Saving model ...\n",
      "2022-04-03 11:15:53,198 | Validation loss got better 0.5280132157708759 --> 0.5219905560523682.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:17:35,556 | Epoch 18 Result\n",
      "2022-04-03 11:17:35,557 | \ttrain loss: 0.6206791778041689\tvalid_loss: 0.5133760843888012\n",
      "2022-04-03 11:17:35,557 | \tacc: 0.800327\tpc: 0.655946\trc: 0.574954\tf1: 0.59272\n",
      "2022-04-03 11:17:36,217 | Validation accuracy got better 0.7976985367239665 --> 0.800326750958943.  Saving model ...\n",
      "2022-04-03 11:17:36,285 | Validation loss got better 0.5219905560523682 --> 0.5133760843888012.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:19:18,679 | Epoch 19 Result\n",
      "2022-04-03 11:19:18,679 | \ttrain loss: 0.608115625518563\tvalid_loss: 0.5102705309075682\n",
      "2022-04-03 11:19:18,679 | \tacc: 0.802529\tpc: 0.657048\trc: 0.58106\tf1: 0.599161\n",
      "2022-04-03 11:19:19,322 | Validation accuracy got better 0.800326750958943 --> 0.8025287682909504.  Saving model ...\n",
      "2022-04-03 11:19:19,386 | Validation loss got better 0.5133760843888012 --> 0.5102705309075682.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:21:01,828 | Epoch 20 Result\n",
      "2022-04-03 11:21:01,829 | \ttrain loss: 0.5995897315028444\tvalid_loss: 0.5016235971945323\n",
      "2022-04-03 11:21:01,829 | \tacc: 0.803381\tpc: 0.647212\trc: 0.576121\tf1: 0.589848\n",
      "2022-04-03 11:21:02,466 | Validation accuracy got better 0.8025287682909504 --> 0.8033811620968888.  Saving model ...\n",
      "2022-04-03 11:21:02,530 | Validation loss got better 0.5102705309075682 --> 0.5016235971945323.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:22:44,955 | Epoch 21 Result\n",
      "2022-04-03 11:22:44,955 | \ttrain loss: 0.5946684636204399\tvalid_loss: 0.4950194016219642\n",
      "2022-04-03 11:22:44,955 | \tacc: 0.804873\tpc: 0.647361\trc: 0.58403\tf1: 0.598099\n",
      "2022-04-03 11:22:45,578 | Validation accuracy got better 0.8033811620968888 --> 0.8048728512572809.  Saving model ...\n",
      "2022-04-03 11:22:45,640 | Validation loss got better 0.5016235971945323 --> 0.4950194016219642.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:24:28,071 | Epoch 22 Result\n",
      "2022-04-03 11:24:28,072 | \ttrain loss: 0.5838223089614971\tvalid_loss: 0.49360434298387285\n",
      "2022-04-03 11:24:28,072 | \tacc: 0.805938\tpc: 0.657815\trc: 0.587048\tf1: 0.601486\n",
      "2022-04-03 11:24:28,699 | Validation accuracy got better 0.8048728512572809 --> 0.8059383435147038.  Saving model ...\n",
      "2022-04-03 11:24:28,760 | Validation loss got better 0.4950194016219642 --> 0.49360434298387285.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:26:11,217 | Epoch 23 Result\n",
      "2022-04-03 11:26:11,218 | \ttrain loss: 0.5775782136601225\tvalid_loss: 0.4909127290690211\n",
      "2022-04-03 11:26:11,218 | \tacc: 0.807359\tpc: 0.664078\trc: 0.593169\tf1: 0.609741\n",
      "2022-04-03 11:26:11,846 | Validation accuracy got better 0.8059383435147038 --> 0.8073589998579344.  Saving model ...\n",
      "2022-04-03 11:26:11,909 | Validation loss got better 0.49360434298387285 --> 0.4909127290690211.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 11:27:54,221 | Epoch 24 Result\n",
      "2022-04-03 11:27:54,221 | \ttrain loss: 0.5752880671714329\tvalid_loss: 0.48493971347402387\n",
      "2022-04-03 11:27:54,221 | \tacc: 0.808424\tpc: 0.668095\trc: 0.59526\tf1: 0.610664\n",
      "2022-04-03 11:27:54,846 | Validation accuracy got better 0.8073589998579344 --> 0.8084244921153573.  Saving model ...\n",
      "2022-04-03 11:27:54,908 | Validation loss got better 0.4909127290690211 --> 0.48493971347402387.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:29:37,275 | Epoch 25 Result\n",
      "2022-04-03 11:29:37,275 | \ttrain loss: 0.5652875564093818\tvalid_loss: 0.48097462319806145\n",
      "2022-04-03 11:29:37,276 | \tacc: 0.806507\tpc: 0.656085\trc: 0.593335\tf1: 0.605876\n",
      "2022-04-03 11:29:37,906 | Validation loss got better 0.48493971347402387 --> 0.48097462319806145.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 11:31:20,169 | Epoch 26 Result\n",
      "2022-04-03 11:31:20,169 | \ttrain loss: 0.5611772372344865\tvalid_loss: 0.4782005331871574\n",
      "2022-04-03 11:31:20,170 | \tacc: 0.810413\tpc: 0.664859\trc: 0.600887\tf1: 0.613011\n",
      "2022-04-03 11:31:20,803 | Validation accuracy got better 0.8084244921153573 --> 0.81041341099588.  Saving model ...\n",
      "2022-04-03 11:31:20,865 | Validation loss got better 0.48097462319806145 --> 0.4782005331871574.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:33:03,250 | Epoch 27 Result\n",
      "2022-04-03 11:33:03,250 | \ttrain loss: 0.5564593133920864\tvalid_loss: 0.4755673133305722\n",
      "2022-04-03 11:33:03,251 | \tacc: 0.811408\tpc: 0.668725\trc: 0.608157\tf1: 0.619186\n",
      "2022-04-03 11:33:03,890 | Validation accuracy got better 0.81041341099588 --> 0.8114078704361415.  Saving model ...\n",
      "2022-04-03 11:33:03,953 | Validation loss got better 0.4782005331871574 --> 0.4755673133305722.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:34:46,321 | Epoch 28 Result\n",
      "2022-04-03 11:34:46,321 | \ttrain loss: 0.5508954612126218\tvalid_loss: 0.4720275359899589\n",
      "2022-04-03 11:34:46,322 | \tacc: 0.813113\tpc: 0.663033\trc: 0.607899\tf1: 0.618613\n",
      "2022-04-03 11:34:46,950 | Validation accuracy got better 0.8114078704361415 --> 0.8131126580480181.  Saving model ...\n",
      "2022-04-03 11:34:47,013 | Validation loss got better 0.4755673133305722 --> 0.4720275359899589.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.70it/s]\n",
      "2022-04-03 11:36:29,390 | Epoch 29 Result\n",
      "2022-04-03 11:36:29,390 | \ttrain loss: 0.5461608972772628\tvalid_loss: 0.46835605687318765\n",
      "2022-04-03 11:36:29,391 | \tacc: 0.81361\tpc: 0.672168\trc: 0.608484\tf1: 0.624042\n",
      "2022-04-03 11:36:30,028 | Validation accuracy got better 0.8131126580480181 --> 0.8136098877681489.  Saving model ...\n",
      "2022-04-03 11:36:30,092 | Validation loss got better 0.4720275359899589 --> 0.46835605687318765.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:38:12,498 | Epoch 30 Result\n",
      "2022-04-03 11:38:12,499 | \ttrain loss: 0.5410006347281419\tvalid_loss: 0.4685863183800987\n",
      "2022-04-03 11:38:12,499 | \tacc: 0.814178\tpc: 0.663989\trc: 0.611608\tf1: 0.621411\n",
      "2022-04-03 11:38:13,123 | Validation accuracy got better 0.8136098877681489 --> 0.8141781503054412.  Saving model ...\n",
      "2022-04-03 11:38:13,186 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 11:39:55,580 | Epoch 31 Result\n",
      "2022-04-03 11:39:55,580 | \ttrain loss: 0.5372548795945428\tvalid_loss: 0.4652914393437588\n",
      "2022-04-03 11:39:55,581 | \tacc: 0.814462\tpc: 0.67786\trc: 0.611692\tf1: 0.625637\n",
      "2022-04-03 11:39:56,207 | Validation accuracy got better 0.8141781503054412 --> 0.8144622815740872.  Saving model ...\n",
      "2022-04-03 11:39:56,269 | Validation loss got better 0.46835605687318765 --> 0.4652914393437588.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:41:38,680 | Epoch 32 Result\n",
      "2022-04-03 11:41:38,680 | \ttrain loss: 0.5330398117358641\tvalid_loss: 0.4625154355148443\n",
      "2022-04-03 11:41:38,680 | \tacc: 0.81638\tpc: 0.674703\trc: 0.614868\tf1: 0.628409\n",
      "2022-04-03 11:41:39,310 | Validation accuracy got better 0.8144622815740872 --> 0.8163801676374485.  Saving model ...\n",
      "2022-04-03 11:41:39,373 | Validation loss got better 0.4652914393437588 --> 0.4625154355148443.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 11:43:21,838 | Epoch 33 Result\n",
      "2022-04-03 11:43:21,839 | \ttrain loss: 0.5316857927175741\tvalid_loss: 0.459719541753993\n",
      "2022-04-03 11:43:21,839 | \tacc: 0.816167\tpc: 0.6736\trc: 0.611624\tf1: 0.626125\n",
      "2022-04-03 11:43:22,477 | Validation loss got better 0.4625154355148443 --> 0.459719541753993.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:45:04,955 | Epoch 34 Result\n",
      "2022-04-03 11:45:04,956 | \ttrain loss: 0.526850586838135\tvalid_loss: 0.462879427235681\n",
      "2022-04-03 11:45:04,956 | \tacc: 0.81432\tpc: 0.665427\trc: 0.617624\tf1: 0.625527\n",
      "2022-04-03 11:45:05,615 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 11:46:47,967 | Epoch 35 Result\n",
      "2022-04-03 11:46:47,967 | \ttrain loss: 0.5239076208438279\tvalid_loss: 0.4569707157801864\n",
      "2022-04-03 11:46:47,967 | \tacc: 0.817517\tpc: 0.672733\trc: 0.618074\tf1: 0.628013\n",
      "2022-04-03 11:46:48,611 | Validation accuracy got better 0.8163801676374485 --> 0.817516692712033.  Saving model ...\n",
      "2022-04-03 11:46:48,674 | Validation loss got better 0.459719541753993 --> 0.4569707157801864.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:48:31,170 | Epoch 36 Result\n",
      "2022-04-03 11:48:31,170 | \ttrain loss: 0.5199193380389455\tvalid_loss: 0.45387627184602714\n",
      "2022-04-03 11:48:31,170 | \tacc: 0.818724\tpc: 0.673333\trc: 0.618205\tf1: 0.628553\n",
      "2022-04-03 11:48:31,825 | Validation accuracy got better 0.817516692712033 --> 0.818724250603779.  Saving model ...\n",
      "2022-04-03 11:48:31,888 | Validation loss got better 0.4569707157801864 --> 0.45387627184602714.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.64it/s]\n",
      "2022-04-03 11:50:14,566 | Epoch 37 Result\n",
      "2022-04-03 11:50:14,567 | \ttrain loss: 0.5162407502578996\tvalid_loss: 0.45323555143334376\n",
      "2022-04-03 11:50:14,567 | \tacc: 0.817446\tpc: 0.678468\trc: 0.617953\tf1: 0.629944\n",
      "2022-04-03 11:50:15,228 | Validation loss got better 0.45387627184602714 --> 0.45323555143334376.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:51:57,701 | Epoch 38 Result\n",
      "2022-04-03 11:51:57,702 | \ttrain loss: 0.5139634079156615\tvalid_loss: 0.4507240899365503\n",
      "2022-04-03 11:51:57,702 | \tacc: 0.819719\tpc: 0.674405\trc: 0.615861\tf1: 0.627839\n",
      "2022-04-03 11:51:58,359 | Validation accuracy got better 0.818724250603779 --> 0.8197187100440404.  Saving model ...\n",
      "2022-04-03 11:51:58,423 | Validation loss got better 0.45323555143334376 --> 0.4507240899365503.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:33<00:00,  2.78it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 11:53:42,490 | Epoch 39 Result\n",
      "2022-04-03 11:53:42,491 | \ttrain loss: 0.5140248460677582\tvalid_loss: 0.4503933877866365\n",
      "2022-04-03 11:53:42,491 | \tacc: 0.817446\tpc: 0.678545\trc: 0.618857\tf1: 0.630754\n",
      "2022-04-03 11:53:43,131 | Validation loss got better 0.4507240899365503 --> 0.4503933877866365.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:55:25,632 | Epoch 40 Result\n",
      "2022-04-03 11:55:25,633 | \ttrain loss: 0.5090741868592132\tvalid_loss: 0.4486719018983848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 11:55:25,633 | \tacc: 0.81979\tpc: 0.676948\trc: 0.622946\tf1: 0.63442\n",
      "2022-04-03 11:55:26,311 | Validation accuracy got better 0.8197187100440404 --> 0.8197897428612019.  Saving model ...\n",
      "2022-04-03 11:55:26,376 | Validation loss got better 0.4503933877866365 --> 0.4486719018983848.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:57:08,850 | Epoch 41 Result\n",
      "2022-04-03 11:57:08,850 | \ttrain loss: 0.5067652201762345\tvalid_loss: 0.4443196434581088\n",
      "2022-04-03 11:57:08,851 | \tacc: 0.820358\tpc: 0.674318\trc: 0.624456\tf1: 0.635798\n",
      "2022-04-03 11:57:09,489 | Validation accuracy got better 0.8197897428612019 --> 0.8203580053984941.  Saving model ...\n",
      "2022-04-03 11:57:09,554 | Validation loss got better 0.4486719018983848 --> 0.4443196434581088.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 11:58:52,051 | Epoch 42 Result\n",
      "2022-04-03 11:58:52,051 | \ttrain loss: 0.504597765303561\tvalid_loss: 0.4463480045416423\n",
      "2022-04-03 11:58:52,051 | \tacc: 0.820713\tpc: 0.669368\trc: 0.625949\tf1: 0.632487\n",
      "2022-04-03 11:58:52,681 | Validation accuracy got better 0.8203580053984941 --> 0.8207131694843017.  Saving model ...\n",
      "2022-04-03 11:58:52,744 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 12:00:35,091 | Epoch 43 Result\n",
      "2022-04-03 12:00:35,092 | \ttrain loss: 0.5026972194057352\tvalid_loss: 0.4452701257633069\n",
      "2022-04-03 12:00:35,092 | \tacc: 0.819719\tpc: 0.680263\trc: 0.62986\tf1: 0.639361\n",
      "2022-04-03 12:00:35,726 | patience 1 --> 2\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "2022-04-03 12:02:18,080 | Epoch 44 Result\n",
      "2022-04-03 12:02:18,081 | \ttrain loss: 0.500039699375847\tvalid_loss: 0.4423611358513055\n",
      "2022-04-03 12:02:18,081 | \tacc: 0.819364\tpc: 0.680165\trc: 0.628185\tf1: 0.637052\n",
      "2022-04-03 12:02:18,710 | Validation loss got better 0.4443196434581088 --> 0.4423611358513055.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:04:01,256 | Epoch 45 Result\n",
      "2022-04-03 12:04:01,257 | \ttrain loss: 0.49805035312820645\tvalid_loss: 0.4422554767915921\n",
      "2022-04-03 12:04:01,257 | \tacc: 0.82256\tpc: 0.67084\trc: 0.623612\tf1: 0.632004\n",
      "2022-04-03 12:04:01,886 | Validation accuracy got better 0.8207131694843017 --> 0.8225600227305014.  Saving model ...\n",
      "2022-04-03 12:04:01,950 | Validation loss got better 0.4423611358513055 --> 0.4422554767915921.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 12:05:44,360 | Epoch 46 Result\n",
      "2022-04-03 12:05:44,361 | \ttrain loss: 0.4949215712416454\tvalid_loss: 0.44090442544679986\n",
      "2022-04-03 12:05:44,361 | \tacc: 0.821423\tpc: 0.676115\trc: 0.624084\tf1: 0.633528\n",
      "2022-04-03 12:05:44,992 | Validation loss got better 0.4422554767915921 --> 0.44090442544679986.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:07:27,518 | Epoch 47 Result\n",
      "2022-04-03 12:07:27,518 | \ttrain loss: 0.4922395196409387\tvalid_loss: 0.44131110093525516\n",
      "2022-04-03 12:07:27,519 | \tacc: 0.8205\tpc: 0.687482\trc: 0.624517\tf1: 0.637821\n",
      "2022-04-03 12:07:28,142 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 12:09:10,605 | Epoch 48 Result\n",
      "2022-04-03 12:09:10,605 | \ttrain loss: 0.4911386831298743\tvalid_loss: 0.4393678313714737\n",
      "2022-04-03 12:09:10,606 | \tacc: 0.822702\tpc: 0.687442\trc: 0.628113\tf1: 0.639833\n",
      "2022-04-03 12:09:11,233 | Validation accuracy got better 0.8225600227305014 --> 0.8227020883648245.  Saving model ...\n",
      "2022-04-03 12:09:11,296 | Validation loss got better 0.44090442544679986 --> 0.4393678313714737.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:10:53,871 | Epoch 49 Result\n",
      "2022-04-03 12:10:53,871 | \ttrain loss: 0.49146715926316714\tvalid_loss: 0.4379962615151181\n",
      "2022-04-03 12:10:53,871 | \tacc: 0.823697\tpc: 0.683702\trc: 0.633331\tf1: 0.641483\n",
      "2022-04-03 12:10:54,497 | Validation accuracy got better 0.8227020883648245 --> 0.8236965478050859.  Saving model ...\n",
      "2022-04-03 12:10:54,559 | Validation loss got better 0.4393678313714737 --> 0.4379962615151181.  Saving model ...\n",
      "2022-04-03 12:10:54,624 | # train data: 132867\n",
      "2022-04-03 12:10:54,625 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:12:37,087 | Epoch 0 Result\n",
      "2022-04-03 12:12:37,087 | \ttrain loss: 5.181154071032645\tvalid_loss: 4.4932528252729655\n",
      "2022-04-03 12:12:37,088 | \tacc: 0.108822\tpc: 0.002478\trc: 0.005806\tf1: 0.00244\n",
      "2022-04-03 12:12:37,697 | Validation accuracy got better None --> 0.10882227589146186.  Saving model ...\n",
      "2022-04-03 12:12:37,751 | Validation loss got better None --> 4.4932528252729655.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:14:20,309 | Epoch 1 Result\n",
      "2022-04-03 12:14:20,309 | \ttrain loss: 3.9524398876173015\tvalid_loss: 3.127704236534174\n",
      "2022-04-03 12:14:20,310 | \tacc: 0.314178\tpc: 0.043155\trc: 0.043431\tf1: 0.033321\n",
      "2022-04-03 12:14:20,935 | Validation accuracy got better 0.10882227589146186 --> 0.3141781503054411.  Saving model ...\n",
      "2022-04-03 12:14:20,996 | Validation loss got better 4.4932528252729655 --> 3.127704236534174.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:16:03,499 | Epoch 2 Result\n",
      "2022-04-03 12:16:03,499 | \ttrain loss: 2.9413933635230824\tvalid_loss: 2.1293258838379887\n",
      "2022-04-03 12:16:03,499 | \tacc: 0.499716\tpc: 0.129937\trc: 0.099217\tf1: 0.091686\n",
      "2022-04-03 12:16:04,132 | Validation accuracy got better 0.3141781503054411 --> 0.4997158687313539.  Saving model ...\n",
      "2022-04-03 12:16:04,193 | Validation loss got better 3.127704236534174 --> 2.1293258838379887.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:17:46,767 | Epoch 3 Result\n",
      "2022-04-03 12:17:46,767 | \ttrain loss: 2.1216008657148255\tvalid_loss: 1.458896150167633\n",
      "2022-04-03 12:17:46,767 | \tacc: 0.617986\tpc: 0.219355\trc: 0.177034\tf1: 0.171236\n",
      "2022-04-03 12:17:47,391 | Validation accuracy got better 0.4997158687313539 --> 0.617985509305299.  Saving model ...\n",
      "2022-04-03 12:17:47,453 | Validation loss got better 2.1293258838379887 --> 1.458896150167633.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 12:19:29,973 | Epoch 4 Result\n",
      "2022-04-03 12:19:29,974 | \ttrain loss: 1.5801355078122985\tvalid_loss: 1.1104729387261918\n",
      "2022-04-03 12:19:29,974 | \tacc: 0.683052\tpc: 0.313289\trc: 0.249263\tf1: 0.251947\n",
      "2022-04-03 12:19:30,602 | Validation accuracy got better 0.617985509305299 --> 0.6830515698252593.  Saving model ...\n",
      "2022-04-03 12:19:30,663 | Validation loss got better 1.458896150167633 --> 1.1104729387261918.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:21:13,130 | Epoch 5 Result\n",
      "2022-04-03 12:21:13,130 | \ttrain loss: 1.2731638411265\tvalid_loss: 0.9195928040816205\n",
      "2022-04-03 12:21:13,131 | \tacc: 0.715798\tpc: 0.374123\trc: 0.303158\tf1: 0.311878\n",
      "2022-04-03 12:21:13,754 | Validation accuracy got better 0.6830515698252593 --> 0.7157976985367239.  Saving model ...\n",
      "2022-04-03 12:21:13,814 | Validation loss got better 1.1104729387261918 --> 0.9195928040816205.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 12:22:56,296 | Epoch 6 Result\n",
      "2022-04-03 12:22:56,296 | \ttrain loss: 1.088306550280528\tvalid_loss: 0.8080137958410095\n",
      "2022-04-03 12:22:56,297 | \tacc: 0.734906\tpc: 0.461119\trc: 0.358535\tf1: 0.376307\n",
      "2022-04-03 12:22:56,922 | Validation accuracy got better 0.7157976985367239 --> 0.7349055263531752.  Saving model ...\n",
      "2022-04-03 12:22:56,984 | Validation loss got better 0.9195928040816205 --> 0.8080137958410095.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 12:24:39,506 | Epoch 7 Result\n",
      "2022-04-03 12:24:39,507 | \ttrain loss: 0.9681676876382826\tvalid_loss: 0.7326914496949526\n",
      "2022-04-03 12:24:39,507 | \tacc: 0.750746\tpc: 0.506438\trc: 0.408377\tf1: 0.429488\n",
      "2022-04-03 12:24:40,132 | Validation accuracy got better 0.7349055263531752 --> 0.750745844580196.  Saving model ...\n",
      "2022-04-03 12:24:40,195 | Validation loss got better 0.8080137958410095 --> 0.7326914496949526.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:26:22,666 | Epoch 8 Result\n",
      "2022-04-03 12:26:22,666 | \ttrain loss: 0.8858075053639449\tvalid_loss: 0.6832156649095156\n",
      "2022-04-03 12:26:22,667 | \tacc: 0.759341\tpc: 0.552985\trc: 0.441794\tf1: 0.467341\n",
      "2022-04-03 12:26:23,296 | Validation accuracy got better 0.750745844580196 --> 0.759340815456741.  Saving model ...\n",
      "2022-04-03 12:26:23,359 | Validation loss got better 0.7326914496949526 --> 0.6832156649095156.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:28:05,891 | Epoch 9 Result\n",
      "2022-04-03 12:28:05,892 | \ttrain loss: 0.8246390999511473\tvalid_loss: 0.6461958854878248\n",
      "2022-04-03 12:28:05,892 | \tacc: 0.76751\tpc: 0.571628\trc: 0.468739\tf1: 0.493241\n",
      "2022-04-03 12:28:06,514 | Validation accuracy got better 0.759340815456741 --> 0.7675095894303168.  Saving model ...\n",
      "2022-04-03 12:28:06,576 | Validation loss got better 0.6832156649095156 --> 0.6461958854878248.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:29:49,127 | Epoch 10 Result\n",
      "2022-04-03 12:29:49,127 | \ttrain loss: 0.7769919914749671\tvalid_loss: 0.6161313531649081\n",
      "2022-04-03 12:29:49,128 | \tacc: 0.774968\tpc: 0.574363\trc: 0.478814\tf1: 0.500496\n",
      "2022-04-03 12:29:49,746 | Validation accuracy got better 0.7675095894303168 --> 0.7749680352322773.  Saving model ...\n",
      "2022-04-03 12:29:49,809 | Validation loss got better 0.6461958854878248 --> 0.6161313531649081.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 12:31:32,279 | Epoch 11 Result\n",
      "2022-04-03 12:31:32,279 | \ttrain loss: 0.7435996003877211\tvalid_loss: 0.5949248507172229\n",
      "2022-04-03 12:31:32,280 | \tacc: 0.780793\tpc: 0.585514\trc: 0.50134\tf1: 0.519616\n",
      "2022-04-03 12:31:32,904 | Validation accuracy got better 0.7749680352322773 --> 0.7807927262395227.  Saving model ...\n",
      "2022-04-03 12:31:32,966 | Validation loss got better 0.6161313531649081 --> 0.5949248507172229.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:33:15,457 | Epoch 12 Result\n",
      "2022-04-03 12:33:15,457 | \ttrain loss: 0.7150336973249064\tvalid_loss: 0.5763281682689584\n",
      "2022-04-03 12:33:15,458 | \tacc: 0.785268\tpc: 0.6106\trc: 0.508146\tf1: 0.532187\n",
      "2022-04-03 12:33:16,086 | Validation accuracy got better 0.7807927262395227 --> 0.785267793720699.  Saving model ...\n",
      "2022-04-03 12:33:16,148 | Validation loss got better 0.5949248507172229 --> 0.5763281682689584.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 12:34:58,658 | Epoch 13 Result\n",
      "2022-04-03 12:34:58,658 | \ttrain loss: 0.6901040173300412\tvalid_loss: 0.5611971185566061\n",
      "2022-04-03 12:34:58,658 | \tacc: 0.786759\tpc: 0.632037\trc: 0.52276\tf1: 0.547921\n",
      "2022-04-03 12:34:59,304 | Validation accuracy got better 0.785267793720699 --> 0.7867594828810911.  Saving model ...\n",
      "2022-04-03 12:34:59,366 | Validation loss got better 0.5763281682689584 --> 0.5611971185566061.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:36:41,886 | Epoch 14 Result\n",
      "2022-04-03 12:36:41,886 | \ttrain loss: 0.669275982560593\tvalid_loss: 0.5496765884050406\n",
      "2022-04-03 12:36:41,886 | \tacc: 0.790879\tpc: 0.650729\trc: 0.536858\tf1: 0.562142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:36:42,512 | Validation accuracy got better 0.7867594828810911 --> 0.7908793862764597.  Saving model ...\n",
      "2022-04-03 12:36:42,574 | Validation loss got better 0.5611971185566061 --> 0.5496765884050406.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.68it/s]\n",
      "2022-04-03 12:38:25,134 | Epoch 15 Result\n",
      "2022-04-03 12:38:25,135 | \ttrain loss: 0.6535827799295468\tvalid_loss: 0.5397726396451469\n",
      "2022-04-03 12:38:25,135 | \tacc: 0.792584\tpc: 0.638697\trc: 0.549561\tf1: 0.570065\n",
      "2022-04-03 12:38:25,760 | Validation accuracy got better 0.7908793862764597 --> 0.7925841738883365.  Saving model ...\n",
      "2022-04-03 12:38:25,822 | Validation loss got better 0.5496765884050406 --> 0.5397726396451469.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.63it/s]\n",
      "2022-04-03 12:40:08,511 | Epoch 16 Result\n",
      "2022-04-03 12:40:08,511 | \ttrain loss: 0.6381644578153275\tvalid_loss: 0.5297224906581863\n",
      "2022-04-03 12:40:08,512 | \tacc: 0.796633\tpc: 0.666186\trc: 0.553893\tf1: 0.581446\n",
      "2022-04-03 12:40:09,157 | Validation accuracy got better 0.7925841738883365 --> 0.7966330444665436.  Saving model ...\n",
      "2022-04-03 12:40:09,224 | Validation loss got better 0.5397726396451469 --> 0.5297224906581863.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:41:51,900 | Epoch 17 Result\n",
      "2022-04-03 12:41:51,901 | \ttrain loss: 0.6271386866877549\tvalid_loss: 0.5241412060354596\n",
      "2022-04-03 12:41:51,901 | \tacc: 0.798835\tpc: 0.658469\trc: 0.564837\tf1: 0.59012\n",
      "2022-04-03 12:41:52,522 | Validation accuracy got better 0.7966330444665436 --> 0.7988350617985509.  Saving model ...\n",
      "2022-04-03 12:41:52,583 | Validation loss got better 0.5297224906581863 --> 0.5241412060354596.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:43:35,140 | Epoch 18 Result\n",
      "2022-04-03 12:43:35,141 | \ttrain loss: 0.6151608745403304\tvalid_loss: 0.5164326463576863\n",
      "2022-04-03 12:43:35,141 | \tacc: 0.803736\tpc: 0.656533\trc: 0.568072\tf1: 0.589117\n",
      "2022-04-03 12:43:35,773 | Validation accuracy got better 0.7988350617985509 --> 0.8037363261826964.  Saving model ...\n",
      "2022-04-03 12:43:35,835 | Validation loss got better 0.5241412060354596 --> 0.5164326463576863.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:45:18,281 | Epoch 19 Result\n",
      "2022-04-03 12:45:18,282 | \ttrain loss: 0.6048862093478322\tvalid_loss: 0.5080938463032221\n",
      "2022-04-03 12:45:18,282 | \tacc: 0.802387\tpc: 0.658728\trc: 0.563309\tf1: 0.587241\n",
      "2022-04-03 12:45:18,923 | Validation loss got better 0.5164326463576863 --> 0.5080938463032221.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.63it/s]\n",
      "2022-04-03 12:47:01,703 | Epoch 20 Result\n",
      "2022-04-03 12:47:01,703 | \ttrain loss: 0.5972284152617654\tvalid_loss: 0.5036935001836106\n",
      "2022-04-03 12:47:01,704 | \tacc: 0.804091\tpc: 0.662021\trc: 0.581028\tf1: 0.601024\n",
      "2022-04-03 12:47:02,370 | Validation accuracy got better 0.8037363261826964 --> 0.804091490268504.  Saving model ...\n",
      "2022-04-03 12:47:02,439 | Validation loss got better 0.5080938463032221 --> 0.5036935001836106.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 12:48:45,236 | Epoch 21 Result\n",
      "2022-04-03 12:48:45,237 | \ttrain loss: 0.5881420279949825\tvalid_loss: 0.4980938550270591\n",
      "2022-04-03 12:48:45,237 | \tacc: 0.805583\tpc: 0.654762\trc: 0.578058\tf1: 0.597486\n",
      "2022-04-03 12:48:45,868 | Validation accuracy got better 0.804091490268504 --> 0.8055831794288961.  Saving model ...\n",
      "2022-04-03 12:48:45,931 | Validation loss got better 0.5036935001836106 --> 0.4980938550270591.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 12:50:28,503 | Epoch 22 Result\n",
      "2022-04-03 12:50:28,503 | \ttrain loss: 0.5801973238447079\tvalid_loss: 0.4938606485620719\n",
      "2022-04-03 12:50:28,504 | \tacc: 0.809064\tpc: 0.677987\trc: 0.590972\tf1: 0.615464\n",
      "2022-04-03 12:50:29,134 | Validation accuracy got better 0.8055831794288961 --> 0.809063787469811.  Saving model ...\n",
      "2022-04-03 12:50:29,197 | Validation loss got better 0.4980938550270591 --> 0.4938606485620719.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:52:11,697 | Epoch 23 Result\n",
      "2022-04-03 12:52:11,697 | \ttrain loss: 0.5742907796397952\tvalid_loss: 0.4890335946788265\n",
      "2022-04-03 12:52:11,698 | \tacc: 0.812331\tpc: 0.670722\trc: 0.592121\tf1: 0.612374\n",
      "2022-04-03 12:52:12,327 | Validation accuracy got better 0.809063787469811 --> 0.8123312970592413.  Saving model ...\n",
      "2022-04-03 12:52:12,390 | Validation loss got better 0.4938606485620719 --> 0.4890335946788265.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 12:53:55,033 | Epoch 24 Result\n",
      "2022-04-03 12:53:55,033 | \ttrain loss: 0.5657544807584863\tvalid_loss: 0.487831014227945\n",
      "2022-04-03 12:53:55,034 | \tacc: 0.811621\tpc: 0.672767\trc: 0.598121\tf1: 0.618563\n",
      "2022-04-03 12:53:55,690 | Validation loss got better 0.4890335946788265 --> 0.487831014227945.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.63it/s]\n",
      "2022-04-03 12:55:38,464 | Epoch 25 Result\n",
      "2022-04-03 12:55:38,464 | \ttrain loss: 0.5618806654944154\tvalid_loss: 0.48346249180636736\n",
      "2022-04-03 12:55:38,465 | \tacc: 0.812473\tpc: 0.668841\trc: 0.596417\tf1: 0.613236\n",
      "2022-04-03 12:55:39,118 | Validation accuracy got better 0.8123312970592413 --> 0.8124733626935644.  Saving model ...\n",
      "2022-04-03 12:55:39,185 | Validation loss got better 0.487831014227945 --> 0.48346249180636736.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 12:57:21,966 | Epoch 26 Result\n",
      "2022-04-03 12:57:21,967 | \ttrain loss: 0.5565860895784777\tvalid_loss: 0.48037963249514365\n",
      "2022-04-03 12:57:21,967 | \tacc: 0.814391\tpc: 0.669094\trc: 0.609257\tf1: 0.623506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:57:22,602 | Validation accuracy got better 0.8124733626935644 --> 0.8143912487569257.  Saving model ...\n",
      "2022-04-03 12:57:22,665 | Validation loss got better 0.48346249180636736 --> 0.48037963249514365.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.63it/s]\n",
      "2022-04-03 12:59:05,528 | Epoch 27 Result\n",
      "2022-04-03 12:59:05,528 | \ttrain loss: 0.5509049072045773\tvalid_loss: 0.47728720942856423\n",
      "2022-04-03 12:59:05,528 | \tacc: 0.814817\tpc: 0.660402\trc: 0.602131\tf1: 0.616165\n",
      "2022-04-03 12:59:06,178 | Validation accuracy got better 0.8143912487569257 --> 0.8148174456598949.  Saving model ...\n",
      "2022-04-03 12:59:06,243 | Validation loss got better 0.48037963249514365 --> 0.47728720942856423.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:00:48,916 | Epoch 28 Result\n",
      "2022-04-03 13:00:48,917 | \ttrain loss: 0.5449390608847872\tvalid_loss: 0.47459342246334024\n",
      "2022-04-03 13:00:48,917 | \tacc: 0.81496\tpc: 0.662959\trc: 0.601371\tf1: 0.617264\n",
      "2022-04-03 13:00:49,543 | Validation accuracy got better 0.8148174456598949 --> 0.814959511294218.  Saving model ...\n",
      "2022-04-03 13:00:49,607 | Validation loss got better 0.47728720942856423 --> 0.47459342246334024.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:02:32,170 | Epoch 29 Result\n",
      "2022-04-03 13:02:32,170 | \ttrain loss: 0.5396945295825388\tvalid_loss: 0.4729736774613665\n",
      "2022-04-03 13:02:32,171 | \tacc: 0.815031\tpc: 0.673784\trc: 0.601044\tf1: 0.620542\n",
      "2022-04-03 13:02:32,826 | Validation accuracy got better 0.814959511294218 --> 0.8150305441113794.  Saving model ...\n",
      "2022-04-03 13:02:32,888 | Validation loss got better 0.47459342246334024 --> 0.4729736774613665.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:04:15,436 | Epoch 30 Result\n",
      "2022-04-03 13:04:15,437 | \ttrain loss: 0.5363172292825987\tvalid_loss: 0.47072351385304356\n",
      "2022-04-03 13:04:15,437 | \tacc: 0.81638\tpc: 0.668561\trc: 0.606661\tf1: 0.620062\n",
      "2022-04-03 13:04:16,089 | Validation accuracy got better 0.8150305441113794 --> 0.8163801676374485.  Saving model ...\n",
      "2022-04-03 13:04:16,151 | Validation loss got better 0.4729736774613665 --> 0.47072351385304356.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:05:58,783 | Epoch 31 Result\n",
      "2022-04-03 13:05:58,783 | \ttrain loss: 0.5326694008468603\tvalid_loss: 0.46913491053783785\n",
      "2022-04-03 13:05:58,784 | \tacc: 0.815883\tpc: 0.67444\trc: 0.607983\tf1: 0.624842\n",
      "2022-04-03 13:05:59,425 | Validation loss got better 0.47072351385304356 --> 0.46913491053783785.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:07:41,949 | Epoch 32 Result\n",
      "2022-04-03 13:07:41,949 | \ttrain loss: 0.5281072424013058\tvalid_loss: 0.46701131515296995\n",
      "2022-04-03 13:07:41,949 | \tacc: 0.815883\tpc: 0.654898\trc: 0.60012\tf1: 0.613563\n",
      "2022-04-03 13:07:42,591 | Validation loss got better 0.46913491053783785 --> 0.46701131515296995.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:09:25,127 | Epoch 33 Result\n",
      "2022-04-03 13:09:25,127 | \ttrain loss: 0.5250256040038915\tvalid_loss: 0.4636723383835626\n",
      "2022-04-03 13:09:25,128 | \tacc: 0.818298\tpc: 0.672727\trc: 0.612509\tf1: 0.626967\n",
      "2022-04-03 13:09:25,769 | Validation accuracy got better 0.8163801676374485 --> 0.8182980537008098.  Saving model ...\n",
      "2022-04-03 13:09:25,832 | Validation loss got better 0.46701131515296995 --> 0.4636723383835626.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:11:08,385 | Epoch 34 Result\n",
      "2022-04-03 13:11:08,385 | \ttrain loss: 0.5220155090485468\tvalid_loss: 0.4622585444579766\n",
      "2022-04-03 13:11:08,385 | \tacc: 0.81915\tpc: 0.669415\trc: 0.613325\tf1: 0.626532\n",
      "2022-04-03 13:11:09,029 | Validation accuracy got better 0.8182980537008098 --> 0.8191504475067481.  Saving model ...\n",
      "2022-04-03 13:11:09,091 | Validation loss got better 0.4636723383835626 --> 0.4622585444579766.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.64it/s]\n",
      "2022-04-03 13:12:51,743 | Epoch 35 Result\n",
      "2022-04-03 13:12:51,743 | \ttrain loss: 0.5175803284778513\tvalid_loss: 0.46242475675611877\n",
      "2022-04-03 13:12:51,743 | \tacc: 0.819648\tpc: 0.666609\trc: 0.614892\tf1: 0.626058\n",
      "2022-04-03 13:12:52,409 | Validation accuracy got better 0.8191504475067481 --> 0.8196476772268788.  Saving model ...\n",
      "2022-04-03 13:12:52,470 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:14:34,836 | Epoch 36 Result\n",
      "2022-04-03 13:14:34,836 | \ttrain loss: 0.515408575010627\tvalid_loss: 0.4584610570914909\n",
      "2022-04-03 13:14:34,837 | \tacc: 0.819719\tpc: 0.667166\trc: 0.614664\tf1: 0.627437\n",
      "2022-04-03 13:14:35,505 | Validation accuracy got better 0.8196476772268788 --> 0.8197187100440404.  Saving model ...\n",
      "2022-04-03 13:14:35,568 | Validation loss got better 0.4622585444579766 --> 0.4584610570914909.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:16:18,177 | Epoch 37 Result\n",
      "2022-04-03 13:16:18,177 | \ttrain loss: 0.5127591290143371\tvalid_loss: 0.457493669489836\n",
      "2022-04-03 13:16:18,177 | \tacc: 0.818653\tpc: 0.667817\trc: 0.613751\tf1: 0.626569\n",
      "2022-04-03 13:16:18,818 | Validation loss got better 0.4584610570914909 --> 0.457493669489836.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:18:01,336 | Epoch 38 Result\n",
      "2022-04-03 13:18:01,336 | \ttrain loss: 0.5091397000540125\tvalid_loss: 0.45609399018800467\n",
      "2022-04-03 13:18:01,336 | \tacc: 0.8205\tpc: 0.671448\trc: 0.613667\tf1: 0.629252\n",
      "2022-04-03 13:18:01,967 | Validation accuracy got better 0.8197187100440404 --> 0.8205000710328172.  Saving model ...\n",
      "2022-04-03 13:18:02,028 | Validation loss got better 0.457493669489836 --> 0.45609399018800467.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:19:44,565 | Epoch 39 Result\n",
      "2022-04-03 13:19:44,566 | \ttrain loss: 0.5066734135482428\tvalid_loss: 0.4525240064090686\n",
      "2022-04-03 13:19:44,566 | \tacc: 0.821708\tpc: 0.669249\trc: 0.614099\tf1: 0.6272\n",
      "2022-04-03 13:19:45,199 | Validation accuracy got better 0.8205000710328172 --> 0.8217076289245632.  Saving model ...\n",
      "2022-04-03 13:19:45,261 | Validation loss got better 0.45609399018800467 --> 0.4525240064090686.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:21:27,875 | Epoch 40 Result\n",
      "2022-04-03 13:21:27,876 | \ttrain loss: 0.5023840313371664\tvalid_loss: 0.45241758990717945\n",
      "2022-04-03 13:21:27,876 | \tacc: 0.822276\tpc: 0.659398\trc: 0.616526\tf1: 0.624247\n",
      "2022-04-03 13:21:28,517 | Validation accuracy got better 0.8217076289245632 --> 0.8222758914618554.  Saving model ...\n",
      "2022-04-03 13:21:28,581 | Validation loss got better 0.4525240064090686 --> 0.45241758990717945.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:23:11,208 | Epoch 41 Result\n",
      "2022-04-03 13:23:11,208 | \ttrain loss: 0.5018424503134852\tvalid_loss: 0.45080890472952423\n",
      "2022-04-03 13:23:11,208 | \tacc: 0.821992\tpc: 0.67831\trc: 0.615119\tf1: 0.632863\n",
      "2022-04-03 13:23:11,838 | Validation loss got better 0.45241758990717945 --> 0.45080890472952423.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:24:54,468 | Epoch 42 Result\n",
      "2022-04-03 13:24:54,468 | \ttrain loss: 0.4995125613082885\tvalid_loss: 0.45047545632883845\n",
      "2022-04-03 13:24:54,468 | \tacc: 0.822986\tpc: 0.680673\trc: 0.619955\tf1: 0.636664\n",
      "2022-04-03 13:24:55,095 | Validation accuracy got better 0.8222758914618554 --> 0.8229862196334706.  Saving model ...\n",
      "2022-04-03 13:24:55,158 | Validation loss got better 0.45080890472952423 --> 0.45047545632883845.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:26:37,750 | Epoch 43 Result\n",
      "2022-04-03 13:26:37,751 | \ttrain loss: 0.49665946037047587\tvalid_loss: 0.449519319990884\n",
      "2022-04-03 13:26:37,751 | \tacc: 0.822134\tpc: 0.670629\trc: 0.611626\tf1: 0.628134\n",
      "2022-04-03 13:26:38,381 | Validation loss got better 0.45047545632883845 --> 0.449519319990884.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.65it/s]\n",
      "2022-04-03 13:28:21,645 | Epoch 44 Result\n",
      "2022-04-03 13:28:21,646 | \ttrain loss: 0.49247387431235756\tvalid_loss: 0.44931095891893713\n",
      "2022-04-03 13:28:21,646 | \tacc: 0.823341\tpc: 0.672028\trc: 0.619626\tf1: 0.633288\n",
      "2022-04-03 13:28:22,318 | Validation accuracy got better 0.8229862196334706 --> 0.8233413837192783.  Saving model ...\n",
      "2022-04-03 13:28:22,381 | Validation loss got better 0.449519319990884 --> 0.44931095891893713.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:30:04,970 | Epoch 45 Result\n",
      "2022-04-03 13:30:04,971 | \ttrain loss: 0.49204897573709183\tvalid_loss: 0.44792806897283294\n",
      "2022-04-03 13:30:04,971 | \tacc: 0.823554\tpc: 0.665402\trc: 0.617433\tf1: 0.628444\n",
      "2022-04-03 13:30:05,594 | Validation accuracy got better 0.8233413837192783 --> 0.8235544821707629.  Saving model ...\n",
      "2022-04-03 13:30:05,657 | Validation loss got better 0.44931095891893713 --> 0.44792806897283294.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:31:48,181 | Epoch 46 Result\n",
      "2022-04-03 13:31:48,181 | \ttrain loss: 0.48948904548833705\tvalid_loss: 0.44523037467292126\n",
      "2022-04-03 13:31:48,181 | \tacc: 0.824762\tpc: 0.675874\trc: 0.624093\tf1: 0.636888\n",
      "2022-04-03 13:31:48,821 | Validation accuracy got better 0.8235544821707629 --> 0.8247620400625089.  Saving model ...\n",
      "2022-04-03 13:31:48,887 | Validation loss got better 0.44792806897283294 --> 0.44523037467292126.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.63it/s]\n",
      "2022-04-03 13:33:31,564 | Epoch 47 Result\n",
      "2022-04-03 13:33:31,564 | \ttrain loss: 0.4864091411228126\tvalid_loss: 0.44589027492714495\n",
      "2022-04-03 13:33:31,564 | \tacc: 0.82327\tpc: 0.669073\trc: 0.618476\tf1: 0.630321\n",
      "2022-04-03 13:33:32,203 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:35:14,714 | Epoch 48 Result\n",
      "2022-04-03 13:35:14,714 | \ttrain loss: 0.48605461414894063\tvalid_loss: 0.4435760456487052\n",
      "2022-04-03 13:35:14,714 | \tacc: 0.826254\tpc: 0.681477\trc: 0.630608\tf1: 0.642227\n",
      "2022-04-03 13:35:15,338 | Validation accuracy got better 0.8247620400625089 --> 0.826253729222901.  Saving model ...\n",
      "2022-04-03 13:35:15,403 | Validation loss got better 0.44523037467292126 --> 0.4435760456487052.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:36:57,942 | Epoch 49 Result\n",
      "2022-04-03 13:36:57,943 | \ttrain loss: 0.4826516931416595\tvalid_loss: 0.44182678965245953\n",
      "2022-04-03 13:36:57,943 | \tacc: 0.826396\tpc: 0.678933\trc: 0.623426\tf1: 0.638138\n",
      "2022-04-03 13:36:58,575 | Validation accuracy got better 0.826253729222901 --> 0.826395794857224.  Saving model ...\n",
      "2022-04-03 13:36:58,638 | Validation loss got better 0.4435760456487052 --> 0.44182678965245953.  Saving model ...\n",
      "2022-04-03 13:36:58,703 | # train data: 132867\n",
      "2022-04-03 13:36:58,703 | # valid data: 14078\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:38:41,159 | Epoch 0 Result\n",
      "2022-04-03 13:38:41,159 | \ttrain loss: 5.159793874804668\tvalid_loss: 4.443617672384386\n",
      "2022-04-03 13:38:41,159 | \tacc: 0.097812\tpc: 0.000435\trc: 0.004444\tf1: 0.000792\n",
      "2022-04-03 13:38:41,765 | Validation accuracy got better None --> 0.09781218923142491.  Saving model ...\n",
      "2022-04-03 13:38:41,819 | Validation loss got better None --> 4.443617672384386.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:40:24,369 | Epoch 1 Result\n",
      "2022-04-03 13:40:24,369 | \ttrain loss: 3.924405517890497\tvalid_loss: 3.1025795968423293\n",
      "2022-04-03 13:40:24,370 | \tacc: 0.313468\tpc: 0.042008\trc: 0.043771\tf1: 0.031663\n",
      "2022-04-03 13:40:24,984 | Validation accuracy got better 0.09781218923142491 --> 0.31346782213382585.  Saving model ...\n",
      "2022-04-03 13:40:25,045 | Validation loss got better 4.443617672384386 --> 3.1025795968423293.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:42:07,626 | Epoch 2 Result\n",
      "2022-04-03 13:42:07,626 | \ttrain loss: 2.915589229064336\tvalid_loss: 2.0984008005014587\n",
      "2022-04-03 13:42:07,626 | \tacc: 0.509376\tpc: 0.142044\trc: 0.102475\tf1: 0.094004\n",
      "2022-04-03 13:42:08,250 | Validation accuracy got better 0.31346782213382585 --> 0.5093763318653218.  Saving model ...\n",
      "2022-04-03 13:42:08,312 | Validation loss got better 3.1025795968423293 --> 2.0984008005014587.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:43:50,848 | Epoch 3 Result\n",
      "2022-04-03 13:43:50,848 | \ttrain loss: 2.1002196522432013\tvalid_loss: 1.442394067523391\n",
      "2022-04-03 13:43:50,849 | \tacc: 0.628498\tpc: 0.231364\trc: 0.185172\tf1: 0.180386\n",
      "2022-04-03 13:43:51,474 | Validation accuracy got better 0.5093763318653218 --> 0.6284983662452053.  Saving model ...\n",
      "2022-04-03 13:43:51,536 | Validation loss got better 2.0984008005014587 --> 1.442394067523391.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:45:34,081 | Epoch 4 Result\n",
      "2022-04-03 13:45:34,082 | \ttrain loss: 1.5668265168894568\tvalid_loss: 1.1014732247236219\n",
      "2022-04-03 13:45:34,082 | \tacc: 0.684188\tpc: 0.310276\trc: 0.252644\tf1: 0.254344\n",
      "2022-04-03 13:45:34,701 | Validation accuracy got better 0.6284983662452053 --> 0.6841880948998438.  Saving model ...\n",
      "2022-04-03 13:45:34,762 | Validation loss got better 1.442394067523391 --> 1.1014732247236219.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:47:17,335 | Epoch 5 Result\n",
      "2022-04-03 13:47:17,335 | \ttrain loss: 1.265332874916968\tvalid_loss: 0.922148259970796\n",
      "2022-04-03 13:47:17,335 | \tacc: 0.713525\tpc: 0.404473\trc: 0.318664\tf1: 0.327901\n",
      "2022-04-03 13:47:17,959 | Validation accuracy got better 0.6841880948998438 --> 0.713524648387555.  Saving model ...\n",
      "2022-04-03 13:47:18,023 | Validation loss got better 1.1014732247236219 --> 0.922148259970796.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:49:00,648 | Epoch 6 Result\n",
      "2022-04-03 13:49:00,648 | \ttrain loss: 1.0817925193433653\tvalid_loss: 0.8107068398439473\n",
      "2022-04-03 13:49:00,649 | \tacc: 0.735261\tpc: 0.484515\trc: 0.37852\tf1: 0.391958\n",
      "2022-04-03 13:49:01,287 | Validation accuracy got better 0.713524648387555 --> 0.7352606904389828.  Saving model ...\n",
      "2022-04-03 13:49:01,350 | Validation loss got better 0.922148259970796 --> 0.8107068398439473.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:50:43,917 | Epoch 7 Result\n",
      "2022-04-03 13:50:43,917 | \ttrain loss: 0.9612797479969307\tvalid_loss: 0.7408928739057548\n",
      "2022-04-03 13:50:43,917 | \tacc: 0.748615\tpc: 0.532465\trc: 0.41733\tf1: 0.439565\n",
      "2022-04-03 13:50:44,544 | Validation accuracy got better 0.7352606904389828 --> 0.7486148600653502.  Saving model ...\n",
      "2022-04-03 13:50:44,605 | Validation loss got better 0.8107068398439473 --> 0.7408928739057548.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:52:27,212 | Epoch 8 Result\n",
      "2022-04-03 13:52:27,213 | \ttrain loss: 0.8818569274286091\tvalid_loss: 0.6899546599723446\n",
      "2022-04-03 13:52:27,213 | \tacc: 0.759199\tpc: 0.552835\trc: 0.446006\tf1: 0.467801\n",
      "2022-04-03 13:52:27,831 | Validation accuracy got better 0.7486148600653502 --> 0.759198749822418.  Saving model ...\n",
      "2022-04-03 13:52:27,892 | Validation loss got better 0.7408928739057548 --> 0.6899546599723446.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:54:10,442 | Epoch 9 Result\n",
      "2022-04-03 13:54:10,442 | \ttrain loss: 0.8211848635380388\tvalid_loss: 0.6525590016872711\n",
      "2022-04-03 13:54:10,442 | \tacc: 0.765876\tpc: 0.576351\trc: 0.473552\tf1: 0.494334\n",
      "2022-04-03 13:54:11,063 | Validation accuracy got better 0.759198749822418 --> 0.7658758346356016.  Saving model ...\n",
      "2022-04-03 13:54:11,125 | Validation loss got better 0.6899546599723446 --> 0.6525590016872711.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:55:53,677 | Epoch 10 Result\n",
      "2022-04-03 13:55:53,678 | \ttrain loss: 0.7751436240182275\tvalid_loss: 0.6258964621727736\n",
      "2022-04-03 13:55:53,678 | \tacc: 0.77376\tpc: 0.60096\trc: 0.500672\tf1: 0.522293\n",
      "2022-04-03 13:55:54,321 | Validation accuracy got better 0.7658758346356016 --> 0.7737604773405313.  Saving model ...\n",
      "2022-04-03 13:55:54,384 | Validation loss got better 0.6525590016872711 --> 0.6258964621727736.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 13:57:36,958 | Epoch 11 Result\n",
      "2022-04-03 13:57:36,959 | \ttrain loss: 0.7420958392485524\tvalid_loss: 0.6018778606476576\n",
      "2022-04-03 13:57:36,959 | \tacc: 0.779301\tpc: 0.617867\trc: 0.510956\tf1: 0.532816\n",
      "2022-04-03 13:57:37,598 | Validation accuracy got better 0.7737604773405313 --> 0.7793010370791306.  Saving model ...\n",
      "2022-04-03 13:57:37,662 | Validation loss got better 0.6258964621727736 --> 0.6018778606476576.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 13:59:20,218 | Epoch 12 Result\n",
      "2022-04-03 13:59:20,219 | \ttrain loss: 0.7149875035336516\tvalid_loss: 0.5856269250997919\n",
      "2022-04-03 13:59:20,219 | \tacc: 0.781432\tpc: 0.617202\trc: 0.521054\tf1: 0.541694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 13:59:20,848 | Validation accuracy got better 0.7793010370791306 --> 0.7814320215939764.  Saving model ...\n",
      "2022-04-03 13:59:20,911 | Validation loss got better 0.6018778606476576 --> 0.5856269250997919.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:01:03,472 | Epoch 13 Result\n",
      "2022-04-03 14:01:03,472 | \ttrain loss: 0.6910256985192667\tvalid_loss: 0.5694963949311608\n",
      "2022-04-03 14:01:03,472 | \tacc: 0.78541\tpc: 0.636862\trc: 0.541302\tf1: 0.561125\n",
      "2022-04-03 14:01:04,104 | Validation accuracy got better 0.7814320215939764 --> 0.785409859355022.  Saving model ...\n",
      "2022-04-03 14:01:04,174 | Validation loss got better 0.5856269250997919 --> 0.5694963949311608.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:02:46,674 | Epoch 14 Result\n",
      "2022-04-03 14:02:46,674 | \ttrain loss: 0.6721860628061407\tvalid_loss: 0.5578577038001771\n",
      "2022-04-03 14:02:46,674 | \tacc: 0.789885\tpc: 0.644361\trc: 0.55253\tf1: 0.573977\n",
      "2022-04-03 14:02:47,310 | Validation accuracy got better 0.785409859355022 --> 0.7898849268361984.  Saving model ...\n",
      "2022-04-03 14:02:47,373 | Validation loss got better 0.5694963949311608 --> 0.5578577038001771.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 14:04:29,893 | Epoch 15 Result\n",
      "2022-04-03 14:04:29,893 | \ttrain loss: 0.6557169460262121\tvalid_loss: 0.5481285853961056\n",
      "2022-04-03 14:04:29,893 | \tacc: 0.790808\tpc: 0.647736\trc: 0.549914\tf1: 0.570159\n",
      "2022-04-03 14:04:30,540 | Validation accuracy got better 0.7898849268361984 --> 0.7908083534592982.  Saving model ...\n",
      "2022-04-03 14:04:30,602 | Validation loss got better 0.5578577038001771 --> 0.5481285853961056.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 14:06:13,121 | Epoch 16 Result\n",
      "2022-04-03 14:06:13,121 | \ttrain loss: 0.6422982129332211\tvalid_loss: 0.5404746755989358\n",
      "2022-04-03 14:06:13,121 | \tacc: 0.794289\tpc: 0.65694\trc: 0.563768\tf1: 0.581663\n",
      "2022-04-03 14:06:13,760 | Validation accuracy got better 0.7908083534592982 --> 0.7942889615002131.  Saving model ...\n",
      "2022-04-03 14:06:13,823 | Validation loss got better 0.5481285853961056 --> 0.5404746755989358.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:07:56,419 | Epoch 17 Result\n",
      "2022-04-03 14:07:56,419 | \ttrain loss: 0.629564280571569\tvalid_loss: 0.5304856198063322\n",
      "2022-04-03 14:07:56,419 | \tacc: 0.795283\tpc: 0.658022\trc: 0.57398\tf1: 0.590199\n",
      "2022-04-03 14:07:57,070 | Validation accuracy got better 0.7942889615002131 --> 0.7952834209404746.  Saving model ...\n",
      "2022-04-03 14:07:57,132 | Validation loss got better 0.5404746755989358 --> 0.5304856198063322.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:09:39,689 | Epoch 18 Result\n",
      "2022-04-03 14:09:39,690 | \ttrain loss: 0.6167661457029396\tvalid_loss: 0.5251633345801343\n",
      "2022-04-03 14:09:39,690 | \tacc: 0.797485\tpc: 0.642883\trc: 0.574442\tf1: 0.588811\n",
      "2022-04-03 14:09:40,342 | Validation accuracy got better 0.7952834209404746 --> 0.7974854382724819.  Saving model ...\n",
      "2022-04-03 14:09:40,405 | Validation loss got better 0.5304856198063322 --> 0.5251633345801343.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:11:22,934 | Epoch 19 Result\n",
      "2022-04-03 14:11:22,935 | \ttrain loss: 0.608234149470663\tvalid_loss: 0.5166320791636057\n",
      "2022-04-03 14:11:22,935 | \tacc: 0.800043\tpc: 0.653419\trc: 0.579901\tf1: 0.593816\n",
      "2022-04-03 14:11:23,573 | Validation accuracy got better 0.7974854382724819 --> 0.8000426196902969.  Saving model ...\n",
      "2022-04-03 14:11:23,636 | Validation loss got better 0.5251633345801343 --> 0.5166320791636057.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:13:06,229 | Epoch 20 Result\n",
      "2022-04-03 14:13:06,229 | \ttrain loss: 0.5977189777093327\tvalid_loss: 0.5111009026813412\n",
      "2022-04-03 14:13:06,230 | \tacc: 0.801747\tpc: 0.656651\trc: 0.581731\tf1: 0.598406\n",
      "2022-04-03 14:13:06,858 | Validation accuracy got better 0.8000426196902969 --> 0.8017474073021736.  Saving model ...\n",
      "2022-04-03 14:13:06,919 | Validation loss got better 0.5166320791636057 --> 0.5111009026813412.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:14:49,484 | Epoch 21 Result\n",
      "2022-04-03 14:14:49,484 | \ttrain loss: 0.5930123215235169\tvalid_loss: 0.506304409798954\n",
      "2022-04-03 14:14:49,484 | \tacc: 0.801463\tpc: 0.662874\trc: 0.589719\tf1: 0.604594\n",
      "2022-04-03 14:14:50,111 | Validation loss got better 0.5111009026813412 --> 0.506304409798954.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:16:32,634 | Epoch 22 Result\n",
      "2022-04-03 14:16:32,634 | \ttrain loss: 0.582825115095647\tvalid_loss: 0.5025063378513833\n",
      "2022-04-03 14:16:32,634 | \tacc: 0.80054\tpc: 0.650334\trc: 0.582106\tf1: 0.597558\n",
      "2022-04-03 14:16:33,261 | Validation loss got better 0.506304409798954 --> 0.5025063378513833.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:18:15,852 | Epoch 23 Result\n",
      "2022-04-03 14:18:15,853 | \ttrain loss: 0.5767500073071391\tvalid_loss: 0.4984239634506945\n",
      "2022-04-03 14:18:15,853 | \tacc: 0.805796\tpc: 0.657817\trc: 0.593297\tf1: 0.607334\n",
      "2022-04-03 14:18:16,479 | Validation accuracy got better 0.8017474073021736 --> 0.8057962778803808.  Saving model ...\n",
      "2022-04-03 14:18:16,541 | Validation loss got better 0.5025063378513833 --> 0.4984239634506945.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:19:59,122 | Epoch 24 Result\n",
      "2022-04-03 14:19:59,122 | \ttrain loss: 0.5696223760914542\tvalid_loss: 0.4932775342137591\n",
      "2022-04-03 14:19:59,123 | \tacc: 0.806009\tpc: 0.649491\trc: 0.596528\tf1: 0.606936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 14:19:59,758 | Validation accuracy got better 0.8057962778803808 --> 0.8060093763318653.  Saving model ...\n",
      "2022-04-03 14:19:59,821 | Validation loss got better 0.4984239634506945 --> 0.4932775342137591.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:21:42,436 | Epoch 25 Result\n",
      "2022-04-03 14:21:42,436 | \ttrain loss: 0.5644401391649608\tvalid_loss: 0.4897541511903891\n",
      "2022-04-03 14:21:42,436 | \tacc: 0.806436\tpc: 0.654531\trc: 0.597814\tf1: 0.610146\n",
      "2022-04-03 14:21:43,070 | Validation accuracy got better 0.8060093763318653 --> 0.8064355732348345.  Saving model ...\n",
      "2022-04-03 14:21:43,133 | Validation loss got better 0.4932775342137591 --> 0.4897541511903891.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:23:25,726 | Epoch 26 Result\n",
      "2022-04-03 14:23:25,726 | \ttrain loss: 0.5595232234462361\tvalid_loss: 0.4841914618450533\n",
      "2022-04-03 14:23:25,727 | \tacc: 0.808496\tpc: 0.666923\trc: 0.601757\tf1: 0.615256\n",
      "2022-04-03 14:23:26,364 | Validation accuracy got better 0.8064355732348345 --> 0.8084955249325189.  Saving model ...\n",
      "2022-04-03 14:23:26,428 | Validation loss got better 0.4897541511903891 --> 0.4841914618450533.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:25:09,077 | Epoch 27 Result\n",
      "2022-04-03 14:25:09,078 | \ttrain loss: 0.5534323566072099\tvalid_loss: 0.4836808787707765\n",
      "2022-04-03 14:25:09,078 | \tacc: 0.807643\tpc: 0.66568\trc: 0.601917\tf1: 0.615571\n",
      "2022-04-03 14:25:09,712 | Validation loss got better 0.4841914618450533 --> 0.4836808787707765.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:26:52,386 | Epoch 28 Result\n",
      "2022-04-03 14:26:52,386 | \ttrain loss: 0.5493021978111732\tvalid_loss: 0.48032421750056337\n",
      "2022-04-03 14:26:52,386 | \tacc: 0.808353\tpc: 0.661089\trc: 0.600103\tf1: 0.614163\n",
      "2022-04-03 14:26:53,027 | Validation loss got better 0.4836808787707765 --> 0.48032421750056337.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:28:35,645 | Epoch 29 Result\n",
      "2022-04-03 14:28:35,646 | \ttrain loss: 0.5442724830048247\tvalid_loss: 0.47738879643849547\n",
      "2022-04-03 14:28:35,646 | \tacc: 0.811266\tpc: 0.665723\trc: 0.607453\tf1: 0.619225\n",
      "2022-04-03 14:28:36,281 | Validation accuracy got better 0.8084955249325189 --> 0.8112658048018184.  Saving model ...\n",
      "2022-04-03 14:28:36,345 | Validation loss got better 0.48032421750056337 --> 0.47738879643849547.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:30:18,951 | Epoch 30 Result\n",
      "2022-04-03 14:30:18,952 | \ttrain loss: 0.5439299200736516\tvalid_loss: 0.47435154413902586\n",
      "2022-04-03 14:30:18,952 | \tacc: 0.809703\tpc: 0.663224\trc: 0.610843\tf1: 0.618862\n",
      "2022-04-03 14:30:19,585 | Validation loss got better 0.47738879643849547 --> 0.47435154413902586.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:32:02,171 | Epoch 31 Result\n",
      "2022-04-03 14:32:02,172 | \ttrain loss: 0.538278779600359\tvalid_loss: 0.4725666656160849\n",
      "2022-04-03 14:32:02,172 | \tacc: 0.811692\tpc: 0.673911\trc: 0.611756\tf1: 0.624059\n",
      "2022-04-03 14:32:02,802 | Validation accuracy got better 0.8112658048018184 --> 0.8116920017047876.  Saving model ...\n",
      "2022-04-03 14:32:02,865 | Validation loss got better 0.47435154413902586 --> 0.4725666656160849.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:33:45,518 | Epoch 32 Result\n",
      "2022-04-03 14:33:45,518 | \ttrain loss: 0.5342410360517812\tvalid_loss: 0.4714216096002552\n",
      "2022-04-03 14:33:45,519 | \tacc: 0.810342\tpc: 0.661487\trc: 0.613237\tf1: 0.620592\n",
      "2022-04-03 14:33:46,150 | Validation loss got better 0.4725666656160849 --> 0.4714216096002552.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:31<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:35:28,708 | Epoch 33 Result\n",
      "2022-04-03 14:35:28,708 | \ttrain loss: 0.5291146537152633\tvalid_loss: 0.46856024028530413\n",
      "2022-04-03 14:35:28,708 | \tacc: 0.811976\tpc: 0.66733\trc: 0.615377\tf1: 0.624816\n",
      "2022-04-03 14:35:29,339 | Validation accuracy got better 0.8116920017047876 --> 0.8119761329734337.  Saving model ...\n",
      "2022-04-03 14:35:29,403 | Validation loss got better 0.4714216096002552 --> 0.46856024028530413.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:37:12,067 | Epoch 34 Result\n",
      "2022-04-03 14:37:12,067 | \ttrain loss: 0.5250405576716961\tvalid_loss: 0.46853857080034444\n",
      "2022-04-03 14:37:12,067 | \tacc: 0.813113\tpc: 0.663697\trc: 0.613859\tf1: 0.621472\n",
      "2022-04-03 14:37:12,718 | Validation accuracy got better 0.8119761329734337 --> 0.8131126580480181.  Saving model ...\n",
      "2022-04-03 14:37:12,783 | Validation loss got better 0.46856024028530413 --> 0.46853857080034444.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:38:55,463 | Epoch 35 Result\n",
      "2022-04-03 14:38:55,464 | \ttrain loss: 0.5218074058593578\tvalid_loss: 0.46547936915606153\n",
      "2022-04-03 14:38:55,464 | \tacc: 0.813539\tpc: 0.661853\trc: 0.610712\tf1: 0.619595\n",
      "2022-04-03 14:38:56,109 | Validation accuracy got better 0.8131126580480181 --> 0.8135388549509873.  Saving model ...\n",
      "2022-04-03 14:38:56,172 | Validation loss got better 0.46853857080034444 --> 0.46547936915606153.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:40:38,797 | Epoch 36 Result\n",
      "2022-04-03 14:40:38,798 | \ttrain loss: 0.5184478956146437\tvalid_loss: 0.46377988179344093\n",
      "2022-04-03 14:40:38,798 | \tacc: 0.812829\tpc: 0.659121\trc: 0.611158\tf1: 0.618039\n",
      "2022-04-03 14:40:39,432 | Validation loss got better 0.46547936915606153 --> 0.46377988179344093.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:42:22,099 | Epoch 37 Result\n",
      "2022-04-03 14:42:22,099 | \ttrain loss: 0.5158129164967242\tvalid_loss: 0.46140720541461283\n",
      "2022-04-03 14:42:22,099 | \tacc: 0.81496\tpc: 0.669073\trc: 0.615871\tf1: 0.627136\n",
      "2022-04-03 14:42:22,736 | Validation accuracy got better 0.8135388549509873 --> 0.814959511294218.  Saving model ...\n",
      "2022-04-03 14:42:22,797 | Validation loss got better 0.46377988179344093 --> 0.46140720541461283.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:44:05,439 | Epoch 38 Result\n",
      "2022-04-03 14:44:05,439 | \ttrain loss: 0.5136704576297016\tvalid_loss: 0.4589685058370201\n",
      "2022-04-03 14:44:05,439 | \tacc: 0.815315\tpc: 0.666052\trc: 0.621406\tf1: 0.630027\n",
      "2022-04-03 14:44:06,081 | Validation accuracy got better 0.814959511294218 --> 0.8153146753800256.  Saving model ...\n",
      "2022-04-03 14:44:06,143 | Validation loss got better 0.46140720541461283 --> 0.4589685058370201.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 14:45:48,760 | Epoch 39 Result\n",
      "2022-04-03 14:45:48,761 | \ttrain loss: 0.5117011778964764\tvalid_loss: 0.45770076605250404\n",
      "2022-04-03 14:45:48,761 | \tacc: 0.815883\tpc: 0.66163\trc: 0.618498\tf1: 0.625363\n",
      "2022-04-03 14:45:49,398 | Validation accuracy got better 0.8153146753800256 --> 0.8158829379173178.  Saving model ...\n",
      "2022-04-03 14:45:49,461 | Validation loss got better 0.4589685058370201 --> 0.45770076605250404.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:47:32,113 | Epoch 40 Result\n",
      "2022-04-03 14:47:32,113 | \ttrain loss: 0.5070194490617574\tvalid_loss: 0.45733678158007995\n",
      "2022-04-03 14:47:32,114 | \tacc: 0.817801\tpc: 0.683257\trc: 0.62811\tf1: 0.63822\n",
      "2022-04-03 14:47:32,774 | Validation accuracy got better 0.8158829379173178 --> 0.8178008239806791.  Saving model ...\n",
      "2022-04-03 14:47:32,837 | Validation loss got better 0.45770076605250404 --> 0.45733678158007995.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "2022-04-03 14:49:15,510 | Epoch 41 Result\n",
      "2022-04-03 14:49:15,510 | \ttrain loss: 0.5069299246545983\tvalid_loss: 0.4550725595909419\n",
      "2022-04-03 14:49:15,510 | \tacc: 0.81638\tpc: 0.674731\trc: 0.622668\tf1: 0.630801\n",
      "2022-04-03 14:49:16,147 | Validation loss got better 0.45733678158007995 --> 0.4550725595909419.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.65it/s]\n",
      "2022-04-03 14:50:58,780 | Epoch 42 Result\n",
      "2022-04-03 14:50:58,781 | \ttrain loss: 0.5034798966974007\tvalid_loss: 0.453983201139233\n",
      "2022-04-03 14:50:58,781 | \tacc: 0.817588\tpc: 0.676115\trc: 0.626461\tf1: 0.634657\n",
      "2022-04-03 14:50:59,411 | Validation loss got better 0.4550725595909419 --> 0.453983201139233.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.65it/s]\n",
      "2022-04-03 14:52:42,110 | Epoch 43 Result\n",
      "2022-04-03 14:52:42,110 | \ttrain loss: 0.5013079774044443\tvalid_loss: 0.4516787795726507\n",
      "2022-04-03 14:52:42,111 | \tacc: 0.818156\tpc: 0.666834\trc: 0.624995\tf1: 0.631907\n",
      "2022-04-03 14:52:42,734 | Validation accuracy got better 0.8178008239806791 --> 0.8181559880664867.  Saving model ...\n",
      "2022-04-03 14:52:42,795 | Validation loss got better 0.453983201139233 --> 0.4516787795726507.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.65it/s]\n",
      "2022-04-03 14:54:25,454 | Epoch 44 Result\n",
      "2022-04-03 14:54:25,455 | \ttrain loss: 0.4987217667858406\tvalid_loss: 0.45223615301283676\n",
      "2022-04-03 14:54:25,455 | \tacc: 0.81567\tpc: 0.675028\trc: 0.627531\tf1: 0.636163\n",
      "2022-04-03 14:54:26,080 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.65it/s]\n",
      "2022-04-03 14:56:08,727 | Epoch 45 Result\n",
      "2022-04-03 14:56:08,728 | \ttrain loss: 0.49701144630849015\tvalid_loss: 0.44818851527444237\n",
      "2022-04-03 14:56:08,728 | \tacc: 0.818582\tpc: 0.670473\trc: 0.630969\tf1: 0.637242\n",
      "2022-04-03 14:56:09,361 | Validation accuracy got better 0.8181559880664867 --> 0.8185821849694559.  Saving model ...\n",
      "2022-04-03 14:56:09,424 | Validation loss got better 0.4516787795726507 --> 0.44818851527444237.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.65it/s]\n",
      "2022-04-03 14:57:52,118 | Epoch 46 Result\n",
      "2022-04-03 14:57:52,119 | \ttrain loss: 0.49518176223891913\tvalid_loss: 0.4483081169774678\n",
      "2022-04-03 14:57:52,119 | \tacc: 0.817162\tpc: 0.670477\trc: 0.617964\tf1: 0.628786\n",
      "2022-04-03 14:57:52,746 | patience 0 --> 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "2022-04-03 14:59:35,306 | Epoch 47 Result\n",
      "2022-04-03 14:59:35,307 | \ttrain loss: 0.4915843874518214\tvalid_loss: 0.4490952628430089\n",
      "2022-04-03 14:59:35,307 | \tacc: 0.816309\tpc: 0.67059\trc: 0.628274\tf1: 0.633039\n",
      "2022-04-03 14:59:35,954 | patience 1 --> 2\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.65it/s]\n",
      "2022-04-03 15:01:18,527 | Epoch 48 Result\n",
      "2022-04-03 15:01:18,527 | \ttrain loss: 0.4899864960238254\tvalid_loss: 0.44585880286179747\n",
      "2022-04-03 15:01:18,527 | \tacc: 0.819435\tpc: 0.669069\trc: 0.633686\tf1: 0.63806\n",
      "2022-04-03 15:01:19,157 | Validation accuracy got better 0.8185821849694559 --> 0.8194345787753943.  Saving model ...\n",
      "2022-04-03 15:01:19,219 | Validation loss got better 0.44818851527444237 --> 0.44585880286179747.  Saving model ...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 260/260 [01:32<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:10<00:00,  2.65it/s]\n",
      "2022-04-03 15:03:01,872 | Epoch 49 Result\n",
      "2022-04-03 15:03:01,873 | \ttrain loss: 0.48755525990925724\tvalid_loss: 0.44489626859734555\n",
      "2022-04-03 15:03:01,873 | \tacc: 0.820429\tpc: 0.670309\trc: 0.629994\tf1: 0.635649\n",
      "2022-04-03 15:03:02,506 | Validation accuracy got better 0.8194345787753943 --> 0.8204290382156556.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 15:03:02,568 | Validation loss got better 0.44585880286179747 --> 0.44489626859734555.  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(cat2id)\n",
    "for e in range(args.estimators):\n",
    "    patience = 0 # early stop patience\n",
    "    model_args = arguments() # config for {e}th model\n",
    "    model_args.project = args.project / f'model{e}' # runs/train/exp00/model{e}\n",
    "    create_directory(model_args.project / 'weights') # runs/train/exp00/model{e}/weights\n",
    "    logger = create_logger(model_args.project, name=f'model{e}', file_name='log.txt')\n",
    "    \n",
    "    # dataset\n",
    "    train_loader = train_loaders[e]\n",
    "    valid_loader = valid_loaders[e]\n",
    "    logger.info(f'# train data: {len(train_loader.dataset)}')\n",
    "    logger.info(f'# valid data: {len(valid_loader.dataset)}')\n",
    "    \n",
    "    # build model\n",
    "    if e < n_bert:\n",
    "        model_args.model = 'kobert'\n",
    "        model = KOBERTClassifier(bert=bert, num_classes=num_classes)\n",
    "    else:\n",
    "        model_args.model = 'kogpt2'\n",
    "        model = KOGPT2Classifier(gpt=gpt, num_classes=num_classes)\n",
    "    model = model.to(args.device)\n",
    "    \n",
    "    # save config\n",
    "    with open(model_args.project / 'config.json', 'w', encoding='utf-8-sig') as f:\n",
    "        arg_dict = {k: (str(v) if type(v)==pathlib.PosixPath else v) for k, v in model_args.__dict__.items()}\n",
    "        json.dump(arg_dict, f, indent=4)\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = get_optimizer(args.optimizer, model, args.learning_rate,\n",
    "                              (args.beta1, args.beta2), args.weight_decay, eps=1e-08, amsgrad=False)\n",
    "    \n",
    "    # lr scheduler\n",
    "    t_total = len(train_loader) * args.epochs\n",
    "    scheduler = get_scheduler(name=args.lr_scheduler, optimizer=optimizer, \n",
    "                              num_warmup_steps=args.warmup_step, num_training_steps=t_total)\\\n",
    "    \n",
    "    criterion = get_loss(args.loss)\n",
    "    \n",
    "    best_acc = None\n",
    "    best_loss = None\n",
    "    for epoch in range(args.epochs):\n",
    "        # train\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for (input_ids, attention_mask, token_type_ids, label) in tqdm(train_loader, total=len(train_loader)):\n",
    "            input_ids = input_ids.to(args.device, non_blocking=True)\n",
    "            attention_mask = attention_mask.to(args.device, non_blocking=True)\n",
    "            token_type_ids = token_type_ids.to(args.device, non_blocking=True)\n",
    "\n",
    "            # forward propagation\n",
    "            output = model(input_ids, attention_mask, token_type_ids)\n",
    "            target = label2target(output, label).to(args.device, non_blocking=True)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # backward propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "            train_loss += float(loss)*len(label)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        # validation\n",
    "        valid_loss = 0\n",
    "        class_scores = defaultdict(list)\n",
    "        predictions = []\n",
    "        valid_confusion_matrix = np.zeros((model.num_classes, model.num_classes), dtype=np.int64)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (input_ids, attention_mask, token_type_ids, label) in tqdm(valid_loader, total=len(valid_loader)):\n",
    "                input_ids = input_ids.to(args.device, non_blocking=True)\n",
    "                attention_mask = attention_mask.to(args.device, non_blocking=True)\n",
    "                token_type_ids = token_type_ids.to(args.device, non_blocking=True)\n",
    "\n",
    "                # forward propagation\n",
    "                output = model(input_ids, attention_mask, token_type_ids)\n",
    "                target = label2target(output, label).to(args.device, non_blocking=True)\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss += float(loss)*len(label)\n",
    "\n",
    "\n",
    "                # get confusion matrix\n",
    "                pred = torch.argmax(output, 1).cpu()\n",
    "                valid_confusion_matrix += confusion_matrix(label, pred, labels=list(range(model.num_classes)))\n",
    "                predictions += pred.tolist()\n",
    "\n",
    "            valid_loss /= len(valid_loader.dataset)\n",
    "            acc = np.diagonal(valid_confusion_matrix).sum() / valid_confusion_matrix.sum()\n",
    "            for c in range(len(valid_confusion_matrix)):\n",
    "                num_pred = valid_confusion_matrix[:, c].sum()\n",
    "                num_true = valid_confusion_matrix[c].sum()\n",
    "                TP = valid_confusion_matrix[c, c]\n",
    "                FP = num_true - TP\n",
    "                FN = num_pred - TP\n",
    "                PC = TP/num_pred if num_pred != 0 else 0 # TP / (TP+FP)\n",
    "                RC = TP/num_true if num_true != 0 else 0  # TP / (TP+FN)\n",
    "                F1 = 2 * PC * RC / (PC + RC) if PC + RC != 0 else 0 # (2 * PC * RC) / (PC + RC)\n",
    "                class_scores['class_id'].append(c)\n",
    "                class_scores['precision'].append(PC)\n",
    "                class_scores['recall'].append(RC)\n",
    "                class_scores['f1score'].append(F1)\n",
    "        \n",
    "        # logging scores\n",
    "        macro_pc = statistics.mean(class_scores['precision'])\n",
    "        macro_rc = statistics.mean(class_scores['recall'])\n",
    "        macro_f1 = statistics.mean(class_scores['f1score'])\n",
    "        logger.info(f'Epoch {epoch} Result')\n",
    "        logger.info(f'\\ttrain loss: {train_loss}\\tvalid_loss: {valid_loss}')\n",
    "        logger.info(f'\\tacc: {round(acc, 6)}\\tpc: {round(macro_pc, 6)}\\trc: {round(macro_rc, 6)}\\tf1: {round(macro_f1, 6)}')\n",
    "        \n",
    "        # save scores\n",
    "        if epoch==0:\n",
    "            # summary.csv\n",
    "            with open(model_args.project / 'summary.csv', 'w', newline='') as f:\n",
    "                wr = csv.writer(f)\n",
    "                wr.writerow(['epoch', 'train loss', 'valid loss', 'accuracy', 'precision', 'recall', 'f1score'])\n",
    "            # base frame for precisions, recalls and f1scores\n",
    "            class_id = list(set(train_loader.dataset.label))\n",
    "            num_train_data, num_valid_data = [0] * len(class_id), [0] * len(class_id)\n",
    "            for c_id, n in dict(Counter(train_loader.dataset.label)).items():\n",
    "                num_train_data[c_id] = n\n",
    "            for c_id, n in dict(Counter(valid_loader.dataset.label)).items():\n",
    "                num_valid_data[c_id] = n\n",
    "            history_frame = defaultdict(lambda: pd.DataFrame({\n",
    "                'class_id': class_id,\n",
    "                'class': list(map(lambda x: ''.join(id2cat[x]), class_id)),\n",
    "                '# train data' : num_train_data,\n",
    "                '# valid data' : num_valid_data\n",
    "            }))\n",
    "        \n",
    "        # add new line to summary.csv\n",
    "        with open(model_args.project / 'summary.csv', 'a', newline='') as f:\n",
    "            wr = csv.writer(f)\n",
    "            wr.writerow([epoch, train_loss, valid_loss, acc, macro_pc, macro_rc, macro_f1])\n",
    "            \n",
    "        # add new column(epoch) to precision.csv, recall.csv and f1score.csv\n",
    "        for metric, values in class_scores.items():\n",
    "            if metric != 'class_id':\n",
    "                history_frame[metric][f'epoch {epoch}'] = 0\n",
    "                for c_id, v in zip(class_scores['class_id'], values):\n",
    "                    r = history_frame[metric][history_frame[metric]['class_id']==c_id][f'epoch {epoch}'].index\n",
    "                    history_frame[metric].loc[r, f'epoch {epoch}'] = v\n",
    "                history_frame[metric].to_csv(model_args.project / f'{metric}.csv', encoding='utf-8-sig', index=False)\n",
    "        \n",
    "        # save performance graph\n",
    "        save_performance_graph(model_args.project / 'summary.csv', model_args.project / 'performance.png')\n",
    "        \n",
    "        # model save\n",
    "        epoch_score = acc\n",
    "        torch.save({'state_dict': model.classifier.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scheduler': scheduler.state_dict(),\n",
    "                    'best acc': acc if best_acc is None or acc > best_acc else best_acc,\n",
    "                    'best loss': valid_loss if best_loss is None or valid_loss <= best_loss else best_loss,\n",
    "                    'epoch': epoch},\n",
    "                   model_args.project / 'weights' / 'checkpoint.pth.tar')\n",
    "        \n",
    "        if best_acc is None or acc > best_acc: \n",
    "            logger.info(f'Validation accuracy got better {best_acc} --> {acc}.  Saving model ...')\n",
    "            shutil.copyfile(model_args.project / 'weights' / 'checkpoint.pth.tar',\n",
    "                            model_args.project / 'weights' / 'best_acc.pth.tar')\n",
    "            best_acc = acc\n",
    "            \n",
    "            # save valid predictions\n",
    "            pred_frame = pd.DataFrame({\n",
    "                \"doc\": valid_loader.dataset.doc,\n",
    "                \"category\": list(map(lambda x: ''.join(id2cat[x]), valid_loader.dataset.label)),\n",
    "                \"predictions\": list(map(lambda x: ''.join(id2cat[x]), predictions))\n",
    "            })\n",
    "            pred_frame.to_csv(model_args.project / 'best_acc_predictions.csv', encoding='utf-8-sig', index=False)\n",
    "        \n",
    "        if best_loss is None or valid_loss <= best_loss:\n",
    "            logger.info(f'Validation loss got better {best_loss} --> {valid_loss}.  Saving model ...')\n",
    "            shutil.copyfile(model_args.project / 'weights' / 'checkpoint.pth.tar',\n",
    "                            model_args.project / 'weights' / 'best_loss.pth.tar')\n",
    "            best_loss = valid_loss\n",
    "            \n",
    "            # save valid predictions\n",
    "            pred_frame = pd.DataFrame({\n",
    "                \"doc\": valid_loader.dataset.doc,\n",
    "                \"category\": list(map(lambda x: ''.join(id2cat[x]), valid_loader.dataset.label)),\n",
    "                \"predictions\": list(map(lambda x: ''.join(id2cat[x]), predictions))\n",
    "            })\n",
    "            pred_frame.to_csv(model_args.project / 'best_loss_predictions.csv', encoding='utf-8-sig', index=False)\n",
    "            patience = 0\n",
    "            del pred_frame\n",
    "        else:\n",
    "            logger.info(f'patience {patience} --> {patience+1}')\n",
    "            patience += 1\n",
    "        \n",
    "        if patience >= args.patience:\n",
    "            logger.info('Early Stop!')\n",
    "            break\n",
    "        del class_scores, predictions\n",
    "        \n",
    "    del history_frame\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06026c",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "backbone bert, gpt 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d1d8d",
   "metadata": {},
   "source": [
    "## Load Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2b990e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_classifiers, gpt_classifiers = [], []\n",
    "\n",
    "for e in tqdm(range(args.estimators), total=args.estimators):\n",
    "    checkpoint = torch.load(args.project / f'model{e}/weights/best_loss.pth.tar',\n",
    "                            map_location=args.device)\n",
    "    with open(args.project / f'model{e}' / 'config.json', 'r', encoding='utf-8-sig') as f:\n",
    "        checkpoint_args = json.load(f)\n",
    "        model_type = checkpoint_args['model']\n",
    "    \n",
    "    if model_type=='kobert':\n",
    "        classifier =  nn.Sequential(nn.Linear(768, 4096, bias=True),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(4096, num_classes, bias=True))\n",
    "        classifier.load_state_dict(checkpoint['state_dict'])\n",
    "        classifier = classifier.to(args.device)\n",
    "        bert_classifiers.append(classifier)\n",
    "    else: # kogpt2\n",
    "        classifier = nn.Sequential(nn.Linear(768, 4026, bias=True, dtype=torch.float32),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(4026, num_classes, bias=True, dtype=torch.float32))\n",
    "        classifier.load_state_dict(checkpoint['state_dict'])\n",
    "        classifier = classifier.to(args.device)\n",
    "        gpt_classifiers.append(classifier)\n",
    "        \n",
    "print(len(bert_classifiers))\n",
    "print(len(gpt_classifiers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c241372",
   "metadata": {},
   "source": [
    "## Build Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "634573e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleClassifier(nn.Module):\n",
    "    def __init__(self, num_classes,\n",
    "                 bert=None,\n",
    "                 gpt=None,\n",
    "                 bert_classifiers=[],\n",
    "                 gpt_classifiers=[],\n",
    "                 aggregation='mean_softmax',\n",
    "                 stacking=None\n",
    "                ):\n",
    "        super(EnsembleClassifier, self).__init__()\n",
    "        assert (bert is not None) == (len(bert_classifiers)!=0),\\\n",
    "            'expect both of bert and bert_classifiers, but get one of them'\n",
    "        assert (gpt is not None) == (len(gpt_classifiers)!=0),\\\n",
    "            'expect both of gpt and gpt_classifiers, but get one of them'\n",
    "        self.num_classes=num_classes\n",
    "        self.bert=bert\n",
    "        self.gpt=gpt\n",
    "        self.bert_classifiers=bert_classifiers\n",
    "        self.gpt_classifiers=gpt_classfiers\n",
    "        self.aggregation=aggregation\n",
    "        if aggregation=='mean_softmax':\n",
    "            self.aggregation_fn=self.mean_softmax\n",
    "        elif aggregation=='sum_argmax':\n",
    "            self.aggregation_fn=self.sum_argmax\n",
    "            \n",
    "        for child in self.bert.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        for child in self.gpt.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def mean_softmax(self, tensor, dim=1):\n",
    "        return tensor.mean(dim)\n",
    "    \n",
    "    def sum_argmax(self, tensor, dim=1):\n",
    "        max_idx = torch.argmax(tensor, dim, keepdim=True)\n",
    "        one_hot = torch.FloatTensor(tensor.shape)\n",
    "        one_hot.zero_()\n",
    "        one_hot.scatter_(dim, max_idx, 1)\n",
    "        return one_hot\n",
    "            \n",
    "        \n",
    "    def forward(self, token_ids, attention_mask, token_type_ids):\n",
    "        output = []\n",
    "        # bert output\n",
    "        if self.bert:\n",
    "            _, pooler = self.bert(input_ids=token_ids.long()[:,0].clone(),\n",
    "                                  token_type_ids=token_type_ids.long()[:,0].clone(),\n",
    "                                  attention_mask=attention_mask.float()[:,0].clone())\n",
    "            output += [\n",
    "                F.softmax(classifier(pooler), dim=1) for classifier in self.bert_classifiers\n",
    "            ]\n",
    "            \n",
    "        if self.gpt:\n",
    "            dec_output = self.gpt.transformer(input_ids=token_ids[:,1],\n",
    "                                      token_type_ids=token_type_ids[:,1],\n",
    "                                      attention_mask = attention_mask[:,1])\n",
    "            dec_outputs = dec_output.last_hidden_state[:, -1].contiguous() # 마지막 예측 토큰을 분류값으로 사용\n",
    "            output +=  [\n",
    "                F.softmax(classifier(pooler), dim=1) for classifier in self.gpt_classifiers\n",
    "            ]\n",
    "            \n",
    "        output = torch.cat([op.unsqueeze(1) for op in output], dim=1)\n",
    "        aggregated = self.aggregation_fn(output)\n",
    "        return aggregated\n",
    "    \n",
    "    \n",
    "ensemble = EnsembleClassifier(num_classes,\n",
    "                             bert=bert,\n",
    "                             gpt=gpt,\n",
    "                             bert_classifiers=bert_classifiers,\n",
    "                             gpt_classifiers=gpt_classifiers,\n",
    "                             aggregation='mean_softmax',\n",
    "                             stacking=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1f0c9",
   "metadata": {},
   "source": [
    "## Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67fa6bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.module._IncompatibleKeys"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_classifiers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c1d0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleDataset(Dataset):\n",
    "    def __init__(self, doc, label, kobert_tokenizer=None, kogpt_tokenizer=None,\n",
    "                 max_len=50, padding='max_length', truncation=True):\n",
    "        super(EnsembleDataset, self).__init__()\n",
    "#         assert (kobert_tokenizer==None) and (kogpt_tokenizer==None),\\\n",
    "#                 'expect at least one of kobert and kogpt tokenizer, but get neither'\n",
    "        self.doc = doc\n",
    "        self.label = label\n",
    "        self.kobert_tokenizer = kobert_tokenizer\n",
    "        self.kogpt_tokenizer = kogpt_tokenizer\n",
    "        self.kobert_tokenized = [self.kobert_tokenizer([d]) for d in doc]\n",
    "        self.kogpt_toknized = self.kogpt_tokenizer(doc, padding=padding, max_length=max_len, truncation=truncation, return_tensors='pt')\n",
    "            \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = np.zeros_like(token_ids)\n",
    "        attention_mask[:valid_length] = 1\n",
    "        return attention_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        kobert_token_ids, kobert_valid_length, kobert_token_type_ids = self.kobert_tokenized[idx]\n",
    "        kobert_attention_mask = self.gen_attention_mask(kobert_token_ids, kobert_valid_length)\n",
    "        \n",
    "        kogpt_token_ids = self.kogpt_toknized.input_ids[idx]\n",
    "        kogpt_attention_mask = self.kogpt_toknized.attention_mask[idx]\n",
    "        kogpt_token_type_ids = self.kogpt_toknized.token_type_ids[idx]\n",
    "        \n",
    "        return (torch.cat([torch.from_numpy(kobert_token_ids).unsqueeze(0), kogpt_token_ids.unsqueeze(0)], dim=0), # token_ids\n",
    "                torch.cat([torch.from_numpy(kobert_attention_mask).unsqueeze(0), kogpt_attention_mask.unsqueeze(0)], dim=0), # attention_mask\n",
    "                torch.cat([torch.from_numpy(kobert_token_type_ids).unsqueeze(0), kogpt_token_type_ids.unsqueeze(0)], dim=0), # token_type_ids\n",
    "                self.label[idx]) # int scalar\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.label))\n",
    "    \n",
    "test_set = EnsembleDataset(test['text'].tolist(), test['label'].tolist(),\n",
    "                          kobert_tokenizer=bert_transform, kogpt_tokenizer=gpt_tokenizer,\n",
    "                          max_len=args.max_len)\n",
    "test_loader = DataLoader(test_set, batch_size=args.batch_size, num_workers=args.workers,\n",
    "                         shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e82c0f",
   "metadata": {},
   "source": [
    "## Ensemble Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b3cc63b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 15:55:37,175 | # test data: 88726\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 174/174 [01:25<00:00,  2.03it/s]\n",
      "2022-04-03 15:57:03,004 | \ttest_loss: 0.44489626859734555\n",
      "2022-04-03 15:57:03,004 | \tacc: 0.775477\tpc: 0.655057\trc: 0.65012\tf1: 0.628421\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Int64Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_185355/3354364644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mhistory_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mhistory_fram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf'test_result_verbose.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8-sig'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, key, axis, is_setter)\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m             \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer_for\u001b[0;34m(self, target, **kwargs)\u001b[0m\n\u001b[1;32m   5273\u001b[0m         \"\"\"\n\u001b[1;32m   5274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5276\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3484\u001b[0m             )\n\u001b[1;32m   3485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3488\u001b[0m     def _get_indexer(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m_get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_signed_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;31m# checks/conversions/roundings are delegated to general method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mtarget_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3502\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m             return this.get_indexer(\n\u001b[0;32m-> 3504\u001b[0;31m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3505\u001b[0m             )\n\u001b[1;32m   3506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3484\u001b[0m             )\n\u001b[1;32m   3485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3488\u001b[0m     def _get_indexer(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3510\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_nearest_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3511\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3512\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_engine_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3514\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Int64Index'"
     ]
    }
   ],
   "source": [
    "logger = create_logger(args.project, name='ensemble test', file_name='ensemble_test_log.txt')\n",
    "logger.info(f'# test data: {len(test_loader.dataset)}')\n",
    "\n",
    "ensemble = ensemble.to(args.device)\n",
    "ensemble.eval()\n",
    "test_loss = 0\n",
    "class_scores = defaultdict(list)\n",
    "predictions = []\n",
    "test_confusion_matrix = np.zeros((ensemble.num_classes, ensemble.num_classes), dtype=np.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (input_ids, attention_mask, token_type_ids, label) in tqdm(test_loader, total=len(test_loader)):\n",
    "        input_ids = input_ids.to(args.device, non_blocking=True)\n",
    "        attention_mask = attention_mask.to(args.device, non_blocking=True)\n",
    "        token_type_ids = token_type_ids.to(args.device, non_blocking=True)\n",
    "\n",
    "        # forward propagation\n",
    "        output = ensemble(input_ids, attention_mask, token_type_ids)\n",
    "        target = label2target(output, label).to(args.device, non_blocking=True)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += float(loss)*len(label)\n",
    "\n",
    "\n",
    "        # get confusion matrix\n",
    "        pred = torch.argmax(output, 1).cpu()\n",
    "        test_confusion_matrix += confusion_matrix(label, pred, labels=list(range(ensemble.num_classes)))\n",
    "        predictions += pred.tolist()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = np.diagonal(test_confusion_matrix).sum() / test_confusion_matrix.sum()\n",
    "    for c in range(len(test_confusion_matrix)):\n",
    "        num_pred = test_confusion_matrix[:, c].sum()\n",
    "        num_true = test_confusion_matrix[c].sum()\n",
    "        TP = test_confusion_matrix[c, c]\n",
    "        FP = num_true - TP\n",
    "        FN = num_pred - TP\n",
    "        PC = TP/num_pred if num_pred != 0 else 0 # TP / (TP+FP)\n",
    "        RC = TP/num_true if num_true != 0 else 0  # TP / (TP+FN)\n",
    "        F1 = 2 * PC * RC / (PC + RC) if PC + RC != 0 else 0 # (2 * PC * RC) / (PC + RC)\n",
    "        class_scores['class_id'].append(c)\n",
    "        class_scores['precision'].append(PC)\n",
    "        class_scores['recall'].append(RC)\n",
    "        class_scores['f1score'].append(F1)\n",
    "\n",
    "# logging scores\n",
    "macro_pc = statistics.mean(class_scores['precision'])\n",
    "macro_rc = statistics.mean(class_scores['recall'])\n",
    "macro_f1 = statistics.mean(class_scores['f1score'])\n",
    "logger.info(f'\\ttest_loss: {valid_loss}')\n",
    "logger.info(f'\\tacc: {round(acc, 6)}\\tpc: {round(macro_pc, 6)}\\trc: {round(macro_rc, 6)}\\tf1: {round(macro_f1, 6)}')\n",
    "\n",
    "# summary.csv\n",
    "with open(args.project / 'test_result.csv', 'w', newline='') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow(['test_loss', 'accuracy', 'precision', 'recall', 'f1score'])\n",
    "# base frame for precisions, recalls and f1scores\n",
    "class_id = list(set(train_loader.dataset.label))\n",
    "num_test_data = [0] * len(class_id)\n",
    "for c_id, n in dict(Counter(test_loader.dataset.label)).items():\n",
    "    num_test_data[c_id] = n\n",
    "history_frame = pd.DataFrame({\n",
    "    'class_id': class_id,\n",
    "    'class': list(map(lambda x: ''.join(id2cat[x]), class_id)),\n",
    "    '# test data' : num_test_data\n",
    "})\n",
    "            \n",
    "# add new line to summary.csv\n",
    "with open(args.project / 'test_result.csv', 'a', newline='') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([test_loss, acc, macro_pc, macro_rc, macro_f1])\n",
    "\n",
    "# add new column(epoch) to precision.csv, recall.csv and f1score.csv\n",
    "for metric, values in class_scores.items():\n",
    "    if metric != 'class_id':\n",
    "        history_frame[metric] = 0\n",
    "        for c_id, v in zip(class_scores['class_id'], values):\n",
    "            r = history_frame[history_frame['class_id']==c_id][metric].index\n",
    "            history_frame.loc[r, metric] = v\n",
    "        history_frame.to_csv(args.project / f'test_result_verbose.csv', encoding='utf-8-sig', index=False)\n",
    "                \n",
    "# save valid predictions\n",
    "pred_frame = pd.DataFrame({\n",
    "    \"doc\": test_loader.dataset.doc,\n",
    "    \"category\": list(map(lambda x: ''.join(id2cat[x]), test_loader.dataset.label)),\n",
    "    \"predictions\": list(map(lambda x: ''.join(id2cat[x]), predictions))\n",
    "})\n",
    "pred_frame.to_csv(args.project / 'predictions.csv', encoding='utf-8-sig', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9beca93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, values in class_scores.items():\n",
    "    if metric != 'class_id':\n",
    "        history_frame[metric] = 0\n",
    "        for c_id, v in zip(class_scores['class_id'], values):\n",
    "            r = history_frame[history_frame['class_id']==c_id][metric].index\n",
    "            history_frame.loc[r, metric] = v\n",
    "        history_frame.to_csv(args.project / f'test_result_verbose.csv', encoding='utf-8-sig', index=False)\n",
    "                \n",
    "# save valid predictions\n",
    "pred_frame = pd.DataFrame({\n",
    "    \"doc\": test_loader.dataset.doc,\n",
    "    \"category\": list(map(lambda x: ''.join(id2cat[x]), test_loader.dataset.label)),\n",
    "    \"predictions\": list(map(lambda x: ''.join(id2cat[x]), predictions))\n",
    "})\n",
    "pred_frame.to_csv(args.project / 'predictions.csv', encoding='utf-8-sig', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59039792",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "input : (args.estimator)개 모델의 output을 개별 feature의 관측치라고 본다..\n",
    "\n",
    "model : 뉴럴 네트워크 뿐만 아니라 일반적인 분류 모델 ex) decision tree 등 사용 가능할 듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be47bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c63744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "185.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
